defective flood-control	1.000000
probabilistic decisions	0.285714
terms such	0.076923
and 2500	0.001445
for disambiguation	0.003610
type validity	0.071429
semi-supervised learning	0.500000
or just	0.004505
Hulth uses	0.333333
PARRY ,	1.000000
of algorithms	0.000891
are both	0.008299
Hulth used	0.333333
the recognition	0.001384
program would	0.045455
-LRB- MPE	0.002710
how strong	0.034483
produce more	0.090909
to found	0.001328
generate form	0.055556
edges are	0.142857
help automatic	0.111111
of hand	0.000891
text-understanding	0.000029
indicates that	1.000000
Input for	0.500000
compare generated	0.142857
typically evaluated	0.055556
Iraq and	0.500000
rates even	0.125000
aspects of	0.857143
of similar	0.001783
special ink	0.200000
errors	0.000145
AT&T	0.000029
for Reading	0.003610
German capitalizes	0.250000
defines components	0.500000
the isolation	0.000692
boards and	1.000000
controversy	0.000029
WER -RRB-	1.000000
the automatic	0.001384
University ,	0.111111
around 2	0.125000
around 6	0.375000
Harvey	0.000029
subscription department	1.000000
language generation	0.033784
Recall measures	0.333333
translate text	0.333333
role the	0.250000
, making	0.000561
abbreviations	0.000145
Office -LRB-	1.000000
the GALE	0.001384
therefore	0.000145
distortions	0.000029
question understanding	0.023810
or ,	0.004505
underlying formal	0.333333
The genetic	0.005208
meteorologist	0.000029
see for	0.050000
Question answering	0.285714
bottom-up parsers	1.000000
of summarization	0.007130
the example	0.002076
<s> But	0.004612
or a	0.085586
or `	0.004505
financial and	0.250000
Individuals with	1.000000
way that	0.125000
want	0.000174
recognize text	0.111111
processing natural	0.018519
topics ,	0.142857
purposes .	0.500000
LL	0.000058
purposes ,	0.250000
Foucault became	0.333333
to lower	0.001328
of good	0.000891
LR	0.000058
1954 on	0.333333
verb ,	0.384615
verb .	0.153846
L.	0.000029
sentences but	0.026316
-RRB- for	0.005634
wrong	0.000029
verb :	0.076923
closest counterparts	0.500000
identify keyphrases	0.083333
CFG	0.000029
of emails	0.000891
The shorter	0.005208
count of	0.400000
, 5000	0.000561
of giving	0.000891
general personal	0.045455
nonsensical	0.000029
lexicon required	0.111111
language document	0.006757
e.g. from	0.017857
underlies the	1.000000
word and	0.016667
infinitive marker	1.000000
platform for	0.500000
are now	0.016598
are not	0.020747
point ,	0.666667
texts of	0.117647
a simulation	0.001227
fundamentally different	1.000000
Schroeder	0.000029
additional costs	0.166667
it agrees	0.008547
have limited	0.009615
as consideration	0.003484
equipment was	0.333333
fact ,	0.454545
a US	0.002454
typically given	0.055556
Jabberwacky	0.000029
move items	1.000000
distance to	0.333333
theory for	0.076923
reasoning schemes	0.142857
Asia	0.000029
among other	0.375000
learning techniques	0.023256
equivalent questions	0.200000
with part-of-speech	0.005464
the advent	0.000692
corpora and	0.090909
1990s .	0.333333
an arithmetic	0.007576
1990s ,	0.333333
dialog that	0.500000
can tell	0.005525
method that	0.062500
after applying	0.083333
whom ?	0.500000
assignment of	0.500000
Message Understanding	1.000000
publication of	0.666667
shift-reduce	0.000029
on written	0.004717
should correspond	0.052632
literature are	1.000000
encourage	0.000029
adapt	0.000029
versus ``	1.000000
estimate	0.000116
printed records	0.083333
; Michel	0.021277
classes Different	0.200000
level features	0.050000
allowable expression	0.500000
this shifting	0.010989
to fine	0.001328
to find	0.010624
Cuzco	0.000029
disturbed	0.000029
to benefit	0.001328
<s> Increasingly	0.001537
computers have	0.111111
considered separately	0.111111
a string	0.002454
goal -RRB-	0.142857
them which	0.052632
document collections	0.027778
entity recognition	0.400000
arise because	1.000000
service	0.000145
, minimum	0.000561
Aggregation	0.000029
needed	0.000608
, typical	0.000561
this refined	0.010989
an average	0.007576
of corpora	0.000891
Robyn Carston	1.000000
algorithms optimized	0.028571
of Chinese	0.000891
feasibility	0.000058
mobile email	0.500000
reviews ,	0.500000
to -RRB-	0.001328
feeling	0.000029
Type =	1.000000
Generally	0.000145
interactive clarification	0.250000
USMC ,	1.000000
of outputs	0.000891
100	0.000087
`` machine	0.005291
difficulty of	0.428571
Theo	0.000029
Then	0.000145
They	0.000087
speech naturally	0.006579
translator 's	0.285714
many aspects	0.019231
, ``	0.014037
a larger	0.004908
time step	0.030303
Meehan ,	1.000000
on integrating	0.004717
metrics	0.000261
simplify	0.000029
even produce	0.037037
wanted to	1.000000
organization of	0.400000
into meaningful	0.025641
vertices	0.000261
is search	0.002033
the photos	0.000692
, preparation	0.000561
saying	0.000029
Jurafsky and	1.000000
commercial OCR	0.181818
primarily with	0.500000
document ,	0.138889
POS-tagging	0.000029
between text	0.025641
topics or	0.142857
recognize the	0.444444
helicopter environment	0.500000
preselects small	1.000000
Such a	0.125000
estimate ,	0.250000
discussion of	0.500000
to adapt	0.001328
than	0.001303
spoke the	1.000000
rich	0.000145
decisions are	0.100000
Computationally ,	1.000000
Jelinek and	0.500000
L'action GRACE	1.000000
Yehoshua Bar-Hillel	1.000000
as information	0.003484
can compensate	0.005525
-LRB- HAMS	0.002710
personal computing	0.250000
deep approach	0.142857
at least	0.073529
paying attention	1.000000
most famous	0.034483
Given a	0.714286
model is	0.100000
approach would	0.028571
diversity during	0.250000
complex question	0.041667
systems and	0.008929
`` diversity	0.005291
system should	0.010753
-LRB- some	0.002710
between ``	0.025641
Advanced	0.000145
more subjective	0.010526
nature	0.000174
customer service	1.000000
successive letters	0.500000
some cases	0.048193
section called	0.166667
on statistical	0.009434
extent	0.000116
common ,	0.080000
is easy	0.002033
customers ,	0.500000
what features	0.031250
graph-based ranking	1.000000
E. Brill	0.250000
R. Schroeder	0.166667
of unigrams	0.001783
smaller more	0.142857
texts to	0.117647
require subjects	0.045455
: compare	0.009804
of their	0.001783
Rhetoric Stylistics	1.000000
customisation	0.000029
-LRB- Dec.	0.002710
for these	0.003610
.	0.037115
much	0.000637
English phrase	0.027027
on stochastic	0.004717
NLP Handbook	0.021277
systems -RRB-	0.008929
and recall	0.002890
The approaches	0.005208
and assess	0.001445
expression .	0.200000
on Audio	0.004717
expression ,	0.200000
they use	0.025000
QUALM	0.000029
k	0.000029
Human languages	0.200000
considered or	0.111111
angry ,	0.500000
transfer-based	0.000087
angry .	0.500000
they consider	0.025000
tagging -LRB-	0.040000
split	0.000116
we hear	0.022222
specifically developed	0.500000
step the	0.066667
Working with	1.000000
tasks like	0.062500
answering systems	0.083333
scores that	0.200000
, Larry	0.000561
combined in	0.500000
and ATIS	0.001445
Isles	0.000058
academic	0.000029
a handheld	0.001227
required for	0.142857
handling differences	0.500000
appropriately	0.000058
the RCA	0.000692
projection	0.000029
has specialized	0.011905
first of	0.030303
The Turney	0.005208
LexRank applies	0.083333
stationary process	0.142857
had	0.000405
Post Office	0.500000
a German	0.001227
<s> According	0.000769
OCR products	0.020408
translator needs	0.142857
has	0.002432
The next	0.005208
their corresponding	0.029412
an implementation	0.007576
a part-of-speech	0.001227
and computational	0.001445
'' appears	0.005376
absorbing Markov	0.333333
evaluated in	0.142857
whether medium	0.076923
proper nouns	0.142857
confusability	0.000029
<s> These	0.012298
Steven	0.000029
weights to	0.400000
Swedish	0.000029
warping	0.000116
acoustic signal	0.166667
and Cary	0.001445
mentions -LRB-	0.333333
Ask.com .	1.000000
Facebook	0.000029
more fine-grained	0.010526
parsers and	0.076923
existing words	0.200000
NLP methods	0.021277
Carla Willig	1.000000
dialing -LRB-	1.000000
they join	0.025000
reCAPTCHA system	1.000000
Hansard corpus	1.000000
In other	0.019048
speeches ,	1.000000
the envelope	0.000692
them into	0.052632
the degree	0.000692
systems with	0.017857
product of	0.142857
redundancy in	0.666667
at language	0.014706
beings	0.000029
we take	0.022222
free of	0.250000
Xerox ,	0.500000
<s> DARPA	0.000769
<s> Black-box	0.000769
summarization often	0.020000
heuristic final	0.333333
news articles	0.230769
by people	0.011429
AFTI -RRB-	1.000000
applies a	0.285714
each such	0.022222
rates greatly	0.125000
, disturbed	0.000561
equivalence relations	0.500000
are free	0.004149
manipulate .	0.333333
solutions .	0.500000
applications fall	0.040000
Sentiment	0.000174
and Reinvestment	0.001445
Politics -LRB-	1.000000
approximating sentence	1.000000
ambiguity because	0.125000
The term	0.020833
role	0.000116
or adjective	0.004505
Documents ''	1.000000
word boundary	0.016667
is actually	0.004065
more power	0.010526
the reduction	0.000692
text-to-speech and	0.500000
reviewed and	1.000000
evaluation Black-box	0.018519
<s> ATNs	0.000769
systems simply	0.008929
chain	0.000029
be maintained	0.004219
be asking	0.004219
'' versus	0.005376
popular strategy	0.111111
We can	0.285714
the different	0.000692
operated on	0.500000
GenEx	0.000029
flatbed	0.000029
distinct sentences	0.142857
choice	0.000232
say your	0.142857
is shown	0.002033
This task	0.031746
corp.	0.000029
Talmy Giv√≥n	1.000000
minute	0.000029
questions from	0.038462
Lehnert	0.000087
real estate	0.111111
<s> Solving	0.000769
subsystem for	1.000000
the research	0.002076
and actual	0.001445
M.	0.000116
dependency grammar	0.200000
dozens of	1.000000
use various	0.013889
the Cuzco	0.000692
patient	0.000029
on such	0.004717
only unigrams	0.026316
programs sponsored	0.090909
<s> Design	0.002306
out loud	0.071429
geography	0.000029
kinds of	1.000000
was evident	0.012987
address	0.000116
degraded-images	0.000029
My	0.000029
ME	0.000058
, whether	0.000561
now largely	0.076923
Precision measures	1.000000
MT	0.000145
accomplished	0.000029
made indifferent	0.062500
web page	0.125000
commercial version	0.090909
wrong fairly	1.000000
automatic keyphrase	0.043478
at Cognitive	0.014706
into separate	0.025641
word is	0.066667
An extractive	0.062500
word in	0.066667
, bigrams	0.001123
Invoice OCR	1.000000
proliferation of	1.000000
working	0.000203
& Critical	0.125000
of producing	0.000891
optimize	0.000029
fully up	0.166667
opposed	0.000029
hitcha '	1.000000
but that	0.044118
order for	0.071429
when outputting	0.028571
well to	0.035714
-LRB- Campaigns	0.002710
the new	0.000692
off-line character	1.000000
originally	0.000058
analysis system	0.015385
Wetherell	0.000029
following	0.000434
people create	0.062500
contractions ,	0.500000
many forms	0.019231
incremental	0.000029
humans can	0.083333
listens	0.000029
same input	0.080000
system answers	0.010753
be deployed	0.004219
the terms	0.000692
processing to	0.018519
Significant	0.000029
although capabilities	0.166667
rules of	0.093023
STT	0.000029
fueled	0.000029
sociolinguistics	0.000058
work derived	0.041667
pulled	0.000029
travel	0.000029
Its results	0.500000
on general	0.004717
weaker .	1.000000
were called	0.024390
effective decision-support	0.166667
to speech	0.003984
years	0.000608
structuring	0.000029
, there	0.006176
no subtypes	0.076923
appear often	0.062500
open-access journal	1.000000
`` fire	0.005291
Keyphrase extractors	0.250000
surfer model	1.000000
subjectivity\/objectivity identification	1.000000
and\/or religious	0.333333
short-time units	0.500000
Tablet PC	1.000000
short intervals	0.125000
Stages The	1.000000
simultaneously with	0.500000
A linguist	0.020000
larger system	0.125000
examples as	0.041667
`` classification	0.015873
<s> How	0.003075
or subjective	0.009009
possible answers	0.041667
<s> Context-free	0.000769
the simple	0.000692
Agency in	0.500000
been made	0.014706
entering	0.000058
of analyses	0.000891
Deborah	0.000058
requires specialized	0.062500
70s the	1.000000
Steven DeRose	1.000000
Michigan	0.000029
automatically evaluating	0.047619
limits -LRB-	1.000000
of syntactic	0.001783
internet	0.000029
, Rajman	0.000561
sociology ,	1.000000
extremely difficult	0.750000
exponential time	0.500000
complicated	0.000087
most difficult	0.017241
without the	0.076923
For telephone	0.016393
comprising multiple	0.500000
of Peru	0.000891
which was	0.036232
against which	0.200000
dictionary .	0.142857
classes of	0.400000
Rabinow	0.000029
reasoning components	0.142857
emotion	0.000029
‚Üí <verb>	0.333333
spoken	0.000405
being the	0.055556
one	0.001882
talk page	1.000000
study of	0.250000
documents were	0.026316
unlikely analyses	1.000000
minimizes	0.000058
Prior implementations	1.000000
4-gram	0.000029
Intelligent Machines	0.333333
domains .	0.250000
domains ,	0.125000
or two	0.009009
NAACL	0.000029
view of	0.333333
answering a	0.083333
Eurospeech\/ICSLP -LRB-	1.000000
programs to	0.090909
Italian ;	0.500000
summarizes that	1.000000
recognition models	0.008264
multi-document summarization	0.750000
History	0.000058
to enumerate	0.001328
answering :	0.083333
document level	0.027778
<s> Unsupervised	0.003843
speech as	0.013158
interactivity -LRB-	1.000000
answering .	0.166667
since it	0.200000
learning procedures	0.046512
1980s saw	0.111111
for errors	0.003610
reporting -LRB-	0.333333
these sounds	0.023810
evaluation Depending	0.018519
turned	0.000058
the Unix	0.001384
uninterrupted	0.000029
Treebank data	0.166667
We assume	0.142857
all unknowns	0.023256
pertain strongly	1.000000
printer	0.000029
opposite	0.000058
is subjectivity\/objectivity	0.002033
hand-printed documents	0.250000
dictionary and	0.142857
printed	0.000347
conditions Accuracy	0.200000
to summarization	0.002656
By having	0.333333
In order	0.019048
sentences begin	0.013158
reasoned views	1.000000
, affective	0.000561
lines and	0.333333
Top-down	0.000058
different groups	0.020408
digital assistants	0.142857
assess how	0.666667
large data	0.043478
texts or	0.058824
, Hindle	0.000561
revolutionized	0.000029
A large	0.020000
well it	0.071429
Louise J.	1.000000
resort to	1.000000
schemata .	1.000000
making up	0.142857
human-like interaction	1.000000
and statistical	0.004335
are able	0.012448
precision and	0.400000
vision	0.000029
within that	0.055556
Constraints e.g.	0.333333
This analysis	0.015873
versions for	0.333333
different way	0.020408
a subset	0.003681
the speaker	0.001384
performed more	0.100000
are germane	0.004149
-LRB- ending	0.002710
Unsourced	0.000029
an EHR	0.007576
levels first	0.045455
diagonal covariance	1.000000
expended	0.000029
of criteria	0.000891
rarely the	0.333333
without reference	0.076923
not mark	0.008929
finds many	1.000000
average distance	0.500000
impossibility of	1.000000
Associated Press	1.000000
A.C.	0.000029
commonly taught	0.125000
have on	0.009615
evaluation workshops	0.018519
Analysis Although	0.200000
to erroneous	0.001328
threshold	0.000116
actually correct	0.333333
the postal	0.000692
heard or	1.000000
word that	0.033333
formed	0.000145
automatizing	0.000029
photos	0.000029
-LRB- sailor	0.005420
learning Beginning	0.023256
algorithm could	0.035714
part-of-speech tags	0.066667
corpora in	0.090909
be the	0.012658
expressed with	0.166667
their products	0.029412
newspaper	0.000087
important Web	0.062500
program got	0.045455
Size	0.000029
highly ambiguous	0.111111
be different	0.004219
the multiple	0.000692
requires its	0.062500
technology	0.000637
N words	0.333333
Profile	0.000029
Reinvestment Act	1.000000
, was	0.002246
or semantics	0.004505
supplying more	1.000000
example-generation	0.000029
assigns	0.000029
recall-based	0.000058
edges	0.000203
to ease	0.001328
methods .	0.022727
methods ,	0.090909
use so-called	0.013889
% range	0.025641
Inclusive choice	1.000000
Back-End	0.000029
agree -RRB-	0.333333
, glossary	0.001123
them ,	0.210526
them .	0.105263
effects	0.000029
being	0.000521
<s> Constraints	0.000769
-RRB- up	0.002817
results show	0.047619
translation studies	0.013514
grounded	0.000087
additional citations	0.166667
Unsourced material	1.000000
Computer Science	0.166667
who co-founded	0.100000
Standard Oil	0.500000
system used	0.010753
gestures	0.000058
Oklahoma ,	1.000000
1985 ,	1.000000
Amplitude	0.000029
world	0.000434
postal	0.000029
Latin .	0.250000
home ''	1.000000
also because	0.014493
other approaches	0.014286
translation tasks	0.013514
satisfactory	0.000029
Information Subsumption	0.200000
working to	0.142857
, sociolinguistics	0.000561
-RRB- BioCreative	0.002817
simple extraction	0.038462
gradual lessening	1.000000
of multimedia	0.000891
bases ,	1.000000
, fuse	0.000561
semantically	0.000029
January 2010	0.500000
Intrinsic	0.000087
a probabilistic	0.001227
machine-generated	0.000029
from technology	0.009615
legal documents	0.333333
`` AI-complete	0.010582
gender ,	1.000000
disabilities	0.000116
parameters for	0.500000
: A	0.009804
product line	0.142857
above ,	0.307692
above .	0.076923
<s> Incorporating	0.000769
multiplying together	1.000000
typically a	0.055556
if indeed	0.035714
NN	0.000029
when multiple	0.028571
NC	0.000029
more input	0.010526
scores as	0.200000
NP	0.000029
asked within	0.333333
improvements in	0.500000
is RDF	0.002033
project and	0.076923
<s> Envelopes	0.000769
more sophisticated	0.021053
, assertion	0.000561
societal	0.000029
Charniak points	1.000000
<s> Up	0.000769
ROUGE-1 only	0.200000
with	0.005298
a rich	0.003681
e.g. Phonemes	0.017857
-LRB- DOE	0.002710
NLG the	0.047619
line in	0.333333
sufficient .	0.600000
and weapons	0.001445
the very	0.000692
alone ,	0.250000
associating	0.000029
formulation	0.000029
3rd rev	1.000000
field because	0.037037
Real	0.000058
Read	0.000058
the shipment	0.000692
thresholded	0.000029
campaign was	0.200000
each segment	0.044444
genetic algorithm	1.000000
US ports	0.142857
accuracy of	0.129032
given restaurant	0.041667
out the	0.214286
of symbols	0.000891
a database	0.003681
recognition in	0.024793
Fowler ,	1.000000
higher than	0.142857
linguists would	0.333333
of Eastern	0.000891
proper lexical	0.142857
be repeated	0.004219
a class	0.001227
and nouns	0.001445
learning the	0.023256
domains such	0.125000
causes	0.000029
morphologically rich	1.000000
related fields	0.066667
<s> Further	0.002306
a preliminary	0.001227
be gained	0.004219
In contrast	0.047619
norm	0.000029
or ``	0.018018
time ,	0.333333
time .	0.121212
Conversation	0.000029
connected by	0.200000
linguists	0.000087
faster to	0.333333
that revolutionized	0.003546
filling	0.000029
small	0.000261
to input	0.002656
and echoes	0.001445
statistically-based speech	1.000000
analysis include	0.015385
The ``	0.010417
algorithms one	0.028571
past	0.000087
displays	0.000029
Swedish pilots	1.000000
pass	0.000029
that are	0.053191
exploited ;	1.000000
statistical quantity	0.030303
translators and	1.000000
dog to	0.333333
the difficulties	0.000692
modeling salience	0.142857
full	0.000145
usually from	0.031250
highly interactive	0.111111
RCA collaborated	0.200000
-LRB- MAHS	0.002710
in visible	0.001873
be confused	0.004219
experience	0.000058
prior	0.000087
in such	0.005618
fighter trainer	0.166667
less expensive	0.083333
report -RRB-	0.250000
the times	0.000692
followed	0.000116
traffic controllers	1.000000
generic response	0.333333
: Rule-based	0.009804
Kolodner	0.000029
and SpeechTEK	0.001445
Throughout the	1.000000
weather forecasts	0.571429
The relationships	0.005208
The state-of-the-art	0.005208
automate	0.000087
, verb	0.001123
more	0.002750
than what	0.022222
door	0.000116
simple keyword	0.038462
TextRank is	0.071429
company	0.000087
corrected	0.000029
paragraphs -RRB-	0.250000
in restricted	0.001873
a multi-way	0.001227
existing summaries	0.200000
1993 -RRB-	0.333333
software produces	0.037037
2.0 The	0.500000
whereby words	1.000000
installing	0.000029
script .	0.500000
by limiting	0.005714
learn	0.000376
associated word	0.250000
CoNLL shared	1.000000
ambiguity and	0.125000
continuous speech	0.500000
various term	0.055556
<s> Recognizing	0.000769
records and	0.250000
Aided Machine	0.333333
huge	0.000029
1994 ,	1.000000
written-out	0.000029
and memory	0.001445
efforts were	0.142857
part-of-speech categories	0.066667
Answer extraction	0.666667
stub reader	1.000000
about 95	0.025000
completely nonsensical	1.000000
20th-century newspaper	1.000000
intended	0.000145
functional languages	0.500000
variant	0.000029
organization	0.000145
Law and	1.000000
current state	0.142857
system-generated summaries	0.500000
entered John	0.500000
have multiple	0.009615
a web	0.001227
characterize a	0.500000
installed	0.000087
paper	0.000318
funding was	0.125000
a likelihood	0.001227
one symbol	0.015385
easy-to-use syntax	1.000000
system was	0.053763
in France	0.003745
routed along	0.500000
-RRB- approach	0.002817
Response based	1.000000
the informational	0.000692
to generate	0.007968
automatic summaries	0.130435
electronic medical	0.500000
representation system	0.052632
be explained	0.004219
Morpholympics compared	1.000000
<s> POS-tagging	0.000769
courses	0.000029
, audio	0.001123
create features	0.058824
other scientific	0.014286
that state	0.003546
such system	0.008130
French were	0.250000
recognition performance	0.033058
to what	0.005312
numeric	0.000029
operation	0.000058
component sentences	0.200000
granted a	1.000000
keywords or	0.500000
standards and	0.200000
using neural	0.016949
ME is	0.500000
the barmaid	0.000692
similar methods	0.037037
research	0.001216
view -LRB-	0.333333
opportunities and	1.000000
DeRose 1990	0.200000
, statement	0.000561
-LRB- Sonic	0.002710
individual users	0.083333
exactly as	0.333333
of interest	0.002674
: Statistical	0.009804
and researchers	0.001445
see the	0.100000
generation because	0.111111
Subjectivity ''	1.000000
definition	0.000145
pairs	0.000058
implications of	1.000000
Screenshot	0.000029
formal rules	0.111111
gonna do	1.000000
may well	0.019231
rather to	0.062500
basic sub-signals	0.076923
is on	0.004065
network is	0.166667
of Business-card	0.000891
judgement ,	0.333333
domain and	0.050000
1969 Roger	0.500000
certain sequences	0.142857
it might	0.008547
appropriate number	0.250000
and we	0.001445
large quantities	0.086957
robot questions	0.500000
door being	0.250000
sound .	0.050000
sound ,	0.100000
into play	0.012821
event .	0.333333
event ,	0.666667
are selected	0.004149
data in	0.025974
be kept	0.004219
500 samples	0.500000
and get	0.001445
issues of	0.200000
to dozens	0.001328
segmentation task	0.030303
also	0.001998
recognizing	0.000145
cockpit functions	0.500000
Interlingual machine	0.666667
systems remains	0.008929
that character-by-character	0.003546
Ge'ez script	1.000000
Consultant	0.000029
typical large-vocabulary	0.111111
DeRose	0.000145
an ellipsis	0.007576
on their	0.009434
seize	0.000029
sometimes	0.000376
task it	0.023810
by Ask.com	0.005714
task is	0.142857
Voice Translator	0.200000
stutering ,	1.000000
we try	0.022222
ambiguities	0.000116
to segment	0.003984
in NLP	0.014981
speaker .	0.166667
deferred speech	1.000000
sort mail	0.333333
in NLG	0.005618
involve the	0.166667
guessed at	1.000000
This technique	0.015873
columns	0.000029
's intent	0.019608
, unverified	0.000561
sentences from	0.026316
problem may	0.022727
controller ,	0.500000
specific theoretical	0.047619
as maximum	0.003484
human-made summaries	0.500000
of children	0.000891
d'√©valuation	0.000029
Advanced reasoning	0.200000
sound waves	0.050000
quantity of	0.333333
model would	0.100000
web blogs	0.125000
vendors .	0.250000
higher error	0.142857
mentions within	0.333333
analog	0.000058
tag ''	0.062500
<s> Competing	0.000769
similar to	0.555556
about unigrams	0.025000
asking for	0.500000
include distinct	0.037037
both to	0.129032
register by	1.000000
length ,	0.250000
last	0.000145
document browsing	0.027778
follow-the-bouncing-ball video	1.000000
sense disambiguation	0.250000
Query	0.000029
a cluster	0.002454
EndWar	0.000029
the WYSIWYM	0.000692
described here	0.166667
marks ,	0.250000
Research into	0.125000
adaptation	0.000087
by Yehoshua	0.005714
create some	0.058824
Cary	0.000029
rudimentary translation	0.500000
intelligence that	0.250000
information can	0.021739
counselling	0.000029
spectrum	0.000029
finds	0.000029
despite	0.000087
untrained	0.000029
Michel	0.000087
things -RRB-	0.333333
interpreter ,	0.500000
to enhance	0.001328
exponential	0.000058
expanded	0.000029
empirical	0.000029
Intelligence	0.000087
view language	0.333333
from machine	0.019231
intervening punctuation	1.000000
from script	0.009615
higher degree	0.142857
several phases	0.045455
SYSTRAN for	1.000000
release beyond	0.333333
abilities .	1.000000
speaking ,	0.625000
digital .	0.142857
captioned	0.000029
Royal Australian	0.500000
rules --	0.023256
sounds ,	0.133333
vowels .	0.333333
Named	0.000029
zero ''	1.000000
adverb ,	1.000000
raters	0.000029
adjacent words	0.333333
invented Penicillin	0.500000
predict -RRB-	0.166667
bag of	1.000000
About 90	0.500000
coming between	1.000000
generated summary	0.066667
+ Web-based	0.166667
his method	0.083333
<s> Technologies	0.000769
inflection is	1.000000
-LRB- Style	0.002710
qualities making	0.500000
read the	0.142857
it can	0.051282
corresponding to	0.333333
On	0.000174
soft decisions	0.500000
an optimal	0.007576
Of	0.000029
sold by	0.333333
here ,	0.500000
sets ;	0.090909
title concentrates	1.000000
emergence	0.000029
interaction The	0.125000
reliable sources	0.250000
`` deep	0.005291
robust to	0.250000
individuals	0.000029
on training	0.004717
the news	0.001384
methods to	0.090909
OS	0.000058
summarise	0.000087
implemented by	0.200000
methods	0.001274
lexical segments	0.076923
of Knowledge	0.000891
`` book	0.005291
harder when	0.142857
manually or	0.250000
Aviation	0.000029
implementing a	1.000000
semantics formalization	0.071429
for natural	0.014440
singular common	0.250000
Viterbi	0.000116
As mentioned	0.166667
to this	0.007968
translation was	0.027027
Harris at	0.111111
How ,	0.142857
handwriting ,	0.500000
handwriting .	0.500000
the noun	0.000692
10msec ,	0.500000
into	0.002258
Kurzweil 's	0.142857
domain tends	0.050000
ranks ,	0.500000
semantic equivalence	0.047619
up the	0.045455
span	0.000029
problems Processes	0.058824
Security Agency	1.000000
, weather	0.000561
the effort	0.000692
, Paul	0.001684
User	0.000058
Solving System	0.500000
opens	0.000029
required many	0.142857
smaller ones	0.142857
by resorting	0.005714
1998 Language	0.250000
needed to	0.095238
information retrieval	0.108696
considerable	0.000145
lot more	0.333333
Piron 's	0.333333
that spontaneous	0.003546
nautical context	0.500000
identifying relevant	0.166667
the class	0.000692
<s> require	0.000769
Among these	1.000000
sophisticated NLG	0.142857
will need	0.028571
library ,	0.500000
camp	0.000116
influence	0.000029
diverse	0.000058
in non-Western	0.001873
, combined	0.000561
% still	0.025641
the given	0.001384
meantime ,	1.000000
the APEXC	0.000692
disambiguation concerns	0.100000
learn about	0.076923
season ,	1.000000
Phrases	0.000029
summarise financial	0.333333
vowels and	0.333333
operators need	1.000000
more qualities	0.010526
<s> and	0.000769
: Top-down	0.009804
methodologies	0.000058
algorithm	0.000811
to settle	0.001328
may chose	0.019231
was hoping	0.012987
train	0.000029
social work	0.071429
roadmap of	1.000000
process .	0.138889
process ,	0.027778
give predicted	0.250000
Jim	0.000029
Bolivar	0.000029
<s> Substantial	0.000769
exclamation marks	1.000000
broader	0.000029
the action	0.000692
to move	0.001328
by Environment	0.005714
with ``	0.016393
-- 10	0.040000
resources	0.000174
Johnstone ,	1.000000
situation where	0.500000
account	0.000087
to parse	0.005312
into all	0.012821
document .	0.138889
all these	0.023256
are sometimes	0.004149
easier on	0.125000
human-language question	1.000000
new set	0.041667
the result	0.002768
some invalid	0.012048
video	0.000145
dynamics	0.000058
ARCHILES technique	1.000000
multimedia	0.000058
linguistics Cognitive	0.050000
Campaigns	0.000029
coreference	0.000029
system determine	0.010753
1980s .	0.222222
difficult problem	0.035714
the discourse	0.002076
topic ,	0.250000
improved the	0.250000
under ultraviolet	0.200000
a corresponding	0.001227
Disambiguation	0.000029
survey	0.000029
is devoted	0.002033
makes	0.000232
Category	0.000058
simple bar	0.038462
the robot	0.000692
referenced .	1.000000
complex task	0.041667
to use	0.013280
Sample a	1.000000
those human	0.045455
next	0.000203
e.g. Querying	0.017857
functioning of	0.333333
and not	0.011561
becoming more	1.000000
top-down parsing	0.500000
an active	0.007576
-LRB- like	0.002710
flight displays	0.500000
: Given	0.098039
customer	0.000029
by Junqua	0.005714
integrating	0.000029
lists that	1.000000
unknowns	0.000029
smaller sub-sounds	0.142857
to prune	0.001328
painstakingly	0.000029
process	0.001042
against feature	0.200000
<s> Words	0.001537
be adequately	0.004219
17 ambiguous	1.000000
problem overlaps	0.022727
Mutual Information	1.000000
expanding all	1.000000
bilingual	0.000058
within an	0.055556
intelligent	0.000029
Automatic tagging	0.111111
greatly	0.000203
, according	0.000561
vs. glass-box	0.083333
two meanings	0.034483
highly redundant	0.111111
input devices	0.048780
If the	0.400000
a modal	0.001227
, Carnegie	0.000561
realized	0.000029
speech-to-text processing	0.500000
graph will	0.153846
or Web-based	0.004505
grammars ,	0.142857
`` Did	0.005291
grammars .	0.142857
One	0.000376
see Handwriting	0.050000
other similar	0.014286
higher level	0.142857
models are	0.038462
Tags usually	1.000000
green fire	1.000000
insight	0.000029
in 1997	0.003745
in 1993	0.001873
perfect	0.000029
Current QA	0.200000
a ''	0.001227
of his	0.002674
Technology Integration	0.333333
meantime	0.000029
users with	0.111111
extracting their	0.200000
helicopters ,	0.500000
physicians	0.000029
ratings are	0.222222
is need	0.002033
an 11	0.007576
will ``	0.057143
are analyzed	0.004149
however ,	0.923077
to see	0.002656
stress injuries	0.500000
Talmy	0.000029
robust against	0.250000
these same	0.023810
to set	0.003984
deal of	0.250000
reproducing	0.000029
likely part	0.062500
into machine	0.012821
thought of	0.666667
books	0.000029
people untrained	0.062500
thought or	0.333333
, processing	0.000561
relationships among	0.166667
routed through	0.500000
matrix	0.000029
'	0.000550
an epidemic	0.007576
progress was	0.285714
then using	0.028571
, grammatical	0.000561
do you	0.038462
document before	0.027778
<s> Harris	0.000769
not seen	0.008929
applying some	0.250000
order to	0.571429
mainland	0.000058
modern statistical	0.200000
problem for	0.022727
Robinson ,	1.000000
length	0.000232
true only	0.500000
is routed	0.004065
semantic information	0.095238
related tasks	0.200000
from data	0.019231
learn the	0.076923
and exclamation	0.001445
vendors in	0.250000
but this	0.058824
psychology ,	0.750000
Standardization in	1.000000
Iraq	0.000058
different tongues	0.020408
systems on	0.008929
the learner	0.000692
of triples	0.000891
systems of	0.053571
pauses .	0.250000
write `	1.000000
commonly serve	0.125000
processing part	0.018519
new odd	0.041667
and LexRank	0.004335
many times	0.019231
<s> Potentially	0.000769
data set	0.012987
computer can	0.022727
Discourse analysis	1.000000
left-to-right .	1.000000
, or	0.018529
warped ''	1.000000
of cases	0.000891
Popular speech	1.000000
has used	0.011905
one way	0.015385
divider ,	1.000000
site .	1.000000
, ELIZA	0.001123
OnlineOCR or	0.333333
with attribute	0.005464
to multi-platforms	0.001328
interpreters require	1.000000
to various	0.001328
media such	0.166667
urgent early	1.000000
worldwide	0.000029
Pierce	0.000029
This hierarchy	0.015873
project were	0.076923
insurance bills	1.000000
recognition vary	0.008264
so-called	0.000087
over many	0.083333
placement	0.000029
purely statistical	1.000000
structures in	0.200000
natural and	0.026667
how close	0.034483
original paper	0.076923
i.e. source	0.052632
candidates instead	0.200000
software libraries	0.037037
of high	0.000891
rubric	0.000029
Vauquois '	1.000000
deaf telephony	1.000000
entropy has	0.200000
, follow-the-bouncing-ball	0.000561
maintenance -RRB-	1.000000
entities	0.000203
of internal	0.000891
PageRank selects	0.166667
examples in	0.041667
of oral	0.000891
Racter ,	1.000000
language learning	0.006757
the subject	0.003460
predict performance	0.166667
complex problem	0.041667
reduce acoustic	1.000000
the informativeness	0.000692
and competitions	0.001445
comprising	0.000058
conditions in	0.200000
The success	0.005208
a combination	0.002454
can understand	0.005525
guessing	0.000029
pronoun	0.000029
frame	0.000058
the Medical	0.000692
possible to	0.125000
immediate neighbors	1.000000
possessives into	1.000000
: e.g.	0.019608
error	0.000347
<s> BASEBALL	0.000769
why HMMs	0.142857
Cullingford	0.000029
PC	0.000116
soon become	0.333333
source code	0.041667
input is	0.024390
The unsupervised	0.005208
by their	0.005714
wrote an	0.333333
proper names	0.142857
Sonic Extractor	1.000000
P.	0.000058
More recently	0.111111
a neural	0.001227
Although ,	0.125000
ambiguous .	0.250000
dialogues between	1.000000
Some examples	0.047619
cosine transform	0.333333
other cockpit	0.014286
essentially calculates	0.125000
instead optimize	0.142857
as questions	0.003484
to express	0.001328
genetic	0.000058
the orthography	0.000692
2,663,758	0.000029
-LRB- English	0.002710
speech in	0.013158
important sentences	0.125000
coherence	0.000087
error-prone and	1.000000
and Windows	0.001445
Handel also	1.000000
customers .	0.500000
of marketing	0.000891
Number	0.000029
The United	0.005208
focusing on	1.000000
strength at	0.200000
phrases may	0.062500
networks have	0.071429
boundary disambiguation	0.333333
solve the	0.250000
of images	0.000891
Yehoshua	0.000029
-- or	0.040000
grammars alone	0.071429
, picture	0.000561
-- on	0.040000
be included	0.004219
language into	0.006757
also pioneered	0.014493
is vital	0.002033
research ,	0.071429
research .	0.095238
a watertight	0.001227
identity	0.000116
of structured	0.000891
off	0.000058
, Politics	0.000561
semantics of	0.071429
patterns	0.000145
other non-textual	0.014286
good for	0.076923
sentiment with	0.040000
semantics or	0.142857
was not	0.025974
accuracy and	0.032258
compactly ,	1.000000
Similarly	0.000029
, whereas	0.001123
OCR to	0.061224
is the	0.091463
methods have	0.045455
grammar rules	0.135135
web	0.000232
of document	0.000891
simulation vendors	0.333333
intonation ,	1.000000
start experimenting	0.142857
are accepted	0.004149
parsers which	0.076923
video -RRB-	0.200000
Avionics Research	1.000000
represented as	0.333333
TextRank While	0.071429
well as	0.464286
a product	0.001227
<s> Aided	0.000769
Handwriting	0.000029
possible analyses	0.083333
Leading software	1.000000
then can	0.028571
analysis Genre	0.015385
become	0.000116
two methods	0.034483
are generally	0.016598
Elinor Ochs	1.000000
statistical techniques	0.060606
some classification-related	0.012048
string of	1.000000
developed the	0.153846
process that	0.055556
by trying	0.005714
recognition	0.003503
find a	0.153846
Paul Hopper	0.200000
small set	0.111111
allows for	0.125000
no pauses	0.076923
FoG triggered	0.500000
many strokes	0.019231
post-secondary look	1.000000
it seems	0.008547
the adjacent	0.000692
require a	0.227273
a fashion	0.001227
summarization algorithms	0.020000
blocks worlds	0.250000
letters	0.000290
more compactly	0.010526
written including	0.038462
in one	0.007491
sometimes ambiguous	0.076923
more ,	0.010526
Schiffrin	0.000029
ranked with	0.200000
hand-annotated with	1.000000
on hand-written	0.004717
which itself	0.007246
an RCA	0.015152
then taking	0.028571
, consider	0.000561
a machine	0.008589
Paragraph Structure	1.000000
usually rated	0.031250
are efficient	0.004149
places	0.000058
a Standard	0.001227
now done	0.076923
placed	0.000087
and typically	0.002890
problem	0.001274
Extractive	0.000029
use simple	0.013889
bigram	0.000087
comprehensive theories	0.200000
Lehnert 1981	0.333333
of medical	0.001783
compared	0.000203
details	0.000058
own assumptions	0.166667
correlate with	0.666667
Structure	0.000029
a trillion-word	0.001227
them automatically	0.052632
references ,	0.250000
the strengths	0.000692
non-whitespace	0.000029
least five	0.200000
Corps	0.000058
be further	0.004219
strings	0.000058
tag for	0.062500
the particular	0.001384
searched	0.000058
dialogue with	0.500000
major component	0.083333
or speed	0.004505
NYU	0.000029
TWA where	1.000000
of identifying	0.000891
data sets	0.038961
entropy	0.000145
embedded .	0.250000
classified into	1.000000
reference for	0.125000
worth	0.000058
here there	0.500000
of vertices	0.000891
summarizes	0.000029
`` foreign	0.005291
Amharic and	1.000000
steady accumulation	0.500000
use context-free	0.013889
Military	0.000029
incorrectly causing	1.000000
LILOG projects	0.500000
Then the	0.400000
quantitative evaluation	0.500000
reuse ,	1.000000
forms can	0.166667
Winograd continued	0.333333
D. Das	0.200000
machines	0.000116
Just which	1.000000
's blocks	0.019608
or opinion	0.004505
each unigram	0.044444
, Gender	0.000561
2002 evaluation	0.500000
research groups	0.023810
Brown	0.000405
, French	0.000561
protection	0.000029
vehicle Navigation	1.000000
small knowledge	0.111111
are time-consuming	0.004149
obtained	0.000203
eigenvector centrality	0.500000
the reverse	0.000692
John Pierce	0.125000
work well	0.041667
loss function	1.000000
-- Pointwise	0.040000
encoding world	1.000000
run each	0.200000
removing stopwords	0.500000
of around	0.001783
focused solely	0.090909
Drum printer	1.000000
processing text	0.018519
or aspects	0.004505
document is	0.027778
separated	0.000087
corresponds to	1.000000
of unknown	0.000891
line as	0.333333
includes making	0.142857
ambiguities in	0.250000
1991	0.000087
1990	0.000087
1993	0.000087
1995	0.000029
1994	0.000029
1997	0.000058
1996	0.000029
1999	0.000058
1998	0.000116
the Lander	0.000692
is checking	0.002033
a digital	0.002454
era	0.000029
resources are	0.166667
on unsupervised	0.004717
indicates	0.000029
the complex	0.000692
transducers	0.000029
generated text	0.133333
provide	0.000174
Verbyx	0.000029
random surfer	0.142857
accuracy will	0.032258
the goals	0.000692
very	0.001187
Henry Widdowson	0.500000
text classification	0.006289
8 %	1.000000
earlier in	0.250000
that part-of-speech	0.003546
conclusions .	1.000000
models that	0.115385
Models .	0.333333
overall task	0.166667
Huang etc.	1.000000
a meaningful	0.002454
and later	0.001445
require advanced	0.045455
A semantic	0.020000
1629 ,	1.000000
to distinguish	0.006640
innovative	0.000029
system for	0.021505
those concerning	0.045455
Drew	0.000029
having to	0.200000
at each	0.014706
unless the	1.000000
dependency relations	0.200000
within another	0.055556
failed to	1.000000
process may	0.027778
American English	0.200000
a Markov	0.001227
What learning	0.090909
right-to-left	0.000029
reasonable	0.000058
Anaphora	0.000029
Bible Society	1.000000
the inter-texual	0.000692
clarify a	1.000000
convey .	0.333333
Type	0.000029
creating more	0.142857
information appear	0.021739
`` Apparatus	0.005291
comprehensive knowledge	0.200000
Summarization -RRB-	0.500000
It consists	0.026316
GALE project	1.000000
occurs	0.000087
the EMR	0.000692
also stems	0.014493
detecting	0.000029
observed vector	1.000000
forecasts used	0.200000
some parsing	0.012048
, information	0.001123
: To	0.009804
first raised	0.030303
Manfred	0.000029
, based	0.001123
electronic	0.000058
, maximum	0.000561
the Penpoint	0.000692
where natural	0.028571
US Army	0.142857
machine language	0.037975
approximately	0.000058
technology for	0.090909
CLAWS -LRB-	0.250000
dogs	0.000203
to take	0.006640
A subtask	0.020000
learning -RRB-	0.023256
, despite	0.000561
Japanese prisoner	0.125000
amounts of	1.000000
corresponding systems	0.166667
on each	0.004717
In theory	0.019048
universal language	0.333333
years researchers	0.047619
a grammar	0.002454
and Spanish	0.001445
word-category	0.000029
most important	0.034483
learning such	0.023256
put a	0.250000
historical	0.000029
acoustics	0.000029
25 %	1.000000
used English	0.008850
reading text	0.125000
and worked	0.001445
a stationary	0.002454
performance mainly	0.055556
about 12	0.025000
methodology was	0.500000
Poncini ,	1.000000
contents	0.000029
context to	0.030303
several other	0.045455
in both	0.001873
1987 -LRB-	0.333333
images of	0.333333
terms to	0.076923
subjects	0.000029
page .	0.142857
is called	0.012195
factor .	0.500000
improve machine	0.076923
which has	0.050725
acquire	0.000029
ranking process	0.142857
germane	0.000029
paragraph .	0.333333
which had	0.007246
pollen example	0.076923
been based	0.014706
assessed	0.000029
English-like syntax	0.333333
QA	0.000608
Linguistics -LRB-	0.333333
to adjust\/correct	0.001328
simple world	0.038462
of examples	0.000891
began planning	0.142857
strokes for	1.000000
on-line character	0.333333
signal .	0.166667
it .	0.042735
it ,	0.017094
standards .	0.400000
the accuracy	0.000692
PAM	0.000029
the feature\/aspect-based	0.000692
DCD	0.000029
speech-to-text	0.000058
language-processing	0.000029
degradation	0.000029
topics discussed	0.142857
other structure	0.014286
runs	0.000029
Spoken Language	1.000000
made of	0.187500
been taken	0.014706
but discards	0.014706
ignore this	1.000000
visited and	1.000000
Halliday ,	1.000000
of English	0.002674
for medical	0.003610
discussions	0.000087
is identifying	0.002033
on what	0.009434
among sentences	0.125000
techniques	0.000666
draws	0.000029
pasted	0.000029
away	0.000058
may denote	0.019231
transfer-based ,	0.333333
the parser	0.002768
incomplete sentences	1.000000
drawn	0.000029
too expensive	0.333333
averaged .	1.000000
analysis -LRB-	0.061538
high quality	0.055556
speech Task	0.006579
by Greene	0.005714
and indirect	0.001445
essentially	0.000232
the Mars	0.000692
explicit features	0.200000
word blend	0.016667
after ,	0.083333
because translation	0.033333
phrased in	1.000000
on sentence	0.004717
ASRU .	1.000000
N-best	0.000029
relationship mentions	0.166667
the noise	0.000692
being referred	0.055556
-LRB- grammar	0.002710
Grammar ,	1.000000
strong	0.000116
from 50	0.009615
they all	0.050000
relevant content	0.142857
from mild	0.009615
negative ,	0.125000
The two	0.010417
and on	0.002890
tokens form	0.142857
and of	0.001445
the ANR-Passage	0.000692
Such systems	0.125000
like being	0.035714
and Japanese	0.001445
we might	0.022222
Another good	0.076923
tagging could	0.040000
were very	0.048780
tasks have	0.031250
reader -RRB-	0.100000
example of	0.086420
the individual	0.001384
die or	1.000000
adjectives	0.000087
been devoted	0.014706
earlier some	0.250000
that participate	0.003546
combination of	0.200000
whole .	0.111111
counterparts	0.000029
hand	0.000405
fuse	0.000058
network has	0.166667
whereby	0.000029
<s> QA	0.000769
were started	0.024390
musical	0.000029
non-trivial	0.000058
typical accuracy	0.111111
turns .	0.333333
thanks	0.000029
step and	0.066667
electronically	0.000029
successful finished	0.111111
Constraint Grammar	1.000000
similarities	0.000058
tag-sets .	1.000000
examples produces	0.041667
about specific	0.025000
Future of	0.500000
objective True\/False	0.200000
, answered	0.000561
usable	0.000029
further subdivided	0.125000
can also	0.044199
designers	0.000029
a closed-captioning	0.001227
, POS	0.000561
or worse	0.004505
loud .	1.000000
93-95	0.000029
night	0.000029
parser and	0.062500
remarkably similar	1.000000
matching ,	0.200000
and shallowest	0.001445
useful as	0.071429
and widely	0.001445
bore	0.000029
concept ,	0.250000
the user	0.003460
asking	0.000058
it aimed	0.008547
Many Electronic	0.083333
correspond to	1.000000
individual vertices	0.083333
from United	0.009615
English and	0.081081
F. ,	1.000000
substitution	0.000058
discuss the	1.000000
a limited	0.002454
Hardy ,	1.000000
rule-based translation	0.142857
cards for	1.000000
Statistics are	0.333333
recognition Main	0.008264
the Royal	0.001384
length of	0.250000
profession	0.000029
direct real-world	0.166667
patented and	1.000000
as ``	0.048780
immunology ,	1.000000
-LRB- GPO	0.002710
for multiple	0.003610
flying in	1.000000
isolated words	0.200000
They can	0.333333
with C4	0.005464
keyphrases assigned	0.028571
of reproducing	0.000891
graph specially	0.076923
this vocabulary	0.010989
document 's	0.027778
campaign is	0.200000
human-generated	0.000058
keyphrases can	0.057143
its answer	0.028571
determine ``	0.043478
The recognition	0.005208
guesses	0.000029
request	0.000029
where using	0.028571
technique is	0.142857
path ,	0.500000
guessed	0.000029
expertise	0.000029
characters and	0.062500
and 2009	0.001445
number .	0.046512
features\/aspects ,	1.000000
Commercial applications	0.500000
and 2002	0.001445
and 2007	0.001445
the financial	0.000692
lead-in fighter	1.000000
preclude using	1.000000
test	0.000290
is included	0.002033
first came	0.030303
-LRB- roughly	0.005420
finding the	0.400000
cohesion	0.000029
which simulates	0.007246
government .	0.333333
Gaussians ,	1.000000
the capital	0.001384
concept	0.000116
automatic evaluation	0.130435
the serial	0.000692
conducted until	0.200000
These waves	0.058824
to put	0.002656
particular ,	0.230769
it aims	0.008547
to decoding	0.001328
vs. spontaneous	0.083333
both linguistic	0.032258
process broken	0.027778
: Microsoft	0.009804
compiler due	0.333333
realistic grammars	1.000000
turns	0.000087
2000 ,	0.333333
2000 .	0.333333
, studying	0.000561
shallow-transfer	0.000029
psycholinguistics	0.000058
posed by	0.333333
involves the	0.200000
NLP ranking	0.021277
semitied covariance	1.000000
academic research	1.000000
Neural Network	0.250000
probabilistically at	1.000000
the memory	0.000692
than of	0.022222
Ford	0.000029
that do	0.003546
shared	0.000058
both cases	0.032258
summarization research	0.020000
Some SR	0.047619
often characterised	0.022727
to that	0.002656
a feature	0.002454
remain high	1.000000
answers ,	0.083333
Discursive psychology	1.000000
answers .	0.083333
English	0.001071
message understanding	0.500000
significant momentum	0.111111
still have	0.066667
consisted of	1.000000
sense ,	0.125000
a quantitative	0.002454
Major issues	0.500000
domains	0.000232
isolated-word	0.000029
isloated	0.000029
H. Levinsohn	0.500000
The context	0.005208
regardless	0.000087
Carnegie Mellon	1.000000
often considered	0.022727
Method -RRB-	1.000000
written-out number	1.000000
Call home	1.000000
highly-specialized	0.000029
French ,	0.125000
French .	0.250000
centrality	0.000058
For example	0.622951
using journal	0.016949
as commercial	0.003484
output from	0.038462
known for	0.038462
system that	0.032258
Jacob	0.000029
MPE	0.000029
grammars often	0.071429
semi-supervised ''	0.500000
WordNet	0.000058
that about	0.003546
Each frame	0.166667
determine its	0.086957
specific strengths	0.047619
Throughout	0.000029
challenged and	1.000000
part usually	0.037037
Contains	0.000029
a list	0.008589
occur	0.000145
the completion	0.000692
discussion	0.000058
relies on	1.000000
sub-titling	0.000029
unrealistically	0.000029
would then	0.018868
been annotated	0.014706
captured by	1.000000
product	0.000203
moves ,	1.000000
of most	0.000891
-LRB- discourse	0.002710
a solved	0.002454
produce	0.000637
Martin	0.000058
processors	0.000029
, identify	0.001123
term for	0.166667
being scanned	0.055556
laughter -RRB-	1.000000
, Japanese	0.001123
machine-learning-based	0.000029
serving	0.000029
neural-network	0.000029
Jay	0.000029
and taking	0.001445
Use	0.000058
Jan	0.000029
parsing ambiguous	0.035714
extract sentences	0.250000
still	0.000434
Guy Cook	1.000000
make them	0.050000
cause the	0.500000
from it	0.009615
non	0.000029
The lexer	0.005208
answer reuse	0.033333
Faber	0.000029
May 2012	0.500000
achieved with	0.200000
R.	0.000174
now	0.000376
nor	0.000029
predicting star	0.500000
open-ended questions	1.000000
for French	0.010830
theories in	0.200000
inputting approximately	1.000000
would ,	0.018868
would .	0.018868
`` warped	0.005291
challenged	0.000029
are ,	0.004149
challenges	0.000058
year	0.000174
are :	0.008299
are 9	0.004149
candidate ,	0.333333
since words	0.100000
These methods	0.176471
product or	0.142857
include Single	0.037037
course be	0.333333
dependencies	0.000058
reasoning for	0.142857
is clearly	0.004065
`` fastens	0.005291
devised primarily	0.500000
words accidentally	0.009174
mainland Scotland	1.000000
critical that	0.250000
is critical	0.002033
a relative	0.001227
transition	0.000029
at that	0.014706
Parsing	0.000145
that might	0.007092
Overall organization	1.000000
<s> Searches	0.000769
blind	0.000116
, Steven	0.000561
needed .	0.095238
to encode	0.001328
needed ,	0.047619
converted it	0.333333
The model	0.005208
Response	0.000029
volume ,	0.250000
to learn	0.007968
in rank	0.001873
front door	1.000000
Fournier d'Albe	1.000000
professionals	0.000029
common case	0.040000
that form	0.003546
sophisticated questioners	0.142857
approaches designed	0.035714
well the	0.035714
the sequences	0.000692
different types	0.040816
of very	0.001783
is widely	0.004065
C ,	1.000000
as business	0.003484
from this	0.009615
world -LRB-	0.066667
equipment	0.000087
text ''	0.006289
beginning in	0.500000
Unlike	0.000029
the unwanted	0.000692
, on-line	0.000561
importantly	0.000029
the easier	0.000692
text 's	0.006289
-LRB- such	0.021680
Nielsen automatically	1.000000
complex than	0.083333
implications	0.000029
power resulting	0.250000
Jabberwacky .	1.000000
automatically as	0.047619
Web	0.000261
more severe	0.010526
less uninterrupted	0.083333
outputting one	0.500000
Character	0.000058
NN for	1.000000
step -LRB-	0.066667
interaction Pronunciation	0.125000
training ''	0.035714
this kind	0.010989
suitable -LRB-	0.250000
would require	0.056604
Weizenbaum	0.000087
a consumer	0.001227
regard to	0.800000
the use	0.010381
under the	0.200000
In general	0.028571
boundary	0.000174
libraries GRM	0.500000
, Cynthia	0.000561
a compiler	0.003681
1976 -RRB-	0.500000
important part	0.062500
's GenEx	0.019608
or form	0.004505
, syntactic	0.001684
<s> Statistics	0.002306
EMR	0.000087
tags used	0.333333
lexical	0.000376
or FST	0.004505
rephrase	0.000029
translator that	0.142857
languages concepts	0.020000
Englund -LRB-	1.000000
hurts	0.000058
vibration ,	1.000000
effectiveness .	0.333333
first-cut	0.000029
overcome these	0.500000
not produce	0.008929
50 %	0.666667
unclear whether	1.000000
Unicode	0.000029
are outside	0.004149
that appears	0.003546
different distances	0.020408
others -RRB-	0.083333
the statistics	0.000692
150	0.000058
consider the	0.500000
are grounded	0.008299
exploit	0.000029
improve this	0.153846
domain-specific knowledge	0.500000
150,000 words	1.000000
Then we	0.200000
Pragmatics ,	1.000000
dictator	0.000029
NNS for	1.000000
evaluated to	0.285714
side effect	1.000000
hopes to	1.000000
collection -RRB-	0.200000
mainly with	0.166667
vagueness	0.000029
Languages with	0.333333
science of	0.100000
starts ,	0.500000
a construct	0.001227
finite set	0.200000
criteria ,	0.250000
Speech processing	0.032258
criteria .	0.250000
kept either	1.000000
<s> See	0.000769
metamodel and	1.000000
agree about	0.333333
labels to	1.000000
summaries using	0.023256
metric	0.000087
, a	0.026951
structure is	0.083333
's Mars	0.019608
Pronunciation evaluation	1.000000
develop	0.000145
, G	0.000561
, E	0.000561
, D	0.000561
, C	0.000561
, ^	0.001123
, Z	0.000561
, V	0.000561
during World	0.100000
, P	0.000561
<s> Throughout	0.000769
, +	0.001123
contain strings	0.083333
and found	0.001445
in contrast	0.001873
some topic	0.012048
, 7	0.000561
mathematical framework	0.500000
, 4	0.000561
, 3	0.000561
, 2	0.000561
common for	0.080000
pre-processing e.g.	1.000000
kit '	1.000000
one sentence	0.030769
different ways	0.020408
area of	0.454545
the big	0.000692
Puma	0.000029
Service	0.000029
the mission	0.000692
linked with	0.333333
See Peter	0.166667
larger set	0.062500
of the	0.173797
to pauses	0.001328
be faster	0.004219
HTK book	0.500000
comes mainly	0.200000
was reading	0.012987
were surprisingly	0.024390
versa	0.000029
profession -LRB-	1.000000
good candidates	0.230769
indicate a	0.333333
networks as	0.071429
gonna	0.000029
how air	0.034483
Plot Units	1.000000
<s> Deferred	0.000769
using	0.001708
Incorporating diversity	1.000000
low pollen	0.333333
evident way	0.500000
even the	0.074074
output	0.000753
A shallow	0.040000
, Carmen	0.000561
much through	0.045455
that answered	0.003546
use splicing	0.013889
major corpus	0.083333
verbal	0.000029
contain periods	0.083333
been extended	0.014706
noun in	0.071429
than 98	0.022222
research had	0.047619
greatly improved	0.142857
-RRB- Modern	0.002817
Symantec	0.000058
discriminate keyphrases	0.333333
may have	0.038462
, Racter	0.000561
sentence breaks	0.020833
has proven	0.011905
decided a	0.333333
nuggets	0.000029
, heavy-noise	0.000561
because the	0.133333
problems with	0.058824
easily parsed	0.111111
Approaches Bernard	0.333333
necessarily match	0.500000
POS categories	0.076923
sixty	0.000058
approach 90	0.028571
<s> Precision	0.000769
readers .	0.500000
intent	0.000029
simulated the	0.500000
stationary signal	0.285714
backup	0.000029
left recursion	0.166667
interaction by	0.125000
, shallow	0.000561
procedural information	1.000000
solutions to	0.500000
be known	0.004219
intervention	0.000029
apple is	0.666667
vector .	0.333333
system involves	0.010753
start	0.000203
binary classification	0.500000
described as	0.333333
factor -LRB-	0.500000
will have	0.057143
podcast	0.000029
sets for	0.090909
use\/mention	0.000029
This strategy	0.015873
in ASR	0.003745
largely similar	0.200000
is needed	0.002033
translate more	0.166667
usually creating	0.031250
threshold or	0.500000
planning and	0.500000
Obama ,	1.000000
to names	0.001328
LinguaSys ,	1.000000
where much	0.028571
Veterans	0.000029
is working	0.004065
Annex	0.000029
then end	0.028571
term frequencies	0.055556
poor	0.000029
explicitly mention	0.250000
disassembling and	1.000000
or verb	0.004505
OCR patents	0.020408
endeavors	0.000029
filter preselects	0.500000
continued research	0.222222
boundaries between	0.181818
registry	0.000029
Robotics Speech-to-text	1.000000
from weather	0.009615
test environment	0.100000
available isolated-word	0.058824
they must	0.025000
the software	0.002076
plural noun	0.400000
should be	0.473684
distance ,	0.666667
World Wide	0.571429
semantic	0.000608
installing speech	1.000000
edge if	0.333333
high probability	0.055556
religious	0.000029
captioned telephone	1.000000
While there	0.200000
samples from	0.500000
defined as	0.166667
like English	0.071429
Parliament .	0.500000
, adverb	0.000561
logical form	0.166667
the screen	0.000692
case in	0.058824
This comparison	0.015873
methods work	0.045455
case is	0.058824
decide	0.000116
solve properly	0.250000
we rank	0.022222
chatterbots such	0.500000
which parts	0.007246
dissertation	0.000087
cues	0.000029
, leaving	0.000561
Cognitive Process	0.333333
learner	0.000058
Context-free grammars	1.000000
<s> Initial	0.000769
Chilton	0.000029
phonetic-based categories	1.000000
Intrinsic evaluation	0.333333
clear imaging	0.250000
learned	0.000145
telegraph code	1.000000
can only	0.011050
vocabulary and	0.250000
assertions ,	0.500000
as debates	0.003484
usually measured	0.031250
canned text	0.500000
several teams	0.045455
inspired	0.000029
Vocalizations vary	1.000000
probabilities are	0.090909
diagramming	0.000058
and speech	0.001445
nested one	1.000000
requiring	0.000058
lower than	0.200000
, thereby	0.000561
exist .	1.000000
ask	0.000116
S.	0.000058
translation systems	0.027027
then include	0.028571
information needed	0.021739
train their	1.000000
conventional	0.000029
by other	0.005714
document may	0.055556
advanced ''	0.200000
the historical	0.000692
semantic relationship	0.047619
named entity	0.285714
<s> Back-End	0.000769
many debates	0.019231
lowering	0.000029
considerable variation	0.200000
2009 -RRB-	0.333333
Su	0.000029
user .	0.214286
user ,	0.071429
So	0.000087
simulated a	0.500000
in-principle obstacles	1.000000
producing	0.000087
SR	0.000087
various attempts	0.055556
analysis .	0.092308
EHR .	0.333333
Faber ,	1.000000
Howarth ,	1.000000
Kucera and	1.000000
-RRB- -RRB-	0.005634
dynamics and	0.500000
keyphrases from	0.028571
IBM	0.000087
NLG is	0.095238
classify properly	0.500000
phrase	0.000290
simple	0.000753
Monroe and	1.000000
utilize	0.000058
regression	0.000029
<s> Interactive	0.000769
rather than	0.875000
2 --	0.200000
by larger	0.005714
Schools commonly	1.000000
far northeast	0.250000
horizontal	0.000029
been believed	0.014706
use ``	0.013889
Narrow but	1.000000
, once	0.000561
extractors	0.000029
actioning	0.000029
the waves	0.000692
lower level	0.400000
Latin pars	0.250000
ROUGE-1 scores	0.200000
than when	0.022222
insight into	1.000000
1970 ,	0.333333
which sentences	0.007246
by Pang	0.005714
23 letters	1.000000
output in	0.038462
frequencies -LRB-	0.500000
conversation ,	0.250000
the syntactic	0.000692
laws calling	1.000000
sentences into	0.039474
systems	0.003243
and comprehension	0.001445
phrase that	0.100000
real difference	0.111111
given sequences	0.041667
d'√©valuation de	1.000000
classifier that	0.142857
mark word	0.333333
context data	0.030303
frequently used	0.500000
means that	0.666667
computer-type OCR	1.000000
often much	0.022727
reducing training	0.500000
-LRB- disambiguation	0.002710
to unfamiliar	0.001328
the approach	0.000692
notoriously ,	1.000000
collections ,	0.500000
Wall Street	1.000000
transcribe	0.000029
measured by	0.500000
but the	0.044118
product reviews	0.142857
IMR -RRB-	0.500000
hub ''	1.000000
user can	0.071429
, moves	0.000561
settle	0.000029
safety	0.000029
7	0.000203
sections of	1.000000
of Sydney	0.000891
, commanding	0.000561
n-gram overlaps	0.500000
, results	0.000561
Technology Center	0.333333
Stages	0.000029
closer to	1.000000
trees ,	0.500000
trees .	0.333333
identification is	0.200000
of size	0.000891
and post-secondary	0.001445
compounded by	1.000000
-LRB- usually	0.005420
who used	0.100000
extraction :	0.064516
Handel	0.000029
for quantitatively	0.003610
accurate simply	0.142857
Adda	0.000058
a user-specified	0.001227
a gradually	0.001227
the opportunity	0.000692
parser with	0.062500
When several	0.142857
as natural	0.003484
paragraph boundaries	0.333333
second step	0.200000
de l'assignation	0.500000
as division	0.003484
1914	0.000029
very early	0.024390
signal to	0.166667
as with	0.006969
break sentences	0.500000
the character	0.000692
pragmatics to	0.333333
derive part-of-speech	0.500000
summary sentences	0.023810
in general	0.009363
procedural	0.000029
digital computers	0.142857
are statistical	0.004149
short time	0.125000
randomly	0.000029
gold-standard against	1.000000
Australian Air	0.500000
Training air	0.500000
ASR in	0.500000
Penn	0.000261
several qualities	0.045455
ranking algorithm	0.285714
overall topics	0.166667
specific trade	0.047619
fairly trivial	0.250000
many -LRB-	0.019231
context and	0.121212
an earlier	0.007576
multilingual	0.000087
How many	0.142857
Speaker dependence	0.166667
Typically features	1.000000
or otherwise	0.004505
without inter-word	0.076923
first step	0.060606
disabilities who	0.250000
physics	0.000029
negative or	0.125000
a basis	0.002454
phenomenon	0.000145
about democratizing	0.025000
lot and	0.333333
a basic	0.002454
choices Designing	0.200000
OnStar	0.000029
suggest that	0.333333
areas with	0.333333
French	0.000232
and LR	0.001445
physics that	1.000000
you would	0.076923
be described	0.004219
combinations	0.000029
the literature	0.000692
standard random	0.071429
usually with	0.062500
texts can	0.058824
meet larger	0.250000
lunar science	1.000000
of hyphenation	0.000891
extrinsic ,	0.166667
future tense	0.333333
France	0.000116
culture	0.000029
further research	0.125000
the quality	0.003460
pictures	0.000029
interjection	0.000029
this time	0.032967
ranked	0.000145
rules engine	0.023256
from speech	0.009615
shift-reduce algorithm	1.000000
software technology	0.037037
abruptly	0.000029
<s> Then	0.003843
league	0.000029
Informally ,	1.000000
computational power	0.200000
the OCR-A	0.000692
of which	0.008913
; it	0.021277
foster the	1.000000
<s> They	0.002306
multi-platforms such	1.000000
Flickinger	0.000029
In English	0.019048
output to	0.038462
algorithm -RRB-	0.035714
and left	0.001445
clearly not	0.333333
Question Answering	0.142857
word forms	0.016667
with specialised	0.005464
reviews and	0.166667
many researchers	0.019231
relationship to	0.166667
as simply	0.003484
covariance	0.000058
N	0.000087
heavily inflected	1.000000
as simple	0.006969
<s> Specifically	0.000769
Current	0.000145
different features	0.020408
disturbed by	1.000000
into the	0.102564
carry out	1.000000
guide	0.000058
noun can	0.071429
storm ,	1.000000
2009 to	0.333333
shift positions	1.000000
costly	0.000029
parser generators	0.062500
Interlingual Main	0.333333
user are	0.071429
Eagles	0.000029
text-to-speech	0.000116
can effectively	0.005525
Keyphrase extraction	0.500000
, grammar	0.000561
most sense	0.017241
http:\/\/haydn.isi.edu\/ROUGE\/	0.000029
maximum mutual	0.166667
`` Part-of-speech	0.005291
extent of	0.250000
language have	0.006757
`` still	0.005291
, OnStar	0.000561
that machine	0.010638
students ,	0.333333
, abstracts	0.000561
`` recommending	0.005291
reviewed	0.000029
Many real	0.083333
term ,	0.055556
learning and	0.023256
<s> He	0.005380
questioner	0.000116
coarticulation	0.000029
informal	0.000058
pseudo-pilot ,	0.500000
-LRB- closer	0.002710
typically the	0.055556
questioned	0.000029
needs the	0.100000
Lancaster-Oslo-Bergen Corpus	1.000000
of taking	0.000891
and Command	0.001445
showing	0.000058
Winograd was	0.333333
`` supervised	0.026455
DOE	0.000029
EMR -RRB-	0.333333
phoneme classification	0.500000
very likely	0.024390
Robyn	0.000029
demonstrated at	1.000000
popular	0.000261
Orleans ''	0.500000
part may	0.037037
DARPA -RRB-	0.250000
systems have	0.044643
published in	0.142857
a sequence	0.007362
greatly affect	0.142857
<s> Mention	0.000769
Blommaert ,	1.000000
incorporate logical	1.000000
classifier module	0.142857
decade ,	0.333333
semantic theories	0.047619
informational content	0.500000
competitions	0.000029
continuous text	0.166667
financial message	0.250000
approaches Supervised	0.035714
7 distinct	0.142857
an approximation	0.015152
PageRank to	0.333333
background noise	0.333333
non-textual components	1.000000
drawback of	1.000000
a collect	0.001227
normal speech	0.500000
processing techniques	0.037037
significant -RRB-	0.111111
task also	0.023810
the success	0.001384
application for	0.071429
word pronunciations	0.016667
Norman	0.000058
various types	0.111111
2011 -RRB-	0.500000
which various	0.007246
Such algorithms	0.125000
characters .	0.125000
Chantal Mouffe	1.000000
settle on	1.000000
dictates into	1.000000
would only	0.018868
parse trees	0.222222
sophisticated measures	0.142857
her judgement	0.500000
Information extraction	0.200000
as overall	0.003484
`` Turn	0.005291
F35 Lightning	1.000000
similar	0.000782
faces a	1.000000
Gdaniec C.	1.000000
in research	0.001873
accessibility	0.000029
To	0.000261
special challenges	0.200000
is about	0.002033
cases -LRB-	0.055556
in Japanese	0.001873
hand or	0.142857
amounts	0.000058
hands ,	1.000000
also prefer	0.014493
application	0.000405
do so	0.038462
department	0.000058
for machine	0.010830
arithmetic	0.000029
hour or	1.000000
Stanford	0.000058
additional clues	0.166667
such ambiguity	0.024390
Corpus Research	0.062500
will determine	0.028571
Open-domain question	1.000000
complicating	0.000029
svg	0.000029
Separate a	0.500000
typical parser	0.111111
the earliest	0.000692
allowing us	0.333333
by Turney	0.005714
has fueled	0.011905
evaluation technique	0.018519
, quite	0.000561
, where	0.008422
real-world examples	0.166667
Methods such	0.250000
abstracts or	0.500000
typically how	0.055556
of costly	0.000891
wave	0.000261
overfitting and	0.500000
The result	0.005208
have so-called	0.009615
single datum	0.071429
positions	0.000029
rapid access	1.000000
, social	0.001123
ambiguity .	0.125000
approach for	0.028571
Substantial efforts	0.500000
`` barmaid	0.010582
2004 -RRB-	0.333333
caught '	1.000000
of all	0.003565
choose different	0.500000
the Armed	0.000692
U.S. has	0.142857
is felt	0.002033
almost no	1.000000
original scanned	0.076923
statically beforehand	1.000000
Like keyphrase	0.500000
dialog with	0.500000
examples have	0.041667
assumption -LRB-	0.500000
dynamically creating	0.500000
Deferred	0.000029
computer gaming	0.022727
protect New	1.000000
, machine-aided	0.000561
all official	0.023256
Treebank Project	0.166667
resulting in	0.250000
TaleSpin -LRB-	1.000000
, beyond	0.000561
extent to	0.250000
As described	0.055556
sound in	0.050000
patents	0.000029
presented with	0.166667
often of	0.022727
a recall-based	0.001227
Automotive speech	1.000000
used by	0.079646
manage	0.000029
Europe began	0.200000
using general	0.016949
Lisp hence	1.000000
An increasing	0.062500
entropy classifier	0.200000
camera	0.000058
-RRB- HMMs	0.002817
Advanced applications	0.200000
historically	0.000058
formally	0.000058
the trainee	0.000692
the co-occurrence	0.000692
: Translation	0.009804
recognition -LRB-	0.049587
term language	0.055556
boundaries are	0.090909
1990 dissertation	0.333333
select ``	0.166667
prisoner-of-war	0.000029
a case	0.001227
averaged	0.000029
useful in	0.142857
meet	0.000116
arranged hierarchically	1.000000
Mr.	0.000058
-LRB- WER	0.002710
grammars -LRB-	0.071429
request can	1.000000
defective	0.000058
sentiments	0.000029
systems perform	0.008929
functions .	0.500000
but was	0.014706
a year	0.001227
a filter	0.001227
elements of	0.250000
be thousands	0.004219
keyphrase extraction	0.631579
encyclopedia	0.000029
contents of	1.000000
word error	0.016667
trigram ,	0.666667
right context	0.100000
, Harrison	0.000561
types including	0.071429
data rather	0.012987
attribute or	0.500000
including	0.000405
general-purpose speech	1.000000
RAF	0.000029
Canada .	0.166667
RAE	0.000029
is unable	0.002033
NYU ,	1.000000
temporal	0.000058
searched ,	1.000000
Flow of	1.000000
state transducer	0.142857
of new	0.000891
target handover	0.090909
MCE -RRB-	1.000000
source for	0.041667
articulation	0.000029
Two	0.000203
Duranti	0.000029
the application	0.000692
VOLSUNGA	0.000029
`` set	0.005291
Treebank	0.000174
ranks the	0.500000
not found	0.008929
for top-down	0.003610
slide	0.000029
extractor might	0.500000
mechanisms ,	0.500000
such phrases	0.008130
NLP .	0.106383
would probably	0.018868
NLP ,	0.021277
Postal Service	1.000000
Statistics	0.000087
Ideally	0.000058
rates can	0.125000
and semantic	0.004335
a voice	0.001227
OCR	0.001419
as CLAWS	0.003484
special	0.000145
problem ,	0.090909
problem .	0.227273
answer temporal	0.033333
problem because	0.022727
dogs the	0.142857
` discourse	0.062500
book-new .	1.000000
the speakers	0.000692
cause	0.000058
popular ``	0.111111
been previously	0.014706
in all	0.005618
rarely successful	0.333333
determining	0.000174
times	0.000145
a company	0.001227
models .	0.115385
models ,	0.076923
` the	0.062500
post -	1.000000
HMMs ,	0.125000
powerful	0.000029
brought together	1.000000
<s> After	0.002306
Wikipedia and	0.500000
recognition programs	0.008264
now more	0.076923
a campaign	0.001227
improve recognition	0.153846
assist human	1.000000
accepts a	0.500000
lists	0.000029
a text	0.017178
summarization in	0.040000
summarization is	0.120000
for testing	0.003610
Peru .	0.500000
descriptions	0.000029
Blind -LRB-	0.500000
current major	0.142857
Other	0.000203
, adverbs	0.000561
describe the	0.333333
effort .	0.250000
effort ,	0.250000
when moved	0.028571
whether to	0.076923
domain-independent and	1.000000
about nearly	0.025000
documents -LRB-	0.131579
In speech	0.009524
intrinsic	0.000116
, displayed	0.000561
an underlying	0.007576
considerably from	1.000000
lexicons -LRB-	0.500000
weights equal	0.200000
Writing -RRB-	1.000000
essentially identical	0.125000
continued development	0.111111
, paragraphs	0.000561
of contextual	0.000891
create summaries	0.058824
the Technolangue\/Easy	0.000692
utilize large	0.500000
C4 .5	1.000000
Aviation Authorities	1.000000
as BLEU	0.003484
for both	0.003610
addressee at	1.000000
Measuring progress	1.000000
achieve	0.000058
more recent	0.010526
new complex	0.041667
morphosyntactic descriptor	1.000000
to rank	0.003984
other potential	0.014286
until 1970	0.500000
for innumerable	0.003610
tuned	0.000029
as normalization	0.003484
Austrian	0.000029
of recognition	0.001783
multiplying	0.000029
Aggregation :	1.000000
up for	0.090909
operated	0.000058
hand-printed characters	0.250000
-LRB- IMR	0.002710
tend	0.000058
studies of	0.250000
derivation and	0.250000
and wrote	0.001445
, relay	0.000561
would contain	0.018868
indiscriminate	0.000029
produce vowels	0.045455
test example	0.100000
key	0.000174
hits	0.000029
limits	0.000029
to unigram	0.001328
article contains	0.034483
ushered in	1.000000
estimation	0.000029
a deep	0.001227
different realizations	0.020408
relevance assessment	0.333333
Artificial	0.000058
may appear	0.019231
the so-called	0.000692
substantial ambiguity	0.200000
Braille texts	1.000000
essentially they	0.125000
<s> Once	0.003843
teams in	0.500000
controlled	0.000029
its understanding	0.028571
as weights	0.003484
sound clip	0.100000
controller	0.000116
If a	0.100000
Inclusive	0.000029
single speaker	0.071429
The successful	0.005208
printed page	0.083333
considers the	0.500000
complexity ,	0.166667
forms .	0.166667
far more	0.250000
be output	0.004219
We then	0.142857
open letter	0.250000
that we	0.010638
from that	0.009615
picture on	0.250000
problem than	0.022727
classification ,	0.058824
classification .	0.117647
is generally	0.002033
rules through	0.023256
directly to	0.400000
computer-aided	0.000087
parts	0.000463
speaker	0.000521
series of	0.875000
Types	0.000058
Use ''	0.500000
called machine	0.055556
best to	0.111111
, Janet	0.000561
Intrinsic vs.	0.333333
several alternative	0.045455
been closely	0.014706
off as	0.500000
business letters	0.250000
some of	0.156627
features might	0.038462
which could	0.007246
In 2002	0.009524
In 2006	0.009524
but we	0.014706
In 2004	0.009524
increasingly	0.000087
a 70	0.001227
discors	0.000029
distant	0.000029
by teletype	0.005714
-RRB- Parsing	0.002817
generate examples	0.055556
perhaps by	0.166667
the Eagles	0.000692
, ranging	0.001123
programmed by	0.500000
might vary	0.038462
headed	0.000029
disambiguation :	0.100000
an advanced	0.007576
disambiguation ,	0.100000
different angle	0.020408
disambiguation .	0.100000
, Case	0.000561
Nelson	0.000029
ease interoperability	1.000000
recently updated	0.333333
or existing	0.004505
loss	0.000058
necessary	0.000290
and intra-texual	0.001445
appends	0.000029
and identify	0.002890
payments	0.000029
in color	0.001873
generation of	0.111111
, approach	0.000561
be made	0.016878
International continued	1.000000
how summarization	0.034483
library	0.000058
Arabic in	0.250000
usually can	0.031250
Translation ''	0.333333
of domain	0.000891
home	0.000029
development in	0.083333
quantitatively comparing	1.000000
had the	0.071429
broad	0.000116
slide represent	1.000000
overlap	0.000116
knowledge and	0.074074
getting enough	0.250000
demonstrated	0.000029
the '	0.000692
real-world	0.000174
the .	0.000692
Up	0.000029
described	0.000174
between them	0.051282
air traffic	0.600000
Archaeology	0.000029
fluency to	1.000000
in specific	0.003745
to its	0.001328
diversity :	0.250000
etc. ;	0.045455
that use	0.007092
when writing	0.057143
US	0.000203
are designed	0.004149
etc. .	0.409091
etc. ,	0.045455
: lessons	0.009804
UK	0.000116
still contains	0.066667
that output	0.003546
UC	0.000058
of allowing	0.000891
previously	0.000058
whereas speed	0.333333
nets .	1.000000
SVOX	0.000029
video sub-titling	0.200000
of artifacts	0.000891
on his	0.004717
sense of	0.125000
or more	0.018018
language metamodel	0.006757
words being	0.009174
1950s included	0.250000
with which	0.005464
, read	0.001123
distribution of	0.250000
even languages	0.037037
and are	0.007225
highest	0.000087
against noise	0.200000
will approach	0.028571
are those	0.004149
single character	0.071429
that transcended	0.003546
multi-word phrases	1.000000
display	0.000058
used about	0.008850
A technique	0.020000
system working	0.010753
universal	0.000087
pre-structured	0.000029
the sort	0.000692
education	0.000029
platforms .	1.000000
1956 and	1.000000
functions	0.000058
the ambiguity	0.000692
The Association	0.005208
same way	0.040000
star	0.000058
EMNLP ,	1.000000
recursively defines	0.500000
additionally	0.000029
, and\/or	0.000561
by Naomi	0.005714
role of	0.250000
<s> Question	0.003843
pronunciations or	1.000000
15-20	0.000029
the evaluation	0.003460
turn requires	0.166667
might generate	0.038462
general ,	0.272727
, support	0.000561
consists	0.000058
entire words	0.333333
from closely	0.009615
speech-enabled	0.000029
human languages	0.021739
function either	0.125000
of reasoned	0.000891
management task	0.142857
cursive characters	0.200000
Digitize	0.000029
This convinced	0.015873
Conversational	0.000029
grammars of	0.071429
robot in	0.500000
has unambiguously	0.011905
its entirety	0.028571
which kind	0.007246
telephone speech	0.500000
but may	0.029412
Hopper	0.000029
Keyphrase Extraction	0.250000
enhance	0.000029
department ,	0.500000
set a	0.051282
of generating	0.000891
nonexistent in	1.000000
<s> Evaluation	0.003843
turn simplified	0.166667
of heuristics	0.000891
likely	0.000463
more unmanageable	0.010526
note is	1.000000
language processing	0.222973
indicating important	1.000000
<s> Few	0.000769
Information Science	0.200000
this particular	0.010989
poorly	0.000029
describing graphs	0.250000
set ,	0.051282
with disabilities	0.010929
to natural	0.001328
as separate	0.003484
interfaces Symantec	0.500000
's Stilstudien	0.019608
worlds ''	1.000000
identify ambiguities	0.083333
, have	0.001123
specific person	0.047619
is extremely	0.004065
each whole	0.022222
Open-domain	0.000029
letters are	0.100000
WebOCR &	0.750000
was demonstrated	0.012987
Constraints may	0.333333
the operation	0.000692
thus be	0.100000
whether the	0.153846
of different	0.001783
have made	0.009615
various ways	0.111111
to accurately	0.001328
`` depth	0.005291
room	0.000029
navigation ,	0.500000
feature or	0.076923
movies	0.000029
Fournier	0.000029
feature of	0.230769
we want	0.044444
that interact	0.003546
in 1949	0.001873
exceptions	0.000029
little interference	0.333333
and 1957	0.001445
forth .	1.000000
Corporation	0.000116
implementations	0.000058
10,000	0.000029
the learning	0.000692
: Determine	0.009804
linear representation	0.142857
centres require	1.000000
sad ,	1.000000
relevant .	0.142857
group of	0.500000
production when	0.333333
not accommodate	0.017857
human beings	0.021739
four steps	0.142857
document\/text genre	0.500000
and Haton	0.001445
you can	0.153846
E ,	1.000000
unverified or	1.000000
<s> Adverse	0.000769
operate	0.000029
which ,	0.007246
specific tasks	0.047619
, time	0.000561
or 4-gram	0.004505
defined in	0.166667
which ?	0.007246
its designers	0.028571
words and	0.064220
before	0.000174
personal	0.000116
and maximum	0.001445
grammar is	0.054054
grammar in	0.027027
concerning coherence	1.000000
system-generated	0.000058
Engineers ,	0.500000
summarization and	0.020000
combination	0.000145
Royal	0.000058
which a	0.014493
Arabic ,	0.250000
that should	0.007092
<s> IBM	0.000769
Windows Mobile	1.000000
concept into	0.250000
typewritten messages	0.200000
not become	0.008929
networks Neural	0.071429
clauses	0.000029
on corpora	0.004717
two enabling	0.034483
its suitability	0.028571
open	0.000116
testing .	0.200000
if one	0.035714
source can	0.041667
HMMs learn	0.125000
2004 ,	0.333333
2004 .	0.333333
larger sequences	0.062500
hard and	0.166667
interaction Genres	0.125000
together the	0.125000
with restricted	0.005464
-- only	0.040000
software Desktop	0.037037
software is	0.074074
of 5	0.000891
of 4	0.001783
of 3	0.000891
of 1	0.000891
would contribute	0.018868
Ncmsan	0.000029
powerful grammars	1.000000
individual characters	0.083333
cares about	1.000000
OCR systems	0.081633
Transactions on	1.000000
of a	0.081996
resource management	0.400000
Army ,	0.250000
paradigm of	0.333333
data about	0.012987
Shepard	0.000087
type is	0.142857
of N	0.000891
evaluation procedures	0.018519
program that	0.090909
more time-consuming	0.010526
, the	0.058394
and translation	0.004335
light .	0.333333
facing more	1.000000
of selecting	0.000891
discussed between	0.142857
the helicopter	0.002076
automatically learn	0.095238
problem in	0.090909
`` What	0.015873
phonemes is	0.166667
States Postal	0.142857
Shepard ,	0.333333
are good	0.004149
Gripen	0.000029
phonemes in	0.166667
its polarity	0.028571
split ,	0.250000
problem is	0.113636
States and	0.142857
should vertices	0.052632
which occur	0.007246
. .	0.062500
summaries -RRB-	0.023256
32 -RRB-	1.000000
as semiotics	0.003484
all four	0.023256
observation	0.000029
and pragmatics	0.001445
discussed above	0.142857
printed messages	0.083333
purpose of	0.200000
of 98	0.000891
of possibilities	0.000891
an interest	0.007576
in depth	0.001873
part-of-speech assignment	0.066667
timing for	1.000000
northeast	0.000058
of incorrect	0.000891
direct and	0.166667
we normally	0.022222
always the	0.333333
generally lend	0.090909
, hopefully	0.000561
a leftmost	0.002454
was nearly	0.012987
merges highly	1.000000
problem yet	0.022727
<s> Helicopters	0.000769
to refer	0.001328
recursive-descent parser	1.000000
each character	0.022222
, perhaps	0.001684
linguistic term	0.062500
distant from	1.000000
sailor dogs	0.200000
ears	0.000029
hand-crafted	0.000058
automate sentiment	0.333333
particular method	0.076923
Many of	0.166667
are needed	0.004149
<s> ‚Üí	0.000769
a highly	0.001227
artificial	0.000318
and classification	0.001445
which generate	0.021739
improved computer	0.250000
the type	0.002768
some work	0.012048
of research	0.007130
Stephen H.	1.000000
a dog	0.001227
Unix operating	0.500000
that merges	0.003546
provides for	0.500000
coherent and	0.200000
McDonald	0.000029
2012 -RRB-	1.000000
Evaluating summaries	1.000000
Emanuel Schegloff	0.500000
verifiability .	1.000000
good insight	0.076923
remains to	0.250000
marketing .	1.000000
-LRB- CSIS	0.002710
and Plot	0.001445
, humans	0.000561
1952 .	0.500000
such capabilities	0.008130
some sort	0.012048
Vocabulary	0.000087
basis	0.000174
to estimate	0.003984
Chinese ,	0.285714
David H.	0.250000
often argued	0.022727
objects .	0.200000
MorphoChallenge Semi-supervised	1.000000
interest	0.000318
basic	0.000376
As an	0.111111
entered	0.000058
dismiss	0.000029
Flow	0.000029
this sentence	0.010989
Intelligence Corporation	0.333333
Voice	0.000145
correct values	0.066667
morphemes -LRB-	0.333333
Process	0.000029
Robert E.	0.500000
because of	0.200000
such statistical	0.008130
results reported	0.047619
Some classifiers	0.047619
deciding to	0.333333
weapon critical	0.500000
track	0.000029
time-scales	0.000029
<s> Why	0.001537
have some	0.009615
meets	0.000058
methods assess	0.022727
communication Pragmatics	0.200000
whether each	0.076923
beyond polarity	0.166667
an online	0.007576
≈çrƒÅti≈çnis	0.000029
any significant	0.032258
programs	0.000318
which entertaining	0.007246
sequences are	0.111111
The target	0.005208
features indicating	0.038462
2500 articles	1.000000
one to	0.030769
even if	0.111111
even in	0.074074
approaches the	0.035714
assigned	0.000058
requires humans	0.062500
or meets	0.004505
written ,	0.038462
other we	0.014286
readability and	1.000000
was declared	0.012987
without intervening	0.076923
yet	0.000058
In part-of-speech	0.009524
-LRB- unigram	0.002710
more quickly	0.010526
field since	0.037037
than instances	0.022222
text unit	0.006289
NLG system	0.095238
save	0.000029
David Nunan	0.250000
Sager	0.000058
other 10	0.014286
Pollen	0.000029
Art	0.000029
c -RRB-	1.000000
as social	0.003484
by Makoto	0.005714
Are	0.000029
-LRB- written	0.002710
deal	0.000116
Accuracy rates	0.285714
Grant ever	1.000000
somehow	0.000029
over most	0.083333
input gracefully	0.024390
linguistic rules	0.062500
weather data	0.142857
The rise	0.005208
translation requires	0.013514
, Kurzweil	0.001684
although not	0.166667
and controlling	0.001445
from context	0.009615
often mentioned	0.022727
normal human	0.500000
predicting	0.000058
with either	0.005464
left recursive	0.166667
in an	0.014981
education ,	1.000000
-LRB- Pallet	0.002710
sets in	0.090909
magazine	0.000029
for machine-translation	0.003610
automatically	0.000608
NLP as	0.021277
Little	0.000029
the object	0.000692
1966 -RRB-	0.333333
refined	0.000029
-LRB- AVRADA	0.002710
anaphora	0.000029
1964 to	1.000000
does n't	0.100000
some NLP	0.012048
initial	0.000087
use `	0.013889
HMMs -RRB-	0.250000
walking more	0.333333
editor	0.000029
fraction	0.000029
When we	0.142857
Italy ,	1.000000
evaluated using	0.142857
January	0.000116
on which	0.014151
even level	0.037037
, NAACL	0.000561
and non-annotated	0.001445
analyst	0.000029
not sound	0.008929
use ,	0.055556
use .	0.041667
at helping	0.014706
distinguished .	1.000000
Independence :	1.000000
over a	0.083333
not have	0.017857
summary by	0.023810
algorithm As	0.035714
major issues	0.083333
agrees with	1.000000
discourse ,	0.083333
discourse .	0.027778
basics and	1.000000
marking	0.000058
not as	0.008929
, George	0.000561
out of	0.071429
documents ,	0.236842
not an	0.008929
Word segmentation	0.142857
outside world	0.500000
Mobile Smartphones	0.333333
be identified	0.008439
an attempt	0.022727
-LRB- citation	0.035230
copying important	1.000000
, will	0.001123
cases --	0.055556
morphological ,	0.333333
match each	0.166667
following ``	0.066667
a mixture	0.001227
delimited .	0.250000
located anywhere	1.000000
delimited ,	0.500000
emotional states	0.250000
make `	0.050000
make a	0.200000
organization -RRB-	0.200000
are difficult	0.004149
Austrian emigre	1.000000
adviser	0.000029
make ;	0.050000
In some	0.038095
voices or	1.000000
is searched	0.002033
, slowly	0.000561
fighter environment	0.166667
summarization methods	0.020000
display for	0.500000
those utility	0.045455
article and	0.068966
'' tag	0.005376
Abney S.	1.000000
signal is	0.166667
going over	0.250000
and merging	0.001445
unexpected	0.000029
A useful	0.020000
dealing	0.000058
speech processing	0.006579
A.C. Nielsen	1.000000
targets	0.000029
performs	0.000029
Tagset ''	1.000000
Syntactic ;	1.000000
Black-box evaluation	0.500000
international	0.000058
while others	0.200000
, made	0.001123
too -RRB-	0.166667
, up	0.000561
merely	0.000058
is that	0.024390
computer program	0.113636
hierarchically	0.000029
Schank	0.000145
its best	0.028571
and statistics	0.002890
in question	0.003745
marks and	0.250000
automatic summary	0.086957
translation has	0.027027
and recursive-descent	0.001445
of small	0.000891
languages -RRB-	0.040000
form multi-word	0.050000
sample is	0.333333
of triple	0.000891
trained hidden	0.333333
real-world information	0.166667
For most	0.016393
quoting	0.000029
summaries can	0.046512
making	0.000203
Abney	0.000029
abbreviation ,	0.500000
inherent expressivity	1.000000
is sufficient	0.004065
in errata	0.001873
brain is	0.333333
Black-box vs.	0.500000
sample	0.000087
to program	0.001328
language interaction	0.006757
approximate meaning	0.500000
feedback .	0.500000
computer vision	0.022727
SR systems	0.333333
, morphology	0.001123
persuasion	0.000029
consumer ,	1.000000
and reporting	0.001445
UC -RRB-	0.500000
hitcha	0.000029
evaluation looks	0.018519
prior ranking	0.333333
noun	0.000405
absorbing states	0.333333
In one	0.009524
Software OCR	0.500000
an interlingual	0.007576
developed a	0.115385
can select	0.005525
group	0.000116
Jelinek	0.000058
of overlap	0.000891
listed on	1.000000
natural languages	0.120000
visible light	0.333333
the spectrum	0.000692
waves that	0.142857
developed .	0.076923
weather reports	0.285714
E. Longacre	0.500000
very sophisticated	0.024390
7 in	0.285714
recorded speech	0.500000
workload	0.000029
individual speaker	0.083333
specialized output	0.500000
the vagueness	0.000692
concept is	0.250000
bridging	0.000029
performs simple	1.000000
` beyond	0.062500
of listening	0.000891
Civil Aviation	1.000000
of various	0.000891
feasible to	0.500000
Ken	0.000029
never went	0.200000
data for	0.012987
lowering of	1.000000
as ACL	0.003484
multi-platforms	0.000029
algorithm implicitly	0.035714
the functioning	0.000692
or other	0.009009
Sometimes	0.000029
the English	0.002076
assessing whether	1.000000
second ;	0.100000
Question classes	0.285714
Relevance -LRB-	1.000000
system whereby	0.010753
thus speech	0.100000
generic machine-generated	0.333333
first	0.000955
-RRB- had	0.002817
a sentence	0.017178
or real	0.004505
this graph	0.010989
grammatical contexts	0.090909
Black	0.000058
summarizing multiple	1.000000
on different	0.004717
not typically	0.017857
often quoted	0.022727
MLLR -RRB-	1.000000
speaking	0.000232
department in	0.500000
sailor ''	0.400000
segmentation process	0.030303
co-articulation of	1.000000
routing to	0.333333
1995 -RRB-	1.000000
BioCreative	0.000029
Recognizing the	1.000000
of entities	0.000891
... .	0.500000
other words	0.028571
shared concepts	0.500000
study based	0.250000
has turned	0.011905
specific context	0.047619
Current machine	0.200000
meanings according	0.250000
mining of	0.200000
The more	0.005208
next item	0.142857
Dr. Kenneth	1.000000
1950s by	0.250000
performance	0.000521
characters for	0.062500
200	0.000058
LinguaSys	0.000029
written scripts	0.038462
attractive acoustic	0.333333
Data sources	1.000000
<s> Search	0.001537
limited in	0.100000
needs additional	0.100000
of artificial	0.000891
'' all	0.005376
as PC	0.003484
document production	0.027778
: Translations	0.009804
easy to	1.000000
Individuals	0.000029
unknown and	1.000000
the Annual	0.000692
markers over	0.333333
matching up	0.200000
, Reader	0.000561
3 ''	0.200000
weighted by	0.333333
Stephen	0.000029
We	0.000203
Piron	0.000087
portable .	0.333333
portable ,	0.333333
be ranked	0.004219
person\/persons	0.000029
get	0.000203
personal computer	0.250000
converting printed	0.500000
the Morpholympics	0.000692
W.	0.000058
Eugene Charniak	1.000000
Stylistics	0.000029
and built	0.001445
often contains	0.022727
Grant	0.000029
Stylistics -LRB-	1.000000
Turn around	1.000000
Each concept	0.166667
citations for	0.333333
the larger	0.000692
human summary	0.021739
label	0.000029
boundaries	0.000318
enough	0.000145
generate .	0.055556
GRASSHOPPER algorithm	0.333333
measure based	0.090909
across	0.000145
the SR	0.000692
has increased	0.011905
run on	0.200000
five different	0.200000
Each	0.000174
approach to	0.171429
engineers worked	1.000000
have problems	0.009615
output with	0.038462
low agreement	0.333333
Statistical	0.000261
there is	0.350000
among	0.000232
with other	0.005464
error types	0.083333
practice ,	0.500000
complicated statistical	0.333333
ones that	0.100000
an email	0.007576
capable	0.000058
Turing	0.000058
a semantic	0.001227
attaching	0.000058
Optical	0.000087
Birkbeck College	1.000000
voice has	0.076923
declaration	0.000029
: Creating	0.019608
, error-prone	0.000561
^	0.000087
sound	0.000579
PageRank\/TextRank on	1.000000
A word	0.020000
matter .	0.333333
Machine Summarization	0.111111
large-vocabulary system	0.333333
paper skew	0.090909
techniques fall	0.043478
with pilots	0.005464
abstract synopsis	1.000000
for multi-document	0.003610
for many	0.007220
<s> Anaphora	0.000769
than others	0.044444
IEEE	0.000087
a distinction	0.001227
<s> Moreover	0.003075
A year	0.020000
vocabulary size	0.125000
`` ask	0.005291
the number	0.004844
speech attached	0.006579
extended	0.000029
assist	0.000029
parse garden-path	0.111111
a choice	0.001227
that when	0.003546
i.e. ,	0.368421
identifiers	0.000029
other commercial	0.014286
directly comparable	0.200000
consisted	0.000029
stock .	0.666667
children 's	0.500000
computed as	0.500000
a supervised	0.002454
syntactic structure	0.076923
by providing	0.005714
eigenvalue	0.000029
most widely	0.017241
content words	0.083333
lexical analyser	0.076923
and character	0.001445
analysts This	0.500000
RCA product	0.200000
input such	0.024390
identifying	0.000174
QA The	0.047619
Biden	0.000087
Eurofighter Typhoon	1.000000
would thus	0.018868
Moreover	0.000116
Digest	0.000087
a finite	0.002454
probabilistic and	0.142857
including sentiment	0.071429
psychotherapist ,	1.000000
images	0.000174
to accommodate	0.002656
Smith went	1.000000
the continuously	0.000692
1991 -RRB-	0.666667
shortened version	1.000000
AI	0.000087
Palm OS	1.000000
Claude Piron	1.000000
<s> Training	0.000769
grammar which	0.054054
English-like sentences	0.333333
machine to	0.012658
mentions ''	0.333333
sequences -LRB-	0.111111
news article	0.153846
affect is	0.333333
allowable substitutions	0.500000
while the	0.050000
sometimes suggest	0.076923
reverse process	0.500000
are claiming	0.004149
more probabilistic	0.010526
distinctions are	0.500000
word-frequency and	1.000000
evaluation tests	0.037037
skilled	0.000029
and easily	0.001445
no significant	0.076923
those of	0.045455
has increasingly	0.011905
first mechanized	0.030303
computer-aided analysis	0.333333
filter returns	0.500000
probabilities would	0.090909
barmaid ''	0.333333
workshops ,	0.500000
length using	0.125000
to limit	0.002656
the IEEE	0.001384
arranged	0.000029
different sentences	0.061224
one instance	0.015385
day did	1.000000
could just	0.062500
than by	0.022222
Stubbs	0.000029
online news	0.125000
again	0.000029
contextual or	0.500000
dramatically reduced	1.000000
are vulnerable	0.004149
measurement of	0.500000
towards this	1.000000
% .	0.230769
of global	0.000891
% ,	0.051282
‚Üê barmaid	1.000000
recognition task	0.016529
a chunk	0.007362
% ;	0.025641
J. Phillips	0.333333
that had	0.003546
same meaning	0.040000
requires	0.000463
Size Grows	1.000000
that has	0.021277
, online	0.001684
founder	0.000029
, encoding	0.000561
Norval	0.000029
processing would	0.018519
is computed	0.002033
people 's	0.062500
expressions	0.000087
humans ,	0.166667
upon which	1.000000
period may	0.500000
optimistic about	1.000000
QA performance	0.047619
feature segment	0.076923
and turns	0.001445
post-processed by	1.000000
Training	0.000058
procedures ,	0.250000
The popular	0.005208
human-generated model	0.500000
when processed	0.028571
and system	0.001445
analysis Variation	0.015385
online resource	0.125000
unwanted constructs	1.000000
characterized in	0.250000
less complex	0.083333
zero	0.000029
perspective	0.000116
trainee controller	1.000000
instance text	0.071429
'' such	0.005376
and metrics	0.001445
coefficients ,	0.250000
fonts are	0.333333
coefficients .	0.250000
adjectives and	0.333333
can achieve	0.005525
's Law	0.019608
speech act	0.006579
5000	0.000029
languages words	0.020000
situation	0.000058
Svenka Savic	1.000000
as adjectives	0.003484
different similarity	0.020408
was made	0.012987
mentions	0.000087
common-sense	0.000029
pictures or	1.000000
actual data	0.200000
are capitalized	0.004149
own it	0.166667
bilingual text	0.500000
given data	0.041667
know document	0.500000
by concatenating	0.005714
the steady	0.001384
often span	0.022727
constructs	0.000087
for language	0.003610
for single	0.003610
American	0.000145
Roger	0.000116
in multiscript	0.001873
content overlap	0.166667
providing customer	0.500000
hour	0.000029
recall	0.000087
phrasing	0.000029
is 2,000	0.002033
remain	0.000029
Competing semantic	1.000000
large dictionaries	0.043478
of annotated	0.000891
specialized	0.000058
Incorporating	0.000029
In 1974	0.009524
numbers	0.000203
In 1971	0.009524
In 1970	0.009524
In 1978	0.009524
as knowledge	0.003484
the total	0.000692
acts	0.000087
keyphrase containing	0.052632
some tasks	0.012048
expected answer	0.142857
formalisms\/languages .	1.000000
many words	0.038462
greatly .	0.285714
that you	0.003546
coming	0.000029
query-biased	0.000029
words into	0.036697
The common	0.005208
browsing by	1.000000
to manipulate	0.002656
keyphrases are	0.057143
<s> Computationally	0.000769
a significant	0.001227
through	0.000232
Forces	0.000029
special types	0.200000
or 45	0.004505
what sound	0.031250
robustness of	0.250000
SHRDLU and	0.166667
acts ,	0.333333
Interface ,	1.000000
therapy -LRB-	1.000000
primary	0.000058
most research	0.017241
Aletta	0.000029
generated by	0.066667
containing four	0.125000
Hidden Markov	1.000000
usually perform	0.031250
CFG -LRB-	1.000000
engaging	0.000029
necessary subtask	0.100000
-LRB- Schank	0.002710
beginning to	0.500000
that involves	0.003546
only way	0.026316
Cook	0.000029
The best	0.005208
evaluation	0.001563
utility and	0.500000
candidate can	0.333333
Sentences	0.000029
often rely	0.022727
perspective .	0.250000
perspective ,	0.250000
analyze a	0.250000
analyze `	0.250000
titles ,	0.500000
`` Red	0.005291
beginning	0.000058
some context	0.012048
adjective ,	0.142857
The second	0.005208
multiple topics	0.076923
adjective ;	0.142857
NASA	0.000029
<s> Military	0.000769
with only	0.005464
way to	0.416667
<s> More	0.006149
Question processing	0.142857
are unambiguous	0.004149
condense a	1.000000
especially input	0.133333
affine and	1.000000
's usually	0.019608
first evaluation	0.030303
a proper	0.001227
a Rogerian	0.001227
score -LRB-	0.166667
normalization it	0.166667
as candidates	0.003484
on upper	0.004717
Transcription -LRB-	1.000000
dictionary is	0.142857
Research ,	0.125000
variation across	1.000000
% of	0.205128
in machine	0.009363
% on	0.025641
% or	0.025641
Work on	0.500000
develop innovative	0.200000
chosen domains	0.200000
depending	0.000116
early text-to-speech	0.100000
the relevant	0.000692
the letter	0.000692
Corpus -RRB-	0.187500
specific error	0.047619
lexical segment	0.076923
but only	0.014706
programmers	0.000029
, Elinor	0.000561
chart	0.000029
just ``	0.111111
ROUGE metric	0.200000
services	0.000087
right-most derivations	1.000000
pronunciation ,	1.000000
factors which	0.333333
system can	0.010753
businesses	0.000058
the door	0.000692
headlines	0.000029
in quite	0.001873
to human-written	0.001328
merges	0.000029
usually asked	0.031250
so far	0.033333
parsing concatenated	0.035714
most common	0.103448
merged	0.000029
conference headed	0.500000
: What	0.009804
commonly referred	0.125000
systems analyze	0.008929
news stories	0.076923
express	0.000145
is constructed	0.004065
QUALM -LRB-	1.000000
lattices	0.000029
proportional to	1.000000
by visual	0.005714
than trying	0.022222
cases on	0.055556
DeRose used	0.200000
release parameters	0.333333
The idea	0.010417
Perceptron	0.000029
of one	0.003565
Potter ,	1.000000
strategy to	0.600000
Morse	0.000029
Question book-new	0.142857
libraries for	0.500000
<s> Head-driven	0.000769
-LRB- corpus	0.002710
expert	0.000029
comprehensive model	0.200000
<s> Such	0.006149
The 1970s	0.005208
tense ,	0.500000
delimiter .	1.000000
generation technology	0.111111
develop OCR	0.200000
vs. extrinsic	0.083333
that contain	0.010638
selecting and	0.200000
foreign	0.000058
can sometimes	0.005525
for male-female	0.003610
Yet	0.000029
put this	0.250000
point	0.000087
human speakers	0.021739
extractive methods	0.142857
expensive	0.000203
Processing	0.000116
, discontinuous	0.000561
data maintained	0.012987
During this	0.500000
computer in	0.045455
presented	0.000174
the LOB	0.000692
type as	0.071429
systems explore	0.008929
corresponding increase	0.166667
deferred	0.000029
, Invoice	0.000561
the development	0.003460
not remember	0.008929
-LRB- often	0.005420
^ ,	0.666667
user-specified or	0.500000
syllables ,	0.500000
, dynamic	0.000561
recognition benchmark	0.008264
^ 2	0.333333
and perhaps	0.001445
published .	0.142857
text can	0.006289
annotated and	0.500000
Scotland to	0.200000
GRASSHOPPER incorporates	0.333333
accurate recognition	0.142857
70 %	0.750000
development	0.000347
it extremely	0.008547
regions for	0.500000
% accurate	0.051282
deployed was	0.500000
negative examples	0.125000
the mechanical	0.000692
task	0.001216
published a	0.285714
provide any	0.166667
scoring function	0.500000
1965	0.000116
traffic	0.000087
the phonemes	0.001384
NLP task	0.021277
speaker and	0.055556
, recorded	0.000561
arguably -RRB-	0.500000
explore what	0.250000
shape	0.000029
alternative	0.000087
words appear	0.009174
normalize for	1.000000
cut	0.000029
rich languages	0.200000
non-annotated	0.000058
of anaphora	0.000891
source	0.000695
statistical decision-making	0.030303
Large-scale evaluation	1.000000
, Maximum	0.000561
These edges	0.058824
world ,	0.066667
search method	0.090909
1966 ,	0.333333
1966 .	0.333333
online opinion	0.125000
-LRB- creating	0.002710
as interlingual	0.003484
corpora that	0.090909
transfer-based machine	0.666667
the complexity	0.005536
Management	0.000029
summarization ,	0.080000
absolutely	0.000029
then generated	0.028571
: Dictionary-based	0.009804
yet to	0.500000
decision	0.000116
such problems	0.008130
a fair	0.001227
centroid	0.000058
Harvey Sacks	1.000000
<s> Solutions	0.000769
as articles	0.003484
running Palm	0.333333
Chinese characters	0.142857
of people	0.000891
makes the	0.250000
CKY algorithm	1.000000
Recognition	0.000232
aural feedback	1.000000
As in	0.222222
phones .	0.500000
of understanding	0.000891
the title	0.000692
an entity	0.007576
affects the	1.000000
choice with	0.125000
or printed	0.004505
Increase	0.000029
innovative Web-based	1.000000
NER -RRB-	1.000000
and far	0.002890
Accuracy	0.000203
while ``	0.050000
steadily ,	1.000000
<s> Extracted	0.000769
translate	0.000174
required ,	0.142857
required .	0.142857
pumps last	0.500000
reports -RRB-	0.400000
symbols defined	0.333333
their training	0.029412
to query	0.001328
also help	0.014493
spoken sentence	0.071429
positive ,	0.142857
could therefore	0.062500
have tested	0.009615
-LRB- DARPA	0.002710
, object	0.000561
was sold	0.012987
speaker adaptation	0.111111
lead to	1.000000
adjacent unigrams	0.166667
thus has	0.100000
votes from	1.000000
composing	0.000029
translation -LRB-	0.027027
Commissioned	0.000029
becomes	0.000116
logic ,	0.250000
only 10	0.026316
co-occurring	0.000029
and frequency	0.001445
evaluation methods	0.018519
determining the	0.666667
ratings produced	0.111111
G ,	1.000000
implied	0.000029
<s> Parsers	0.001537
Determine	0.000029
system at	0.010753
we create	0.044444
marking abbreviations	0.500000
document such	0.027778
, Charles	0.000561
analysis and	0.030769
The set	0.005208
most spoken	0.034483
masculine	0.000029
: Category	0.009804
This approach	0.031746
derived from	0.500000
implicitly	0.000029
startlingly	0.000029
the cost	0.000692
entire	0.000087
summaries helps	0.023256
as computational	0.003484
radio	0.000029
, isolated	0.000561
and split	0.001445
create a	0.411765
tagged ''	0.666667
indicate that	0.333333
Referring expression	1.000000
, typically	0.001684
access	0.000087
Tigrinya	0.000029
and what	0.001445
sub-signals	0.000029
, James	0.002246
is often	0.022358
non-linear	0.000029
medicine or	1.000000
<s> Thus	0.009224
'' summary	0.005376
length .	0.125000
later became	0.100000
comprehension and	0.142857
the model	0.002076
It sometimes	0.026316
sentence must	0.020833
collect call	1.000000
that pollen	0.003546
clean it	0.500000
<s> Political	0.000769
accusative	0.000029
direction is	0.333333
rightmost derivation	1.000000
, contractions	0.000561
Answer	0.000087
generating natural	0.200000
on paper	0.004717
partial answers	1.000000
-LRB- ATC	0.002710
readable	0.000087
-LRB- ATN	0.002710
understanding and	0.030303
their systems	0.058824
E	0.000029
Mandarin and	1.000000
rule-based ,	0.142857
Understanding Conference	0.500000
around Documents	0.125000
mid 1980s	1.000000
single word	0.071429
questioners expect	1.000000
procedures can	0.500000
NLG to	0.142857
collections vary	0.250000
, word	0.000561
The lowest	0.005208
Extract	0.000029
not in	0.008929
example demonstrates	0.012346
equipment based	0.333333
, abstraction	0.000561
Beginning in	0.500000
detected important	0.500000
OnlineOCR With	0.333333
varied	0.000029
limited .	0.200000
varies	0.000058
<s> History	0.001537
subtask of	1.000000
profile	0.000087
two sequences	0.034483
47 %	1.000000
some measure	0.012048
where each	0.028571
ranked adjacent	0.200000
training documents	0.107143
relationship with	0.166667
& Online	0.125000
or larger	0.004505
or XML	0.004505
flatbed scanner	1.000000
would difficult	0.018868
a statistical	0.003681
Natural ''	0.076923
because recognition	0.033333
Systems that	0.333333
securely ;	1.000000
symbols	0.000087
a lattice	0.001227
getting ranked	0.250000
by Manfred	0.005714
to 150,000	0.001328
human meteorologist	0.021739
An 8	0.062500
equipment would	0.333333
`` automatic	0.005291
the direct	0.000692
per second	0.500000
preclude	0.000029
Q&A	0.000029
text accordingly	0.006289
Gary	0.000029
phonetic	0.000058
technologies --	0.250000
summaries depending	0.046512
coughing ,	1.000000
highly ranked	0.111111
HTK toolkit	0.500000
developed dynamic	0.038462
need a	0.190476
ratings usually	0.111111
approached	0.000058
initial ,	0.333333
ranked by	0.200000
interest in	0.636364
clarify	0.000029
approaches	0.000811
shipment of	1.000000
during handwriting	0.100000
, classroom	0.000561
the 1960s	0.001384
probabilities returned	0.090909
commands or	0.200000
paper-intensive industry	1.000000
right-most	0.000029
200 billion	0.500000
suffix	0.000029
Roger Schank	0.750000
sentence that	0.041667
not readily	0.008929
task ,	0.095238
restricted vocabularies	0.250000
task .	0.238095
reached	0.000058
This system	0.015873
free beer	0.250000
fuse with	1.000000
FST ,	1.000000
in titles	0.001873
score .	0.500000
-LRB- UC	0.002710
retrained to	1.000000
to describe	0.002656
which is	0.094203
scans	0.000029
it works	0.008547
explanation	0.000029
page ,	0.428571
The Future	0.005208
heritage -LRB-	1.000000
are connected	0.004149
mission to	1.000000
SR system	0.333333
parsing or	0.071429
mail ,	0.500000
transducer	0.000058
parsing of	0.071429
abstracts	0.000058
software for	0.037037
these topics	0.023810
have	0.003011
These two	0.058824
Tauschek was	0.500000
is better	0.002033
and W.	0.001445
SPHINX toolkit	1.000000
concerns	0.000058
extensive knowledge	0.333333
Ticket	0.000029
of spectral-domain	0.000891
deep understanding	0.285714
healthcare	0.000029
prisoner	0.000029
by Su	0.005714
payment	0.000029
specification .	0.500000
important subproblem	0.062500
tasks typically	0.031250
software user	0.037037
disease	0.000029
1,000	0.000058
international ATC	0.500000
, TNO	0.000561
list approach	0.090909
using ATC	0.016949
and this	0.001445
this can	0.010989
The interpretation	0.005208
near each	1.000000
graph small	0.076923
Tauschek had	0.500000
dependency parsers	0.200000
knowledge	0.000782
Shipibo .	0.500000
a background	0.001227
LexRank is	0.083333
Deciding what	1.000000
schemes to	0.500000
tag set	0.312500
dimensions For	0.333333
simple natural	0.038462
high noise	0.055556
The Brill	0.005208
to it	0.001328
reputations	0.000029
challenging because	1.000000
might contain	0.038462
which merged	0.007246
TaleSpin	0.000029
teams	0.000058
applied the	0.066667
fixed	0.000058
the country	0.002076
However such	0.027027
Part-of-speech tagging	0.500000
<s> Hence	0.001537
subjectivity used	0.500000
are ambiguities	0.004149
are actually	0.004149
` best	0.062500
on my	0.004717
to dry	0.001328
ideas ,	0.250000
likelihood	0.000087
and answers	0.001445
attribute grammars	0.500000
discussed in	0.142857
difficulties	0.000058
sub-sounds ,	1.000000
control ,	0.200000
with storing	0.005464
however	0.000376
functioning as	0.666667
mainly on	0.166667
and French	0.001445
Bhatia ,	1.000000
around the	0.375000
the conversion	0.000692
opposed to	1.000000
headlines ,	1.000000
equal	0.000029
many written	0.019231
is known	0.006098
no distinction	0.076923
a collection	0.002454
universities around	1.000000
and neural	0.002890
recognizers	0.000058
current research	0.142857
the equipment	0.000692
-LRB- MCE	0.002710
essentially a	0.250000
search for	0.090909
Nations	0.000058
tense	0.000058
simultaneously meets	0.500000
now looking	0.076923
assessments	0.000029
1983 ,	1.000000
General	0.000029
analysis :	0.061538
in politics	0.001873
attractive method	0.333333
analysis ,	0.107692
interpreted as	1.000000
keyphrases that	0.085714
Computer	0.000174
explored .	0.500000
sometimes confused	0.076923
will give	0.028571
systems can	0.026786
If there	0.100000
's seminal	0.019608
can even	0.005525
II	0.000058
be phrased	0.004219
one alternative	0.015385
at phrasing	0.014706
neural	0.000434
`` text	0.005291
parliament and	1.000000
longest running	1.000000
resources such	0.166667
not just	0.008929
NLP programs	0.021277
interim	0.000029
paraphrasing sections	1.000000
conversion of	0.666667
interpret and	1.000000
great importance	0.333333
recommending	0.000029
continued ,	0.111111
smart	0.000029
that were	0.014184
resolved	0.000029
meaning which	0.043478
background material	0.333333
classification decisions	0.058824
classifier and	0.142857
edit distances	1.000000
has yet	0.011905
displaced	0.000029
like	0.000811
success	0.000145
-RRB- would	0.005634
and DCD	0.001445
idea of	0.285714
sentence -RRB-	0.041667
IE -RRB-	0.666667
a method	0.004908
recommendation	0.000058
a scale	0.001227
See also	0.500000
happens	0.000029
some extent	0.012048
hurricane	0.000029
Church used	0.333333
of non-annotated	0.000891
the SPOTLIGHT	0.000692
toolkit is	0.500000
Nations materials	0.500000
relevant summaries	0.142857
' pyramid	0.052632
on Semantic	0.004717
the document	0.004152
scientific fields	0.500000
picture above	0.250000
you meant	0.076923
there as	0.025000
exclusively to	1.000000
really was	1.000000
that some	0.014184
introduced	0.000058
Symbian and	1.000000
extrapolate that	1.000000
size -RRB-	0.166667
learned on	0.200000
a ``	0.007362
not new	0.008929
and singular	0.001445
how often	0.034483
Approaches One	0.333333
condense	0.000029
textual summary	0.200000
approach of	0.028571
Electronic Health	0.500000
As well	0.055556
city .	1.000000
is what	0.004065
but when	0.014706
basic technology	0.076923
predict task-effectiveness	0.333333
basic elements	0.076923
understanding the	0.121212
be very	0.012658
Speech understanding	0.032258
and transmitting	0.001445
character is	0.090909
front-end SR	1.000000
grammatical tagging	0.181818
Paroubek	0.000029
we ultimately	0.022222
survey of	1.000000
measure	0.000318
included speech	0.125000
since ROUGE-1	0.100000
well-defined	0.000029
periods	0.000087
forms ,	0.166667
they belong	0.025000
identities	0.000029
possible -LRB-	0.041667
readable English	0.333333
corporation	0.000029
detail	0.000058
Wireless	0.000029
form of	0.350000
transformations to	0.500000
very rudimentary	0.024390
cheque	0.000029
interest was	0.090909
as high	0.003484
yesterday and	0.333333
than only	0.044444
any answer	0.032258
in time	0.001873
history -RRB-	0.250000
device required	0.500000
Lawrence Rabiner	1.000000
a sound	0.008589
understanding can	0.030303
in French	0.001873
General Post	1.000000
caused	0.000029
natural language	0.760000
late 1980s	0.444444
dispense	0.000029
opinionated ,	1.000000
results suggest	0.047619
ROUGE -LRB-	0.200000
vastly	0.000029
phrase -LRB-	0.100000
, gestures	0.000561
noise -LRB-	0.125000
Alenia	0.000029
intelligent character	1.000000
Designing a	1.000000
itself or	0.200000
an algorithm	0.022727
A summary	0.020000
speed for	0.142857
between computers	0.025641
like sentence	0.035714
disciplines	0.000058
direct	0.000174
Extracted	0.000029
additionally requires	1.000000
<s> Internet	0.000769
so accurate	0.033333
blue	0.000058
tools deploy	0.166667
the advantage	0.000692
selected	0.000058
linguistic discourse	0.062500
'' arguably	0.005376
feature\/aspect	0.000029
disagree with	0.333333
most natural	0.034483
taking the	0.600000
input can	0.024390
Word error	0.142857
which means	0.028986
be formally	0.004219
often do	0.022727
e.g. feature	0.017857
The readers	0.005208
Generation -LRB-	0.500000
offs	0.000029
either user-specified	0.100000
with equipment	0.005464
containing these	0.125000
'' do	0.005376
presented .	0.166667
would	0.001534
adapted to	1.000000
essential difference	1.000000
continuously rendered	1.000000
of context	0.001783
up differently	0.045455
, real-time	0.000561
acts or	0.333333
Translation process	0.666667
excellent	0.000029
a central	0.001227
Mouffe	0.000029
grammars	0.000405
for creating	0.003610
Automatic summarization	0.222222
interpretation .	0.500000
estate	0.000029
Greek -LRB-	0.333333
automatically generate	0.047619
i.e. relationship	0.052632
of data	0.006239
is having	0.002033
given sentence	0.083333
possessives	0.000029
About 47	0.500000
reconfiguring them	1.000000
description	0.000029
HMMs involve	0.125000
horoscope	0.000029
accomplish with	1.000000
languages The	0.020000
infer where	1.000000
Working	0.000029
now named	0.153846
a text-understanding	0.001227
document reader	0.027778
them are	0.105263
the early	0.002076
be directed	0.004219
Extraction and	0.333333
phone call	0.250000
In Italy	0.009524
In both	0.019048
-RRB- question	0.002817
to normalize	0.001328
as from	0.003484
places ,	0.500000
The 10	0.005208
dog ''	0.333333
quickly ,	1.000000
five-star scale	1.000000
many person-years	0.019231
Mobile	0.000087
Spontaneous	0.000029
and know	0.001445
evaluation purposes	0.018519
where the	0.371429
space .	0.200000
determines how	0.333333
, international	0.000561
is easier	0.004065
co-occurrence	0.000087
Corpus	0.000463
capable of	1.000000
still to	0.066667
speech interface	0.006579
integrated information	0.333333
is growing	0.002033
independence	0.000029
by its	0.005714
associate	0.000058
substantial resources	0.200000
analysis algorithms	0.015385
section requires	0.333333
cases one	0.055556
by interactive	0.005714
filter	0.000058
Described above	1.000000
conducted	0.000145
copied and	0.500000
In about	0.009524
abbreviated	0.000029
are called	0.008299
fire truck	0.500000
researched	0.000029
To overcome	0.111111
speaker as	0.055556
, setting	0.001123
Similarly ,	1.000000
corpus	0.000897
While this	0.200000
despite the	0.333333
dedicated to	0.666667
on-line recognition	0.333333
even ,	0.037037
, Driver-license	0.000561
it listens	0.008547
styles itself	1.000000
it takes	0.008547
could often	0.062500
stopwords	0.000029
consonants depends	0.333333
and their	0.008671
seminal	0.000029
bridge	0.000029
systems currently	0.008929
process new	0.027778
transformation ,	1.000000
demonstration in	0.200000
accusative ,	1.000000
traditionally	0.000058
-LRB- Computational	0.002710
n-gram	0.000058
world .	0.133333
enables several	1.000000
p. 32	1.000000
informational structures	0.500000
Convert	0.000058
want to	0.833333
left-to-right	0.000029
the Defense	0.000692
70 's	0.250000
information need	0.021739
only real	0.026316
answers -RRB-	0.083333
informative enough	0.500000
entertaining	0.000058
process The	0.027778
Ticket stock	1.000000
component of	0.600000
sentences that	0.065789
German city	0.250000
the availability	0.000692
spite	0.000029
what the	0.125000
mark was	0.333333
LREC	0.000058
, communicative	0.000561
importance of	0.500000
-LRB- intonation	0.002710
is recall-based	0.002033
applications of	0.040000
any previous	0.032258
appropriate syntactic	0.250000
reads sections	0.500000
syntactic ,	0.076923
syntactic .	0.076923
have any	0.009615
Moore	0.000029
end up	0.250000
ongoing as	0.500000
Broadly ,	1.000000
harder and	0.142857
have several	0.009615
were spoken	0.024390
WYSIWYM	0.000029
learn parameters	0.076923
assembling output	1.000000
form ?	0.050000
1960s	0.000087
form .	0.100000
asked and	0.333333
At Stanford	0.333333
to is	0.001328
to determining	0.001328
easily be	0.111111
approaches are	0.035714
Trek	0.000029
`` case	0.005291
successful demonstration	0.111111
Winograd	0.000087
form a	0.150000
or analysis	0.004505
news	0.000376
response Mobile	0.500000
Among	0.000029
psycholinguistics when	0.500000
term ``	0.111111
With the	0.285714
called morphological	0.055556
dogs ‚Üí	0.142857
support question	0.250000
get the	0.285714
of being	0.000891
sophisticated algorithms	0.285714
giving these	0.500000
conference	0.000058
Extractor -RRB-	1.000000
a reduced	0.001227
Kucera	0.000029
Interactive voice	0.500000
Reukos	0.000029
also very	0.028986
question and	0.023810
as Lisp	0.003484
inserts those	1.000000
and report	0.001445
B. ,	1.000000
formalization	0.000058
n	0.000058
POS tags	0.153846
Japanese and	0.250000
FAS -RRB-	1.000000
, models	0.000561
extraction module	0.032258
different contexts	0.020408
Tell	0.000029
question is	0.095238
Mobile telephony	0.333333
limited vocabulary	0.100000
drawback	0.000029
order in	0.071429
symbol of	0.250000
decision-making	0.000029
' ,	0.315789
' .	0.105263
to carry	0.001328
a core	0.001227
the stock	0.000692
best with	0.055556
`` inadequate	0.005291
Rate -LRB-	1.000000
even where	0.037037
is ,	0.018293
assembling	0.000029
proposed	0.000261
can decide	0.005525
- \/	0.062500
proposes	0.000029
of chatterbots	0.000891
is 7	0.002033
earliest-used algorithms	0.500000
keyphrases by	0.028571
must compute	0.071429
<verb> ‚Üê	1.000000
Behind	0.000029
David 's	0.250000
noun reading	0.071429
speech full	0.006579
Tokens are	1.000000
SAM -LRB-	1.000000
sidestepped	0.000029
breaks	0.000058
is a	0.109756
this regard	0.010989
that overlap	0.003546
envelope based	1.000000
and question	0.001445
Topic	0.000029
Loebner prize	1.000000
algorithm is	0.178571
speeds .	0.500000
Again	0.000029
rescoring -RRB-	1.000000
excerpt	0.000029
Extraction	0.000087
content alone	0.083333
camera ,	0.500000
camera .	0.500000
simply using	0.083333
SCU	0.000029
expressed like	0.166667
Beaugrande	0.000029
are based	0.020747
sentence with	0.020833
is coherent	0.002033
author wishes	0.333333
ensure	0.000029
Environment	0.000029
supervised ''	0.187500
examples to	0.041667
annotating	0.000029
& Server	0.125000
in 2006	0.001873
in 2007	0.001873
in 2004	0.001873
chunks of	1.000000
automata	0.000029
supervised keyphrase	0.125000
generate a	0.333333
by metrics	0.005714
processing news	0.018519
from an	0.009615
Alessandro Duranti	1.000000
have resulted	0.009615
for different	0.003610
factors ,	0.333333
`` New	0.005291
Realtime Speech	1.000000
voice response	0.076923
Subjectivity	0.000029
reader installed	0.100000
An ISO	0.062500
recursive-descent	0.000029
TextRank algorithm	0.071429
W. G.	0.500000
different ones	0.020408
deduction to	1.000000
his book	0.083333
keyphrases attached	0.028571
sensible manner	1.000000
when	0.001013
setting	0.000145
papers	0.000087
or service	0.004505
-LRB- perhaps	0.002710
of achieving	0.001783
picture	0.000116
service with	0.200000
chatterbots were	0.500000
from all	0.009615
judge its	0.250000
to performance	0.001328
being conducted	0.055556
nouns or	0.111111
discontinuous speech	0.666667
faster	0.000087
tested	0.000058
to end	0.002656
polarity classification	0.125000
beyond simple	0.166667
Norman Fairclough	0.500000
Church 's	0.333333
easily retrieved	0.111111
be written	0.004219
<s> Text	0.001537
years later	0.142857
row	0.000029
understanding of	0.151515
clarification	0.000087
resources ,	0.333333
controlling flight	1.000000
passage	0.000029
understanding or	0.030303
general format	0.045455
humans when	0.083333
with neural	0.005464
frequencies	0.000058
True\/False is	1.000000
unfamiliar	0.000087
impressive	0.000058
level	0.000579
posts	0.000029
manner .	0.750000
standards	0.000145
methodologies .	1.000000
`` zero	0.005291
feature\/aspect-based	0.000029
knowledge about	0.111111
corp. .	1.000000
trend	0.000058
The ability	0.005208
, Norman	0.000561
radiology report	1.000000
a function	0.001227
involves ``	0.100000
of natural	0.019608
<s> e.g.	0.001537
technology providers	0.045455
compare them	0.142857
inflectional	0.000058
worth noting	0.500000
causing it	1.000000
<s> Users	0.000769
boundaries may	0.090909
easier task	0.125000
particularly prone	0.200000
considers an	0.500000
interaction with	0.125000
1 -LRB-	0.250000
medium -RRB-	0.333333
to disambiguate	0.003984
walking patterns	0.333333
the correct	0.004152
e.g. ,	0.464286
Corporation -LRB-	0.500000
and proper	0.001445
disruptive to	1.000000
TextRank results	0.071429
must first	0.071429
this field	0.021978
software finding	0.037037
some heuristic	0.012048
Languages	0.000087
Sentiment Analysis	0.166667
Therefore	0.000058
, -LRB-	0.001684
deeply ,	1.000000
helps him	0.500000
it requires	0.017094
variously	0.000029
In 1982	0.009524
broad and	0.250000
was shown	0.025974
'' continued	0.005376
These	0.000492
language production	0.006757
machine would	0.025316
theory and	0.076923
cases	0.000521
those used	0.136364
As businesses	0.055556
Depending on	1.000000
computer based	0.022727
can then	0.005525
usability	0.000029
figure	0.000058
Integration	0.000029
different strategies	0.020408
hyphenation	0.000029
fields of	0.333333
too many	0.333333
developed into	0.038462
Lichtenstein ?	1.000000
larger group	0.062500
Adverse conditions	1.000000
vital	0.000029
` nice	0.062500
system with	0.010753
OCR is	0.061224
's EndWar	0.019608
or English-like	0.004505
NLP problem	0.042553
, syntax	0.001123
of POS	0.001783
representations	0.000116
OCR in	0.040816
, Ren√©	0.000561
system is	0.096774
on technology	0.004717
clear that	0.250000
Contains Confusable	1.000000
the whole	0.000692
feasible the	0.500000
constructed ,	0.500000
categories in	0.111111
subproblem of	1.000000
≈çrƒÅti≈çnis -RRB-	1.000000
not capitalize	0.008929
Higher	0.000029
research in	0.142857
Rules	0.000087
Section ,	1.000000
platform	0.000058
research is	0.047619
describing each	0.250000
words by	0.009174
human-written	0.000058
speaker-dependent system	1.000000
simple pro	0.038462
task requiring	0.023810
total number	0.500000
a small	0.002454
second -RRB-	0.100000
computer that	0.022727
exploring the	1.000000
sentiments expressed	1.000000
Profile templates	1.000000
by an	0.011429
considered -LRB-	0.111111
to predicting	0.001328
use or	0.027778
upgrade a	1.000000
use of	0.291667
not wear	0.008929
France ,	0.500000
short time-scales	0.125000
rule-based machine	0.142857
sufficiently well	1.000000
given rise	0.041667
article then	0.034483
`` who	0.005291
statically	0.000029
not agree	0.008929
et al.	1.000000
or emails	0.004505
that for	0.003546
like PDF	0.035714
of sentiment	0.004456
-LRB- probabilistic	0.002710
detecting the	1.000000
documents with	0.052632
characteristics of	0.500000
had a	0.285714
program by	0.045455
questions pertaining	0.038462
person does	0.052632
often allows	0.022727
London -RRB-	1.000000
'' 100	0.005376
when translating	0.028571
, natural	0.000561
sounds very	0.066667
Little further	1.000000
compute various	0.500000
: This	0.039216
domain might	0.050000
Commercial	0.000058
quality criteria	0.100000
that requires	0.007092
rank order	0.166667
underlying idea	0.333333
perspective in	0.250000
recognition instead	0.008264
IMR	0.000058
<s> Closed-domain	0.000769
the corresponding	0.001384
no spaces	0.076923
Australian physician	0.500000
, has	0.000561
The authors	0.015625
some methods	0.024096
support vector	0.250000
Wordnet	0.000029
AT&T libraries	1.000000
science -LRB-	0.100000
the parsing	0.001384
languages is	0.020000
are two	0.008299
sciences	0.000058
animation	0.000029
this basic	0.010989
languages in	0.020000
about speech	0.050000
Syphon	0.000029
correct result	0.066667
first pass	0.030303
and his	0.001445
, pruned	0.000561
both query	0.032258
of system-generated	0.000891
maintained by	0.500000
with American	0.005464
across their	0.200000
the corpus	0.000692
listening to	1.000000
later	0.000290
program focuses	0.045455
the known	0.003460
expansion .	0.333333
CSIS ,	0.500000
for parsing	0.003610
Optical character	0.666667
Research	0.000232
spaces	0.000145
An absorbing	0.062500
dealing with	1.000000
state	0.000405
similarly effective	1.000000
upper-case letter	1.000000
Laclau	0.000029
summary -LRB-	0.023810
ROUGE measures	0.200000
Annual	0.000029
properties .	0.250000
properties ,	0.250000
Shared tasks	1.000000
jokes	0.000029
predicted	0.000058
then run	0.028571
a word	0.013497
strong and	0.250000
nasality	0.000029
1928	0.000029
1929	0.000029
, contrast	0.000561
position and	0.250000
proceedings into	1.000000
participate in	1.000000
digital speech-to-text	0.142857
the testing	0.000692
multiple possible	0.153846
densely connected	1.000000
the dominance	0.000692
acquiring	0.000029
computer automated	0.022727
V.J. ,	1.000000
inventor Jacob	1.000000
-- whole	0.040000
to translate	0.003984
<s> Efficient	0.000769
filtering	0.000029
American Recovery	0.200000
relying on	1.000000
period	0.000058
a demonstration	0.003681
gestures in	0.500000
return ?	0.500000
aid in	0.750000
strings of	1.000000
knowledge on	0.037037
its immediate	0.028571
to grow	0.001328
a common	0.002454
He took	0.125000
paraphrasing	0.000029
direction	0.000087
a field	0.003681
So ,	0.333333
spirit	0.000029
pilot	0.000145
case	0.000492
identified in	0.200000
is analyzed	0.006098
phoneme	0.000058
addition ,	0.333333
but they	0.044118
sales receipts	0.333333
not the	0.044643
Open	0.000029
-LRB- stationary	0.002710
section needs	0.166667
that allows	0.003546
generally without	0.090909
surrounding the	0.200000
author	0.000087
granted	0.000029
system takes	0.010753
exploration ,	1.000000
-RRB- The	0.005634
dissertation .	0.333333
<s> Collection	0.000769
-LRB- ME	0.002710
relies	0.000029
often represented	0.022727
feature in	0.076923
their context	0.029412
without	0.000376
relief	0.000029
more readily	0.010526
with some	0.021858
error rate	0.416667
rated with	1.000000
appear .	0.062500
researchers	0.000290
appear ,	0.062500
align recorded	1.000000
, Inc.	0.001123
to break	0.001328
is necessary	0.004065
frame has	0.500000
a tool	0.002454
the BORIS	0.000692
remembering ,	1.000000
character groups	0.045455
Tigrinya among	1.000000
's speech	0.019608
summaries humans	0.023256
attained .	1.000000
is slow	0.002033
\/	0.000087
\*	0.000116
their linguistic	0.029412
Many	0.000347
that larger	0.003546
Mars Polar	0.500000
vectors -LRB-	0.333333
they improved	0.025000
-LRB- although	0.005420
returned with	0.250000
becomes harder	0.250000
part-of-speech possibilities	0.066667
speeds made	0.500000
was followed	0.012987
structured into	0.166667
content present	0.083333
registry .	1.000000
of continuous	0.001783
Grass pollen	1.000000
Master	0.000029
concatenating the	1.000000
common tag	0.040000
not to	0.008929
and occurs	0.001445
called GRASSHOPPER	0.055556
using statistical	0.033898
improvement to	0.250000
Department of	1.000000
but vocabulary	0.014706
moon	0.000029
nor even	1.000000
information from	0.065217
in summary	0.003745
by induction	0.005714
in isolation	0.001873
Speereo Voice	0.500000
fall in	0.250000
Variation analysis	1.000000
similarities to	0.500000
discussed	0.000203
, Air	0.000561
and that	0.002890
Artificial neural	0.500000
matter of	0.333333
resulting from	0.250000
strong is	0.250000
increasingly complex	0.333333
there	0.001158
healthcare is	1.000000
sixty Russian	1.000000
Compute	0.000029
time-consuming part	0.333333
applied successfully	0.066667
part-of-speech tagger	0.066667
the invention	0.000692
Syphon -LRB-	1.000000
seen the	0.100000
output than	0.038462
that there	0.007092
affect the	0.333333
more informative	0.010526
all possible	0.069767
called ``	0.277778
features in	0.038462
diversity	0.000116
language such	0.006757
scientific and	0.500000
from improved	0.009615
table is	0.142857
co-occurrence in	0.333333
farther	0.000029
signing off	1.000000
disseminate it	1.000000
enough data	0.400000
Rules post-processed	0.333333
felt -RRB-	1.000000
discrete phonetic	0.333333
wife	0.000029
tend to	1.000000
pre-determined when	1.000000
, generating	0.000561
spaces ,	0.200000
interactive use	0.250000
spaces .	0.200000
Hendrix	0.000029
Linguistics defines	0.333333
2 ,	0.200000
early market	0.100000
decisions	0.000290
sentence position	0.041667
or serving	0.004505
simulation of	0.333333
each choice	0.022222
the error	0.000692
list -LRB-	0.090909
system also	0.010753
whole of	0.111111
backward ,	1.000000
informative with	0.500000
novel	0.000029
a maximum	0.002454
leads	0.000029
Sentence segmentation	0.400000
the questions	0.000692
list	0.000318
to any	0.003984
strongly to	0.500000
may generate	0.019231
Carla	0.000029
may all	0.019231
features that	0.076923
included -LRB-	0.125000
singular forms	0.250000
Deep approaches	1.000000
invention	0.000029
East	0.000029
Rule-based machine	0.500000
into segments	0.025641
rainbow form	1.000000
a radiology	0.001227
version	0.000087
diverse ''	0.500000
summarization -LRB-	0.040000
dry up	1.000000
summary and	0.047619
took Harris	1.000000
naval	0.000087
higher levels	0.285714
and by	0.001445
of hours	0.000891
Amount line	1.000000
produced by	0.333333
at level	0.014706
`` Statistical	0.005291
structure with	0.083333
<s> Topics	0.000769
would like	0.037736
The edges	0.005208
associated number	0.250000
Linguistics ''	0.333333
reached .	0.500000
speech-recognition	0.000087
non-linearly to	1.000000
because a	0.033333
are domain-independent	0.004149
aim is	0.500000
stages are	0.500000
of immunology	0.000891
information of	0.021739
relevant entities	0.142857
computers -RRB-	0.111111
: Rules	0.019608
experiment which	0.200000
data -RRB-	0.038961
Thompson	0.000029
scale rather	0.166667
You	0.000029
the lexicon	0.000692
rather	0.000463
personal computers	0.250000
R. Harris	0.166667
Granada Different	0.500000
: By	0.009804
specialized algorithms	0.500000
, John	0.002807
high-quality weather	1.000000
sometimes called	0.076923
short	0.000232
ranking -LRB-	0.142857
`` tagged	0.010582
adjacent sounds	0.166667
Fourier Transform	0.333333
Armed	0.000029
in computers	0.001873
sentence importance	0.020833
template slot	0.250000
a Japanese	0.001227
nouns were	0.111111
unverified	0.000029
Black-box	0.000058
Blommaert	0.000029
indifferent to	1.000000
and semi-supervised	0.001445
identify objects	0.083333
at University	0.014706
parser often	0.062500
system usability	0.010753
or dictionary	0.004505
first sentence-end	0.030303
, Carla	0.000561
Cohesion	0.000029
were limited	0.024390
SourceForge .	1.000000
instructions	0.000029
the perception	0.000692
very useful	0.048780
robots ,	1.000000
how to	0.103448
into punched	0.012821
Dependence vs.	1.000000
processing ,	0.166667
The system	0.031250
processing .	0.129630
of work	0.000891
the summary	0.005536
-LRB- F-16	0.002710
natural ''	0.026667
processing ;	0.018519
processing :	0.018519
any of	0.064516
we do	0.022222
be available	0.004219
be separated	0.004219
had not	0.071429
Europe ,	0.600000
algorithms are	0.057143
understand the	0.285714
probability -RRB-	0.285714
Often natural	0.333333
public opinion	1.000000
pre-structured database	1.000000
multimedia -LRB-	0.500000
Oklahoma	0.000029
<s> Systems	0.006149
many significant	0.019231
since 1965	0.100000
leading	0.000058
words just	0.009174
Larry	0.000058
this application	0.010989
widely applied	0.125000
them good	0.052632
transducer verifying	0.500000
identify the	0.500000
was the	0.051948
kind	0.000318
methods related	0.022727
is steered	0.002033
counter examples	1.000000
, MT	0.001123
humans deemed	0.083333
've	0.000058
NLP evaluation	0.063830
tongues	0.000029
are made	0.012448
the Penn	0.005536
Research in	0.125000
Convert information	0.500000
language-specific changes	1.000000
ARRA	0.000029
text ;	0.006289
entirety	0.000029
MAHS	0.000029
Edward Robinson	1.000000
text .	0.169811
MAHT	0.000029
text ,	0.188679
as references	0.003484
satisfactory in	1.000000
customize	0.000058
the extremely	0.000692
using some	0.033898
be manually	0.004219
EMR according	0.333333
in Canada	0.001873
all lower	0.023256
probabilistic	0.000203
use training	0.027778
thresholded to	1.000000
product .	0.142857
in computational	0.003745
article is	0.034483
traditional	0.000029
consecutively and	1.000000
decomposition into	1.000000
and applications	0.001445
Evaluation -RRB-	0.222222
abstractive keyphrase	0.166667
and printed	0.001445
posed in	0.666667
the annotation	0.000692
grammar-based methods	1.000000
Carbonell ,	1.000000
EARS project	1.000000
milliseconds -RRB-	0.500000
over an	0.083333
speakers might	0.250000
emails	0.000058
contextual	0.000058
personnel .	1.000000
metrics correlate	0.111111
possible .	0.125000
possible ,	0.125000
Biden visited	0.333333
typically based	0.055556
wrote	0.000174
occurred in	1.000000
of allowable	0.000891
<s> Often	0.002306
and entered	0.001445
or uttered	0.004505
tasks returning	0.031250
named IEEE	0.142857
correct part	0.200000
sold	0.000087
attention	0.000058
Manual	0.000087
code readers	0.142857
Koine	0.000029
and text	0.005780
proposed photographing	0.111111
paradigms	0.000029
At this	0.333333
pre-process data	1.000000
of parse	0.000891
More detailed	0.111111
accuracy include	0.032258
situation .	0.500000
an American	0.007576
extension of	1.000000
Beginning with	0.500000
information then	0.021739
recently there	0.333333
generates summaries	0.333333
flight	0.000058
Audio Processing	0.500000
precision	0.000145
, depends	0.000561
decision trees	1.000000
NIST role	0.500000
of Mandarin	0.000891
datum is	1.000000
The same	0.010417
<s> Glass-box	0.000769
proved negligibly	0.333333
concurrently	0.000029
<s> Generally	0.003843
sentenced separated	1.000000
probabilistically	0.000029
a facemask	0.001227
profile captures	0.333333
in statistical	0.003745
a cryptanalyst	0.001227
alone may	0.250000
create odd	0.058824
9	0.000029
more accurately	0.010526
higher	0.000203
most notoriously	0.017241
methods -LRB-	0.045455
exigencies	0.000029
single PC	0.071429
's gonna	0.019608
Chinese or	0.142857
ATNs ''	0.333333
and visible	0.001445
project was	0.076923
one meaning	0.030769
a phone	0.001227
sophisticated understanding	0.142857
with DTW	0.005464
must make	0.071429
why certain	0.142857
unseen	0.000029
needs to	0.400000
similar application	0.037037
questions	0.000753
summaries	0.001245
a great	0.002454
Brain has	1.000000
must also	0.071429
may vary	0.019231
these tools	0.023810
of large	0.003565
as either	0.003484
predicting ratings	0.500000
past-tense verb	1.000000
and persuasion	0.001445
the way	0.002768
general with	0.045455
SCU in	1.000000
separately	0.000029
collect	0.000029
a much	0.003681
program can	0.045455
the successful	0.000692
Racter	0.000029
automatically do	0.047619
Pierce wrote	1.000000
most fundamental	0.017241
-LRB- though	0.002710
possibly others	0.500000
average text	0.500000
to as	0.005312
viewed as	1.000000
type ,	0.071429
to an	0.001328
leftmost	0.000058
segmentation between	0.030303
solved first	0.200000
five commands	0.200000
the Romance	0.000692
The loss	0.005208
text rather	0.006289
Learning Some	1.000000
vs. open	0.083333
n't for	0.250000
expect answers	0.333333
range	0.000203
relationships between	0.166667
model of	0.033333
Manfred R.	1.000000
plural ,	0.400000
recognition equipment	0.008264
as horoscope	0.003484
produced ,	0.111111
long input	0.500000
question	0.001216
long	0.000058
popular journals	0.111111
approach used	0.028571
another problem	0.153846
modal .	1.000000
comparable .	1.000000
stages of	0.500000
and allows	0.002890
expressivity	0.000029
Voice Command	0.200000
a specialist	0.001227
capitalized	0.000087
or automatically	0.009009
short-time	0.000058
capitalizes	0.000029
etc.	0.000637
: GRASSHOPPER	0.009804
source document	0.083333
`` blue	0.010582
the test	0.001384
that depend	0.003546
vs. Independence	0.083333
Harris ,	0.111111
and without	0.002890
nearly perfect	0.500000
ever appear	1.000000
rainbow	0.000029
marked by	0.333333
it does	0.008547
licensed on	1.000000
On others	0.166667
speakers .	0.250000
nice	0.000116
ISO sub-committee	0.500000
devices .	0.500000
HAMS =	1.000000
allowing	0.000087
<s> Improved	0.000769
corresponding summaries	0.166667
Audio	0.000058
comparative depths	1.000000
Turney	0.000261
common cases	0.040000
which proposed	0.007246
paragraph summary	0.333333
Based	0.000029
sentiment analysis	0.520000
Department	0.000029
that can	0.046099
have proposed	0.009615
world and	0.066667
requires fairly	0.062500
languages	0.001448
include	0.000782
model ,	0.100000
model .	0.066667
best word	0.055556
EHR	0.000087
represented themselves	0.166667
exceeded the	1.000000
P	0.000058
merge adjacent	1.000000
speaker ,	0.055556
cross-discipline	0.000029
corpus with	0.032258
`` breadth	0.005291
term meaning	0.055556
a part	0.002454
Barbara Johnstone	1.000000
It is	0.605263
concluded	0.000058
-RRB- Transcription	0.002817
language without	0.006757
Levinsohn ,	1.000000
statistical output	0.030303
Lehnart	0.000029
one within	0.015385
NLG output	0.047619
document retrieval	0.027778
the wave	0.000692
19th	0.000029
, Deborah	0.001123
substantial funding	0.200000
being said	0.055556
, because	0.004492
chose	0.000029
degree	0.000174
and generic	0.001445
and relevance	0.001445
monetary	0.000029
it statically	0.008547
explore	0.000116
Hands-free computing	1.000000
summary based	0.023810
a appropriate	0.001227
waves can	0.142857
the unsupervised	0.000692
larger	0.000463
leaving	0.000029
For instance	0.114754
Palm	0.000029
<s> Their	0.001537
Senseval and	1.000000
In common	0.009524
the written	0.000692
'' will	0.005376
up-to-date	0.000029
candidate passages	0.333333
human raters	0.021739
regression -LRB-	1.000000
an open	0.015152
just a	0.222222
Apart from	1.000000
different dialogues	0.020408
purpose when	0.200000
from	0.003011
ask for	0.250000
typically around	0.055556
Microsoft	0.000058
<s> Voice	0.000769
Eagles Guidelines	1.000000
input sentence	0.024390
Goldberg developed	0.500000
same problem	0.040000
text into	0.044025
possess -LRB-	1.000000
only do	0.026316
traditional linguistics	1.000000
, cognitive	0.000561
and subsequent	0.001445
Guy	0.000029
injuries to	1.000000
classification of	0.058824
this in	0.010989
Pike ,	1.000000
rules can	0.069767
-LRB- 95	0.002710
notably to	0.333333
used over	0.008850
'' sentiment	0.005376
? -RRB-	0.250000
<s> Hidden	0.002306
of other	0.003565
-LRB- 99	0.002710
imaging is	1.000000
image ,	0.333333
assumptions	0.000145
Australian	0.000058
to doctors	0.001328
meet President	0.250000
lexicon representation	0.111111
roughness	0.000029
to predict	0.002656
; no	0.021277
dog bites	0.333333
better guide	0.111111
decision-making ,	1.000000
recognizer	0.000029
working from	0.142857
a storm	0.001227
, Joseph	0.000561
techniques is	0.043478
BLEU measure	0.333333
the construction	0.000692
10 milliseconds	0.250000
source text	0.208333
Black 1991	0.500000
Schank and	0.400000
of two	0.001783
stream of	0.500000
search Sentence	0.090909
social science	0.071429
, OCR	0.001123
interpreted	0.000029
computer processing	0.022727
interpreter	0.000058
, produced	0.001684
: Sample	0.009804
of regular	0.000891
or Hard	0.004505
are structured	0.004149
when working	0.028571
additional constraints	0.166667
as interactivity	0.003484
in natural	0.013109
Zellig	0.000087
well-known application	1.000000
abstractive	0.000174
articles	0.000232
edit	0.000029
as content	0.003484
lattices represented	1.000000
in Liu	0.001873
specific example	0.047619
and expensive	0.002890
cursive	0.000145
syntactic coverage	0.076923
be asked	0.004219
to those	0.002656
which have	0.014493
prevent incorrect	1.000000
idea but	0.142857
our	0.000145
which give	0.007246
out	0.000405
Two particular	0.142857
sentiment	0.000724
Other measures	0.142857
interfaces such	0.500000
the morphemes	0.000692
social networks	0.214286
in 1971	0.001873
'' vertex	0.005376
and LOB	0.001445
excess	0.000058
rate these	0.090909
affective	0.000058
Beigi	0.000029
shapes .	0.333333
absorbing random	0.333333
of information	0.004456
documents is	0.026316
indeed answer	0.333333
hence	0.000058
documents in	0.026316
describe words	0.166667
of distinctions	0.000891
thought-to-paper communication	1.000000
edited and	1.000000
American Bible	0.200000
An ongoing	0.062500
pilot to	0.400000
unknown	0.000029
T vertices\/unigrams	0.166667
excerpt containing	1.000000
and artificial	0.001445
language modeling	0.006757
measuring similarity	1.000000
<s> Summarization	0.001537
decide that	0.250000
and continued	0.001445
In addition	0.028571
the reason	0.000692
in free	0.003745
Peter	0.000029
Natural Language	0.230769
clip	0.000058
some grammar	0.012048
the recognizer	0.000692
in CSR	0.001873
graph can	0.076923
that dispense	0.003546
having a	0.200000
having `	0.200000
linked	0.000087
person who	0.052632
<s> Ideally	0.001537
generally amenable	0.090909
important points	0.062500
sources for	0.166667
produce the	0.136364
as multi-document	0.003484
Turney 's	0.444444
composing Braille	1.000000
given NLP	0.041667
who	0.000290
A relationship	0.020000
representation	0.000550
period of	0.500000
why	0.000203
system will	0.010753
, columns	0.000561
grammar to	0.027027
<s> SHRDLU	0.001537
people who	0.125000
removing objective	0.500000
DARPA Speech	0.250000
text summarization	0.006289
NLG ;	0.047619
computer language	0.022727
a context-free	0.003681
co-occurring neighbors	1.000000
both time	0.032258
In practice	0.009524
agrees	0.000029
vs. objective	0.083333
extract a	0.250000
local	0.000087
a widely-reported	0.001227
GPO	0.000029
materials .	0.500000
pseudo-pilot ''	0.500000
either manually	0.100000
knowledge system	0.037037
answering deals	0.166667
Dictionary-based machine	0.500000
ATIS	0.000029
translation paradigm	0.013514
not only	0.062500
neural-network output	1.000000
networks discussions	0.071429
`` recommend	0.010582
like Ncmsan	0.035714
the gap	0.000692
; Analysis	0.021277
Another important	0.076923
opinions -RRB-	0.500000
written texts	0.076923
Optophone ,	1.000000
's estimate	0.019608
identification	0.000145
bought	0.000029
ability	0.000116
opening	0.000029
a system-generated	0.001227
job	0.000058
is meaningful	0.002033
sentences for	0.013158
Retrieval	0.000029
, for	0.012353
straightforward PCFGs	1.000000
output a	0.076923
unclear	0.000029
environments	0.000058
word-frequency	0.000029
is testing	0.002033
HMT -RRB-	1.000000
for editing	0.003610
language and	0.013514
approach allows	0.028571
the expectations	0.000692
, its	0.000561
The translator	0.005208
's methods	0.019608
the world	0.002076
of whom	0.000891
excellent application	1.000000
that occurs	0.003546
which bore	0.007246
but have	0.029412
order ,	0.142857
concerns ;	0.500000
thus	0.000290
lightweight	0.000029
keyphrases ,	0.057143
Driver-license OCR	1.000000
keyphrases .	0.314286
usually in	0.093750
generate text	0.055556
largely been	0.200000
perhaps	0.000174
isolated-word recognizers	1.000000
procedure for	0.333333
Improved output	1.000000
largest	0.000029
of co-articulation	0.000891
, with	0.004492
The late	0.005208
machine for	0.012658
The fonts	0.005208
disagree	0.000087
evaluation In	0.018519
is farther	0.002033
computer to	0.045455
users and	0.111111
each sentence	0.022222
writing custom	0.111111
undertaken	0.000058
experimented with	1.000000
operation of	0.500000
heavily	0.000029
punctuation characters	0.142857
its output	0.085714
syntactic parsing	0.076923
I would	1.000000
extent with	0.250000
Ren√© Descartes	1.000000
an array	0.007576
to news-gathering	0.001328
One key	0.076923
fly have	1.000000
usage	0.000029
hurts ?	0.500000
evaluators	0.000029
i.e. text	0.052632
do this	0.076923
In languages	0.009524
Hulth showed	0.333333
Components	0.000029
expression just	0.100000
both very	0.032258
research were	0.023810
techniques that	0.086957
ARNS system	1.000000
addition to	0.500000
in this	0.018727
smoothly	0.000058
generated readable	0.066667
natural as	0.013333
search by	0.090909
playing in	1.000000
'' occur	0.005376
12 such	0.200000
any QA	0.032258
fighter aircraft	0.500000
summaries but	0.023256
SR while	0.333333
paste	0.000029
over 1,000	0.083333
rare	0.000116
carried	0.000058
-LRB- DTW	0.002710
are saying	0.004149
John McCarthy	0.125000
`` learning	0.021164
into canned	0.012821
experts of	1.000000
algorithms to	0.085714
weather	0.000203
promise	0.000029
analysis tasks	0.015385
systems include	0.008929
improve information	0.076923
to ''	0.002656
a piecewise	0.001227
Multilingual	0.000029
blocks to	0.250000
chosen publications	0.200000
where formal	0.028571
Prominent	0.000029
automates	0.000029
person\/persons rather	1.000000
surprisingly disruptive	0.333333
volume	0.000116
we will	0.088889
automated	0.000203
computer speech	0.022727
voice dialog	0.076923
Birkbeck	0.000058
meaningful relationships	0.125000
modern systems	0.200000
their closest	0.029412
of machine	0.007130
1982 ,	0.333333
result in	0.090909
Vice President	1.000000
which were	0.014493
: expanded	0.009804
Up to	1.000000
result is	0.181818
data needed	0.012987
top-down	0.000116
<s> Data	0.000769
beer ,	1.000000
and captioned	0.001445
some fundamental	0.012048
correctly-developed summaries	1.000000
speech dynamics	0.006579
kinds	0.000029
programmers began	1.000000
a negative	0.001227
Future	0.000058
pumps	0.000058
installed at	0.666667
be robust	0.004219
enabling technologies	1.000000
illustrates how	0.500000
adjective or	0.428571
, Adriana	0.000561
Since this	0.200000
sources .	0.333333
sources ,	0.166667
new trend	0.041667
be solved	0.004219
Dynamic time	0.800000
errors per	0.200000
Italian -RRB-	0.500000
major limitation	0.083333
you see	0.076923
, second	0.000561
for Gisting	0.007220
, UPV	0.000561
may contain	0.038462
phone error	0.250000
applications there	0.040000
in terms	0.011236
This new	0.015873
interpreter .	0.500000
and document	0.002890
This can	0.015873
prize	0.000029
potentially more	0.333333
required to	0.142857
`` have	0.005291
succession	0.000029
brain .	0.333333
already been	0.400000
the separate	0.000692
fully solved	0.166667
or legal	0.004505
increasing	0.000087
books a	1.000000
errors -LRB-	0.400000
Church	0.000087
by this	0.005714
tag sets	0.250000
Multimodal	0.000029
then used	0.028571
regard .	0.200000
explained	0.000029
one needs	0.015385
existing so	0.200000
fundamental ,	0.500000
spoke	0.000029
abbreviation MT	0.500000
More sophisticated	0.333333
subdivided into	1.000000
technology useful	0.045455
commanding an	1.000000
telegraph	0.000029
standardised text	1.000000
the affect	0.000692
successful	0.000261
learning algorithms	0.116279
processing uses	0.018519
computational linguistics	0.600000
summary of	0.071429
involves visual	0.100000
are SHRDLU	0.004149
rate still	0.090909
language might	0.006757
organized	0.000029
appear within	0.062500
can be	0.502762
and waves	0.001445
sentence extraction	0.020833
be approximately	0.004219
rudimentary way	0.500000
as sounds	0.003484
values ,	0.125000
turn	0.000174
was installed	0.012987
machine	0.002287
methodology	0.000058
Comparing these	1.000000
preferable	0.000029
word processors	0.016667
manually designed	0.250000
a unit	0.001227
paper legal	0.090909
But from	0.166667
questions ,	0.307692
questions .	0.076923
By combining	0.333333
these programs	0.023810
, Mariani	0.000561
with corpus	0.005464
line of	0.333333
claim that	1.000000
effective	0.000174
Another	0.000376
<s> So	0.002306
which recursively	0.007246
the technology	0.000692
HAMS	0.000029
Extrinsic evaluations	0.500000
vary	0.000174
Modern speech	0.333333
of code	0.000891
Unicode Consortium	1.000000
as text	0.003484
the SIGGEN	0.000692
that most	0.003546
toward actions	1.000000
create texts	0.058824
used more	0.008850
is split	0.004065
narrowest	0.000029
Harris	0.000261
A random	0.020000
a newspaper	0.001227
1953 U.S.	1.000000
sound into	0.050000
's NLP	0.019608
represents	0.000116
two distinct	0.034483
Z ''	1.000000
, speed	0.000561
Functional	0.000029
stationary probability	0.142857
is to	0.038618
expectancy	0.000029
financial	0.000116
that have	0.021277
classify a	0.500000
coherent sequences	0.200000
of general	0.000891
using ``	0.016949
reached 20,000	0.500000
been done	0.029412
by no	0.005714
, common	0.000561
refined score	1.000000
probability ,	0.142857
effectively utilize	0.333333
the smaller	0.000692
However ,	0.864865
match certain	0.166667
University	0.000261
insights .	1.000000
task-effectiveness at	0.500000
the E-set	0.000692
or from	0.004505
\* ''	0.250000
whose usage	0.333333
settings .	1.000000
-LRB- by	0.005420
where sentences	0.057143
high recognition	0.055556
choices	0.000145
in fundamentally	0.001873
Human	0.000145
nouns	0.000261
specific contexts	0.047619
Please	0.000087
piece of	1.000000
a dissertation	0.001227
Stemming	0.000029
a noun	0.007362
is phonetically	0.002033
assigned ,	0.500000
on new	0.004717
section of	0.166667
to mention	0.001328
bottom-up	0.000029
of SHRDLU	0.000891
while Snyder	0.050000
to gather	0.001328
listed	0.000029
underlie	0.000029
speech tagger	0.006579
be divided	0.004219
the schematic	0.000692
a deterministic	0.002454
computer extracting	0.022727
fraction of	1.000000
MT performs	0.200000
annotation has	0.250000
and counter	0.001445
iteration	0.000029
these terms	0.023810
a succession	0.001227
Maximum entropy	0.666667
parsers	0.000376
a naval	0.001227
designers ,	1.000000
responsible	0.000029
Loebner	0.000029
and instead	0.001445
causing	0.000029
sentiment classification	0.040000
also continue	0.014493
information about	0.043478
-LRB- ≈çrƒÅti≈çnis	0.002710
is going	0.002033
would use	0.018868
GRACE d'√©valuation	1.000000
over sixty	0.083333
letter	0.000174
to correct	0.001328
also characterized	0.014493
Typical	0.000058
Process .	1.000000
1997 -LRB-	0.500000
professor	0.000029
meaningful symbol	0.125000
patterns in	0.200000
perform functions	0.090909
increase in	0.750000
and require	0.004335
prolific inventor	1.000000
improve readability	0.076923
copy	0.000029
which may	0.007246
improve performance	0.076923
save time	1.000000
the ability	0.001384
and converted	0.001445
Issues While	0.500000
looking at	0.200000
best model	0.055556
notion that	0.250000
as some	0.003484
also quite	0.014493
, Theo	0.000561
, enables	0.000561
disambiguation -LRB-	0.100000
on content	0.004717
cutoff to	1.000000
remember the	1.000000
, Alessandro	0.000561
process Flow	0.027778
M. De	0.250000
fair	0.000029
7110.65	0.000029
deemed	0.000058
known what	0.038462
fail	0.000087
only some	0.052632
intended meaning	0.200000
best	0.000521
accuracy was	0.032258
companies to	0.500000
in logical	0.001873
system recognizes	0.010753
score	0.000174
actioning it	1.000000
conceptual	0.000058
assigned keywords	0.500000
removed .	1.000000
, which	0.031443
represent a	0.222222
word separators	0.016667
two approaches	0.034483
a consideration	0.001227
simple queries	0.038462
cards	0.000029
DeRose 's	0.400000
subtasks that	0.500000
that assigns	0.003546
of British	0.000891
than speech	0.022222
readers	0.000058
profile feature	0.333333
With discontinuous	0.142857
learning methods	0.023256
adapted	0.000029
syntactic relations	0.076923
integrate reasoning	1.000000
languages which	0.020000
linguistically	0.000029
's idea	0.019608
involved ,	0.166667
summarization Like	0.020000
extraction	0.000897
Jaworski ,	1.000000
life	0.000116
model will	0.033333
among the	0.125000
structure .	0.166667
looks at	0.250000
Regardless of	1.000000
: Digitize	0.009804
keyphrase ,	0.052632
keyphrase .	0.052632
is in	0.006098
is it	0.002033
turns and	0.333333
than processing	0.022222
character recognition	0.500000
in those	0.001873
- Top-down	0.062500
or function	0.004505
sets ,	0.090909
A document	0.020000
, consisting	0.000561
task of	0.214286
naval battle	0.333333
a top-down	0.001227
, going	0.000561
relevant information	0.142857
, The	0.000561
user profile	0.071429
Books like	1.000000
developed and	0.038462
despite warnings	0.333333
text corpus	0.012579
same method	0.040000
fairly	0.000116
conversation or	0.250000
ambiguity than	0.125000
'' to	0.016129
distorted ,	0.500000
mutual information	1.000000
brain recognizes	0.333333
methods is	0.022727
augmented transition	1.000000
benefit from	1.000000
opinions	0.000058
the dynamic	0.000692
4 letters	0.200000
conceptual ontologies	0.500000
4 .	0.400000
4 ,	0.200000
a category	0.001227
probabilistic rules	0.142857
's coherence	0.019608
of Scotland	0.001783
is fairly	0.002033
Wide Web	1.000000
conducted in	0.400000
own right	0.166667
collections	0.000116
, electrical	0.000561
Algorithms Both	0.500000
Health Organization	0.500000
Apart	0.000029
equivalence is	0.500000
-LRB- Recall-Oriented	0.005420
possible	0.000695
possibly	0.000058
of discourse	0.009804
analog wave	0.500000
a revolution	0.001227
Grass	0.000116
rushing to	1.000000
construction of	0.666667
articulated	0.000029
left and	0.333333
resource consumption	0.200000
two measures	0.034483
typically from	0.055556
steps	0.000058
Greek and	0.333333
of OCR	0.003565
people	0.000463
commonplace	0.000029
entropy model	0.200000
<s> Even	0.000769
sociology	0.000029
for	0.008019
on automatically	0.004717
traditionally made	0.500000
Records -LRB-	1.000000
2007 and	0.200000
E-set	0.000029
overcome this	0.500000
hard to	0.333333
shifting	0.000029
F-16 VISTA	0.500000
may also	0.019231
the neural-network	0.000692
Canada are	0.166667
definition ,	0.400000
Georgetown experiment	1.000000
Inter-rater reliability	1.000000
vertex for	0.666667
in different	0.005618
Every acoustic	1.000000
Hirschman	0.000058
simulators with	1.000000
reducing	0.000058
started the	0.250000
Methods for	0.500000
A high	0.020000
<s> Parsing	0.003075
<s> Battle	0.000769
Approaches	0.000087
other are	0.014286
Wireless World	1.000000
icon	0.000029
happy	0.000029
MAHT and	1.000000
explicitly promoting	0.250000
rubric includes	1.000000
Statistical NLP	0.222222
meaningful information	0.125000
De Guzman	1.000000
deliberately inserts	1.000000
the case	0.005536
Language Processor	0.083333
Depending	0.000029
, entering	0.001123
proven	0.000029
like Japanese	0.035714
The parser	0.005208
though the	0.100000
exist	0.000029
phrases .	0.312500
phrases ,	0.125000
strengths and	0.500000
is being	0.006098
for What	0.003610
the vertices	0.000692
unambiguously	0.000029
computer science	0.090909
NIST	0.000058
task can	0.023810
Reading the	0.500000
late 1950s	0.111111
tagging words	0.040000
use techniques	0.013889
each observed	0.022222
full progress	0.200000
learn a	0.230769
language-processing tasks	1.000000
The improvement	0.005208
explore the	0.250000
: control	0.009804
cross-lingual questions	0.500000
first word	0.030303
meaning and	0.043478
dimensionality	0.000029
of logical	0.000891
his company	0.083333
, Systran	0.000561
process termed	0.027778
Arabic and	0.250000
Bernard Vauquois	1.000000
, by	0.002807
interface .	0.250000
also includes	0.014493
solved	0.000145
produced word	0.111111
team	0.000029
statistics -LRB-	0.125000
conveyed via	1.000000
prevent	0.000029
deciding whether	0.333333
Tablet	0.000058
largely an	0.200000
topics in	0.142857
with models	0.005464
into ``	0.012821
contrastive	0.000029
and domain	0.001445
current	0.000203
see LMF	0.050000
estimate sentence	0.250000
examples where	0.041667
assertive	0.000029
extraction and	0.064516
workday to	1.000000
statistical engine	0.030303
studied	0.000029
related in	0.066667
commonly	0.000232
about machine	0.025000
studies	0.000116
and Intelligence	0.001445
-LRB- RAE	0.002710
investigates the	1.000000
identification .	0.200000
all been	0.023256
the other	0.005536
Although these	0.125000
give	0.000116
: Error	0.009804
of ISO\/TC37	0.000891
introducing	0.000029
``	0.005472
tagger to	0.111111
be assumed	0.004219
recommendations and	1.000000
and world	0.001445
ambitious projects	1.000000
translation MAHT	0.013514
systems depended	0.008929
Unsupervised keyphrase	0.333333
a very	0.013497
descriptor	0.000029
values	0.000232
believed	0.000029
Our	0.000087
design and	0.250000
been successfully	0.014706
walks .	0.500000
some states	0.012048
recognition research	0.008264
map one	0.500000
`` generalized	0.005291
necessary ,	0.100000
<s> POS	0.000769
speech and	0.013158
with them	0.016393
Who	0.000058
triples that	0.333333
single binary	0.071429
parameter	0.000029
T. 1991	1.000000
differ ,	0.333333
applications	0.000724
date	0.000087
appends the	1.000000
data	0.002229
well that	0.035714
words occur	0.009174
& Lehrberger	0.125000
ISO\/TC37	0.000029
yielding	0.000029
decades -LRB-	1.000000
encourage systems	1.000000
better understanding	0.111111
relations -LRB-	0.083333
, resulting	0.000561
text summaries	0.006289
, size	0.000561
PageRank	0.000174
a movie	0.002454
ICR make	0.333333
and developed	0.002890
is dependency	0.002033
code of	0.142857
decelerations	0.000029
code on	0.142857
ANR-Passage project	1.000000
decades	0.000029
presented to	0.166667
problem involves	0.045455
and there	0.005780
mention that	0.333333
Maximum	0.000087
records	0.000116
Angenot ,	1.000000
allows movement	0.125000
which they	0.014493
as their	0.006969
Direct Voice	1.000000
PCFGs	0.000029
properly the	0.500000
sequences that	0.111111
Battle management	0.500000
Transcription	0.000029
Snyder	0.000058
the draft	0.000692
experiment was	0.400000
or automotive	0.004505
Online ,	0.500000
word spaces	0.016667
audio ,	1.000000
contained	0.000029
spectrum using	1.000000
Joe	0.000029
are typically	0.012448
interactivity	0.000029
of mainland	0.001783
uncertainties	0.000029
Braille	0.000029
the Ohio	0.000692
million	0.000087
decision-support aids	1.000000
possibility	0.000116
was considerable	0.012987
analysis model	0.015385
avoid confusion	1.000000
query relevant	0.666667
currently the	0.142857
address this	0.250000
science that	0.100000
need for	0.142857
are exceptions	0.004149
PC can	0.250000
nested	0.000029
answering There	0.083333
blocks ,	0.250000
conditions .	0.200000
text cohesion	0.006289
indicate	0.000087
2	0.000145
multiple part-of-speech	0.076923
to maintain	0.001328
tree -LRB-	1.000000
her to	0.500000
product was	0.142857
representing	0.000058
developed to	0.038462
where an	0.028571
page scanner	0.142857
future	0.000087
Xuedong Huang	1.000000
cross-lingual	0.000058
where at	0.028571
systems take	0.008929
technology .	0.090909
technology ,	0.136364
considerably	0.000029
similar clues	0.037037
Document structuring	0.250000
intuitive sense	1.000000
English prose	0.027027
in walking	0.001873
morphology -LRB-	0.142857
other to	0.014286
domain-specific keyphrase	0.500000
take	0.000290
evaluation has	0.018519
<s> Information	0.000769
have ''	0.009615
common use	0.080000
then extrapolate	0.028571
use considers	0.013889
<s> Where	0.000769
decisions or	0.100000
'' with	0.021505
re-encode the	1.000000
called recursively	0.055556
Trained	0.000029
distinct parts	0.142857
walking	0.000087
topic were	0.125000
definite	0.000029
system depend	0.010753
hand-crafted knowledge	0.500000
After the	0.333333
to ignore	0.001328
of many	0.001783
the AVRADA	0.000692
language understanding	0.094595
-RRB- :	0.025352
expressed in	0.166667
or sentences	0.004505
fastens -LRB-	1.000000
of commercial	0.000891
inflectional morphology	1.000000
System -RRB-	1.000000
morphological	0.000087
greater than	0.333333
an automatic	0.015152
Products	0.000058
have used	0.019231
this way	0.021978
contain the	0.166667
Intelligence and	0.333333
neighbors are	0.333333
went to	0.400000
easier for	0.125000
rule-based algorithms	0.142857
Specifically	0.000029
Yes\/No	0.000029
happen between	1.000000
voicemail to	1.000000
isloated and	1.000000
components that	0.200000
not always	0.008929
BLEU is	0.333333
stochastic methods	0.125000
Driver-license	0.000029
an autopilot	0.007576
Bible	0.000029
while verbs	0.050000
documents at	0.026316
through its	0.125000
an edge	0.015152
the interlingua	0.000692
lexical resources	0.076923
HMM states	0.333333
deduction	0.000029
<s> Shared	0.000769
expression	0.000290
<s> Matches	0.000769
to closely	0.001328
,	0.051562
management of	0.285714
comprehensive hand-crafted	0.200000
though such	0.100000
data mining	0.025974
dispense with	1.000000
better	0.000261
combines	0.000029
other task	0.014286
combined	0.000058
same characters	0.040000
Bottom-up parsing	1.000000
startlingly human-like	1.000000
important by	0.062500
waves describe	0.142857
European Parliament	0.333333
or language	0.004505
Projects Agency	1.000000
be apparent	0.004219
consist of	1.000000
standard -LRB-	0.142857
Shift-Reduce	0.000029
<s> Introduction	0.000769
sentences have	0.026316
project .	0.076923
project ,	0.384615
the pragmatics	0.000692
include SpeechTEK	0.037037
<s> Vulcan	0.000769
be ?	0.004219
exception ,	1.000000
Grows :	1.000000
, keyphrases	0.000561
structures of	0.200000
be .	0.004219
that closely	0.003546
frequencies ,	0.500000
bridge the	1.000000
analysis to	0.015385
Orleans by	0.500000
computer read	0.022727
, searching	0.000561
known as	0.384615
language to	0.027027
See chart	0.166667
`` Tell	0.005291
question .	0.047619
question ,	0.261905
by highly	0.005714
I	0.000029
usually have	0.031250
unmanageable	0.000029
defined to	0.166667
be a	0.054852
fall into	0.500000
technology development	0.045455
, funding	0.001684
costs	0.000029
Analysis &	0.200000
any learning	0.032258
that TextRank	0.007092
recognition products	0.008264
What should	0.090909
Judith	0.000029
table ''	0.142857
the grammatical	0.002076
SVM	0.000029
greatly with	0.142857
unknowns ,	1.000000
may happen	0.019231
answer extraction	0.066667
responding to	1.000000
projects never	0.500000
then there	0.028571
voice user	0.076923
of 2009	0.000891
Navy ,	1.000000
of 2007	0.001783
a precise	0.001227
attempt to	1.000000
Air Force	0.666667
parser The	0.125000
is functioning	0.002033
beyond the	0.500000
`` Computing	0.005291
voice and	0.076923
vendors speech	0.250000
short paragraph	0.125000
function with	0.125000
authenticate	0.000029
dimensions	0.000087
it Contains	0.008547
might appear	0.038462
identifying trends	0.166667
Projects	0.000029
Algorithm -RRB-	1.000000
A somewhat	0.020000
Other issues	0.142857
knowledge of	0.148148
even human	0.037037
below 50	0.200000
acoustic	0.000174
Foucault ,	0.333333
this information	0.010989
industry	0.000087
Jefferson ,	1.000000
of tourism	0.000891
a rate	0.001227
act	0.000116
where syllables	0.028571
to think	0.001328
image	0.000087
instead recognizes	0.142857
automated language	0.142857
parties	0.000029
its vocabulary	0.028571
like Page\/Lex\/TextRank	0.035714
Decoding of	0.500000
makes use	0.125000
tokens ,	0.142857
research teams	0.023810
Commanders and	1.000000
knowledge or	0.037037
abbreviations -RRB-	0.200000
translation Example-based	0.013514
general speaker	0.045455
help improve	0.111111
taught	0.000087
corresponding text	0.166667
agree	0.000087
Therein lies	1.000000
gone	0.000029
World Health	0.142857
an	0.003822
-LRB- 1993	0.002710
as	0.008309
a syntactic	0.001227
at	0.001969
-LRB- 1995	0.002710
of characters	0.001783
in common	0.003745
poor coverage	1.000000
the context	0.004152
space exploration	0.200000
Semantic analysis	0.333333
ambiguities and	0.250000
entry from	0.250000
vocabulary	0.000232
American prisoners	0.200000
classifiers -RRB-	0.500000
slang	0.000029
Telematics	0.000029
1978 Kurzweil	0.333333
related languages	0.066667
funding continued	0.125000
objects listed	0.200000
mimic	0.000029
different vendors	0.020408
Understudy for	1.000000
to appear	0.002656
original	0.000376
Canada	0.000174
about how	0.025000
<s> The	0.112221
growing field	0.500000
toy world	0.500000
technology has	0.045455
reasoning	0.000203
, various	0.000561
be nested	0.004219
which class	0.007246
than 1	0.022222
-RRB- examples	0.002817
MT Hybrid	0.200000
that involve	0.003546
authenticate or	1.000000
small incremental	0.111111
dimensions of	0.666667
match the	0.333333
researchers in	0.100000
condition	0.000029
% -RRB-	0.025641
`	0.000463
some time	0.024096
score based	0.166667
than a	0.111111
accompanying	0.000029
sentences Grass	0.013158
within three	0.111111
Vito	0.000029
queries ,	0.333333
`` Dogged	0.005291
Acoustical	0.000058
sublanguage analysis	0.333333
and others	0.002890
hopefully	0.000029
not spend	0.008929
the informal	0.000692
into modern	0.012821
section	0.000174
<s> Answer	0.001537
OCR-A font	1.000000
training a	0.035714
confirmed by	1.000000
contrast	0.000232
would reduce	0.018868
hours	0.000058
card spending	0.250000
real ATC	0.111111
human variability	0.021739
different grammatical	0.020408
versions needed	0.333333
parsers will	0.153846
While supervised	0.200000
identified is	0.200000
without understanding	0.076923
no knowledge	0.076923
person uses	0.052632
MLLR	0.000029
MLLT	0.000029
action	0.000145
training .	0.035714
on any	0.018868
perfect -LRB-	1.000000
which range	0.007246
full stop	0.400000
research to	0.023810
they take	0.025000
language for	0.020270
and grammar	0.002890
not President	0.008929
also require	0.014493
representation into	0.052632
of part	0.000891
was used	0.051948
phrases are	0.062500
will contain	0.028571
Meaningful	0.000029
speech can	0.013158
rules to	0.069767
procedure lies	0.333333
features characterize	0.038462
the human	0.002076
keeping	0.000058
science	0.000290
much easier	0.045455
if the	0.357143
indicating	0.000029
due to	0.400000
TNO developed	1.000000
in that	0.003745
Conference	0.000058
produces less	0.250000
prefer to	0.500000
more robust	0.021053
states	0.000116
sense	0.000232
UMLS	0.000029
<s> Grammatical	0.000769
approaches used	0.035714
information	0.001332
well captured	0.035714
Nagao in	1.000000
machine-learning	0.000116
SHRDLU simulated	0.166667
socio-psychological	0.000029
program were	0.045455
rank unigrams	0.166667
the representation	0.000692
evaluations	0.000174
summarization	0.001448
imagery	0.000029
<s> the	0.000769
capabilities ,	0.200000
meaningful units	0.125000
and Tigrinya	0.001445
radios	0.000029
extraction as	0.064516
In 1949	0.009524
of n-dimensional	0.000891
representation can	0.052632
science ,	0.400000
of identifiers	0.000891
opinion expressed	0.200000
, linguistic	0.000561
two sentences	0.068966
dependent on	0.666667
, facts	0.000561
is based	0.008130
the probabilities	0.002768
pragmatics .	0.333333
formal modeling	0.111111
claiming to	1.000000
output scores	0.038462
common when	0.040000
quite similar	0.125000
been carried	0.014706
tools require	0.166667
U.S. Patent	0.428571
always	0.000087
Newton	0.000029
blogs ,	0.500000
this would	0.010989
of ability	0.000891
errata	0.000029
often a	0.022727
, rather	0.001123
perhaps trivial	0.166667
parser generates	0.062500
psychology	0.000116
intrinsic properties	0.250000
grouped with	0.500000
Translations	0.000029
Machine Aided	0.111111
which includes	0.014493
linguistic knowledge	0.062500
informativeness .	0.333333
triple probabilities	1.000000
for can	0.003610
often .	0.022727
often ,	0.022727
imaging	0.000029
<s> Stages	0.000769
imagine	0.000029
for English	0.003610
must be	0.428571
Shepard 's	0.333333
overlaps between	0.500000
<s> Brain	0.000769
commands .	0.400000
pronunciations	0.000029
Linguistics	0.000087
whole words	0.111111
number	0.001245
create ''	0.058824
two given	0.034483
explored using	0.500000
use natural	0.013889
Phonemes ,	1.000000
Corporation originally	0.250000
management Question	0.142857
which creates	0.007246
and insurance	0.001445
declared during	0.500000
both ``	0.064516
relationship	0.000174
showed that	0.750000
-LRB- University	0.002710
immediate	0.000029
consult	0.000029
focusing	0.000029
original .	0.076923
<s> Task	0.000769
determines	0.000087
KEA	0.000029
for large-vocabulary	0.003610
so-called ROUGE	0.333333
or applying	0.004505
some kind	0.048193
for the	0.111913
Adverse	0.000058
, pollen	0.000561
He tried	0.125000
Transform ,	1.000000
difficult problems	0.107143
analogy	0.000029
slang .	1.000000
is usually	0.016260
substantial amount	0.200000
play	0.000029
was much	0.025974
important memorandum	0.062500
than whole	0.022222
that nuggets	0.003546
a translation	0.002454
vertex would	0.333333
cover	0.000029
decisions .	0.100000
fast-evolving field	1.000000
2PR	0.000029
international relations	0.500000
the labor	0.000692
applies to	0.142857
algorithms is	0.028571
endeavors such	1.000000
has focused	0.047619
expressed	0.000174
take as	0.100000
impact	0.000058
other country	0.014286
failed	0.000058
TextRank	0.000405
five-star	0.000029
closely	0.000145
problems .	0.176471
problems ,	0.352941
they would	0.025000
paper data	0.090909
made in	0.125000
Major tasks	0.500000
and alignment	0.001445
-LRB- DeRose	0.002710
set	0.001129
For	0.001766
at characters	0.014706
see	0.000579
and R.	0.001445
These rules	0.058824
text printed	0.006289
radio frequencies	1.000000
for gestures	0.003610
a question	0.008589
invented examples	0.500000
large-vocabulary speech	0.666667
FoG	0.000058
the sampling	0.000692
as Google	0.003484
way we	0.083333
determine the	0.391304
Anaphora resolution	1.000000
concept -LRB-	0.250000
co-occurrence graph	0.666667
simply ranks	0.083333
logic structures	0.250000
to error	0.001328
whole	0.000261
agglutinative languages	1.000000
applications in	0.080000
corresponds	0.000029
community	0.000029
to help	0.002656
as humans	0.003484
applications it	0.040000
Separate words	0.500000
their lack	0.029412
difference can	0.250000
their stationary	0.029412
citations	0.000087
volume of	0.500000
as relations	0.003484
XML	0.000029
is distinct	0.002033
, different	0.001684
shifted priorities	1.000000
, Wendy	0.000561
its users	0.028571
edges with	0.142857
the predicted	0.000692
used all	0.008850
corpora	0.000318
training document	0.035714
accommodate ambiguity	0.400000
are created	0.012448
formats	0.000029
PangeaMT ,	1.000000
shed light	1.000000
probability what	0.142857
we would	0.066667
increases in	1.000000
all cases	0.023256
made with	0.062500
Mars Microphone	0.500000
is different	0.002033
expand our	1.000000
more formal	0.010526
features like	0.038462
understanding programs	0.030303
The product	0.010417
-RRB- \/	0.002817
or some	0.013514
levels	0.000637
Campaigns -RRB-	1.000000
is again	0.002033
recent	0.000232
canned	0.000058
correlation between	0.500000
Rate	0.000058
single words	0.071429
that represents	0.003546
application may	0.071429
chosen is	0.200000
, Brenton	0.000561
used the	0.008850
case .	0.176471
case ,	0.176471
order ''	0.071429
model that	0.133333
dialogue in	0.500000
about 70	0.050000
had plateaued	0.071429
European Union	0.333333
um ''	1.000000
allows users	0.250000
be ``	0.004219
location	0.000029
relevance	0.000087
are hardly	0.004149
subtasks	0.000058
textbook is	0.500000
sales reports	0.333333
linguistics -LRB-	0.050000
Larry R.	0.500000
apply the	0.200000
not hear	0.008929
of sound	0.001783
unweighted edges	1.000000
currently in	0.142857
hopefully better	1.000000
often ambiguous	0.022727
have also	0.009615
stop character	1.000000
printed pages	0.083333
simple voice	0.038462
report in	0.250000
tagging has	0.040000
block of	1.000000
be	0.006861
interpreters	0.000029
protection from	1.000000
agreement	0.000087
EndWar and	1.000000
adaptation greatly	0.333333
VITO	0.000029
constructed by	0.500000
of virtual	0.000891
major degradation	0.083333
by	0.005066
in generating	0.001873
anything	0.000029
of unlabeled	0.000891
just keeping	0.111111
A restricted	0.020000
Jones Street	1.000000
processing ''	0.037037
computational	0.000290
both isloated	0.032258
bites dog	0.333333
ACL	0.000058
adverbs	0.000029
primarily	0.000058
Again ,	1.000000
shops in	1.000000
and trigram	0.001445
build on	0.333333
retrieving	0.000029
from both	0.009615
specifically	0.000058
there were	0.075000
the ten-year-long	0.000692
1982 Gary	0.333333
translator for	0.142857
problem with	0.022727
to authenticate	0.001328
meaning into	0.043478
relaxed	0.000029
was recognized	0.012987
, Jonathan	0.000561
of negative	0.000891
line	0.000087
is at	0.002033
is as	0.002033
merely copy	0.500000
themselves simply	0.250000
with references	0.005464
be taken	0.004219
basic techniques	0.076923
optimizing a	1.000000
defined	0.000174
customize the	0.500000
users to	0.222222
defines	0.000058
POS tagger	0.307692
<s> Consider	0.001537
small range	0.111111
points	0.000058
are multiple	0.004149
of ways	0.001783
knowledge .	0.037037
robots	0.000029
We have	0.142857
methods QA	0.022727
variant of	1.000000
decisions --	0.100000
term first	0.055556
networks .	0.214286
often inaccurate	0.022727
essay	0.000029
code	0.000203
`` Application-Oriented	0.005291
a typical	0.002454
results	0.000608
noise in	0.125000
Stef	0.000029
Street Journal	0.666667
with medium	0.005464
must interpret	0.071429
cursive script	0.400000
garden	0.000029
categorization ,	1.000000
Speech Writing	0.032258
the translator	0.000692
not describe	0.008929
after John	0.083333
categories	0.000261
and orthography	0.001445
in information	0.001873
identify new	0.083333
, definition	0.000561
the sentences	0.005536
are keyphrase	0.004149
to derive	0.001328
applications .	0.160000
Cross-Sentence Information	1.000000
applications ,	0.160000
internet discussion	1.000000
depth of	0.333333
now commonplace	0.076923
an Inuit	0.007576
returned by	0.250000
index	0.000029
funding Measuring	0.125000
Alan	0.000029
better than	0.111111
typically involved	0.055556
textual summaries	0.200000
units --	0.142857
led	0.000087
Richard Kittredge	1.000000
non-linearly	0.000029
language -RRB-	0.013514
, PAM	0.000561
, mainly	0.000561
, particularly	0.001123
recognition deteriorated	0.008264
Energy	0.000029
EMNLP	0.000029
place at	0.250000
find answers	0.076923
that will	0.007092
shown to	0.400000
to match	0.002656
F-16	0.000058
which generates	0.007246
decisions based	0.200000
Prominent discourse	1.000000
and simpler	0.001445
editing and	0.500000
for their	0.007220
became less	0.200000
7110.65 details	1.000000
recently identified	0.333333
Applied Intelligence	0.500000
comes to	0.200000
saw the	1.000000
both the	0.064516
occurred	0.000029
USAF	0.000029
<s> Recall	0.002306
how it	0.068966
relationships .	0.166667
had been	0.071429
At the	0.333333
Systems -RRB-	0.083333
reports ,	0.200000
used for	0.132743
, since	0.002807
symbols ,	0.333333
the computer-aided	0.000692
is doing	0.002033
-LRB- monetary	0.002710
high	0.000521
, recently	0.000561
central ''	0.666667
Several	0.000087
separated out	0.333333
difficult words	0.035714
He entered	0.125000
often as	0.045455
While some	0.200000
imagine the	1.000000
blocks	0.000116
generating the	0.200000
four step	0.142857
Ingria	0.000029
technologies to	0.250000
reliable hits	0.250000
efficiently	0.000029
Charles Goodwin	1.000000
handling such	0.500000
recognition accuracy	0.057851
appear in	0.437500
worth remembering	0.500000
campaign on	0.200000
first stage	0.030303
business ,	0.250000
, determine	0.003369
which can	0.036232
the figure	0.000692
Political discourse	1.000000
text comprehension	0.006289
jet fighter	1.000000
achieved accuracy	0.200000
whole word	0.111111
i.e. determining	0.052632
be compared	0.004219
bar	0.000058
insufficient .	1.000000
the pollen	0.000692
, answer	0.000561
Vito Technology	1.000000
merge	0.000029
computerization of	1.000000
stochastic .	0.125000
stochastic ,	0.250000
forms than	0.166667
inter-texual	0.000058
frequency	0.000058
opportunity rather	0.500000
were SHRDLU	0.024390
as Robert	0.003484
used a	0.026549
knowledge that	0.037037
, partially	0.000561
interactions	0.000029
Processor is	1.000000
discourse grammar	0.027778
'' as	0.026882
Aided	0.000087
Lander Automatic	0.500000
interactions between	1.000000
because they	0.133333
once you	1.000000
Internet financial	0.500000
used ,	0.070796
representing printed	0.500000
used .	0.044248
individual lines	0.083333
analyze the	0.250000
a letter	0.001227
Automated Summarizers	0.500000
Graesser ,	1.000000
amongst a	1.000000
, Louise	0.000561
sentence Grass	0.020833
of Turney	0.001783
requires in-depth	0.062500
The topic	0.005208
that by	0.003546
, writing	0.001123
and must	0.001445
increased from	0.600000
best modern	0.055556
so that	0.200000
used SYSTRAN	0.008850
2010 -RRB-	0.333333
methods try	0.022727
models have	0.038462
particular event	0.076923
food and	1.000000
automatically to	0.047619
initial capital	0.333333
Orientation	0.000029
language expression	0.006757
with specific	0.005464
coreference resolution	1.000000
<s> All	0.000769
, low-resolution	0.000561
way .	0.041667
phonetically	0.000029
genre .	0.500000
spelled	0.000029
robot	0.000058
have complex	0.009615
conversations such	0.333333
recognition computer	0.016529
keep a	0.333333
of tokens	0.001783
clearly	0.000087
given text	0.041667
documents	0.001100
studying	0.000029
mechanism	0.000029
decomposing	0.000029
a robotic	0.001227
NLP -RRB-	0.085106
on dictionary	0.004717
competence	0.000029
controlled by	1.000000
algorithms used	0.028571
after 2,000	0.083333
look at	0.400000
said	0.000029
appear near	0.062500
so-called discriminative	0.333333
each for	0.022222
Society ,	1.000000
2007 is	0.200000
1998 -RRB-	0.500000
are also	0.033195
its own	0.142857
but much	0.014706
coefficients to	0.250000
would check	0.018868
to infer	0.001328
application .	0.071429
application ,	0.142857
at different	0.014706
was painstakingly	0.012987
theories on	0.200000
the target	0.006228
reasoning approach	0.142857
ROUGE-1 values	0.200000
theories of	0.600000
Independence	0.000029
the earlier	0.000692
dependent system	0.333333
not possible	0.008929
speech data	0.006579
: Overall	0.009804
Whether	0.000058
nodes	0.000203
other possible	0.014286
use following	0.013889
Establishment -LRB-	1.000000
Afghanistan	0.000029
analysis aims	0.015385
larger collection	0.062500
create more	0.058824
edition	0.000029
D. Faber	0.200000
which use	0.007246
Words in	0.250000
CLAWS	0.000116
require some	0.045455
standard written	0.071429
taken to	0.333333
data can	0.025974
popular example	0.111111
email	0.000058
are discussed	0.004149
, Englund	0.000561
success in	0.200000
like in	0.035714
In 1929	0.009524
answer highlighted	0.033333
book ''	0.125000
two classes	0.034483
restrictions	0.000029
Another research	0.076923
Jim Martin	1.000000
match up	0.166667
become clear	0.250000
values of	0.500000
ca	0.000029
on attaching	0.009434
description and	1.000000
architecture Regardless	0.500000
system might	0.010753
to eigenvalue	0.001328
fire ''	0.500000
better scoring	0.111111
phrase appears	0.100000
Gee	0.000029
on extractive	0.004717
conceptual dependency	0.500000
only to	0.026316
psychotherapist	0.000029
door of	0.250000
are beyond	0.004149
photocells ,	1.000000
of software	0.000891
learning disabilities	0.023256
where it	0.028571
by spaces	0.005714
IEEE ASRU	0.333333
linguistic and	0.062500
, parsing	0.001684
shared tasks	0.500000
software .	0.037037
maintain tractability	1.000000
glue text	1.000000
surprisingly	0.000087
seen before	0.200000
output that	0.076923
off on	0.500000
included a	0.125000
the ``	0.003460
highlighted	0.000029
included :	0.125000
field are	0.037037
utility with	0.500000
forecasts	0.000145
proposal for	1.000000
of front-end	0.000891
intra-texual	0.000029
angle .	1.000000
related to	0.266667
a bunch	0.001227
multiple references	0.076923
command	0.000058
, similarity	0.000561
in two	0.001873
surprisingly difficult	0.333333
calculator or	0.500000
, however	0.006176
encyclopedia ''	1.000000
glue	0.000029
or lowering	0.004505
isolation .	0.500000
arm to	1.000000
of an	0.011586
of as	0.001783
including :	0.142857
of at	0.000891
comprehend Morse	1.000000
<s> People	0.000769
Unfortunately	0.000029
professional translator	1.000000
breadth and	0.500000
Text-to-speech	0.000029
or they	0.004505
'' each	0.005376
Our brain	0.666667
judge fluency	0.250000
imagery ,	1.000000
manipulate it	0.333333
relations are	0.083333
corpus ,	0.064516
make decisions	0.050000
corpus .	0.032258
Michael Dyer	0.250000
exercises on	1.000000
filtered from	0.333333
, pre-defined	0.000561
text lacks	0.006289
not also	0.008929
database industry	0.100000
leverages	0.000029
data analysis	0.012987
for an	0.003610
derived by	0.333333
the edges	0.001384
OCR software	0.081633
textual corpora	0.200000
the order	0.001384
, definitional	0.000561
stage	0.000145
gained	0.000058
carefully design	1.000000
and FAA	0.001445
useful only	0.071429
advanced scanning	0.400000
learning that	0.023256
this .	0.010989
this ,	0.043956
may explore	0.019231
for abbreviations	0.003610
good translation	0.076923
to paper-intensive	0.001328
or profession	0.004505
naturally	0.000058
function	0.000232
Lakoff ,	1.000000
damping factor	1.000000
a real-time	0.001227
these devices	0.023810
, wrote	0.000561
construction	0.000087
segmentation systems	0.030303
vector of	0.333333
question-answering	0.000058
resorting to	1.000000
count	0.000145
aims to	0.666667
recognizing hand-printed	0.200000
official	0.000029
However sentence	0.027027
Kintsch ,	1.000000
+5 scale	1.000000
recognize	0.000261
question focus	0.023810
denote	0.000058
grammar Text	0.027027
events .	1.000000
universal encyclopedia	0.333333
Paul Drew	0.200000
, are	0.001123
variety	0.000232
informativeness	0.000087
, speech-to-text	0.000561
Universal Part-of-Speech	1.000000
our life	0.200000
dogs ''	0.571429
deterministic decisions	0.250000
in October	0.001873
arrive at	1.000000
the augmented	0.000692
separate it	0.200000
the size	0.001384
method simply	0.062500
Page	0.000029
fundamentally	0.000029
as focusing	0.003484
alphabet ,	0.666667
keyphrases as	0.028571
document set	0.027778
larger tasks	0.062500
triples or	0.333333
perfectly ,	1.000000
to expand	0.001328
arbitrary piece	0.333333
Back-End or	1.000000
developed at	0.076923
arbitrary length	0.333333
more software	0.010526
for naval	0.003610
Descartes proposed	1.000000
animation ,	1.000000
tagger .	0.111111
adjust\/correct the	1.000000
other scripts	0.014286
adaptive	0.000087
requiring knowledge	0.500000
lessening of	1.000000
several variables	0.045455
role as	0.250000
index entries	1.000000
upload	0.000029
that serve	0.003546
in sentiment	0.001873
names that	0.285714
and Speech	0.001445
established	0.000029
Mirage aircraft	1.000000
phonetic segments	0.500000
output .	0.153846
+	0.000174
Ensemble	0.000029
to model	0.001328
above	0.000376
the summers	0.000692
training techniques	0.035714
are performed	0.004149
of disparate	0.000891
Langues vol-2	1.000000
techniques to	0.173913
characterizes its	1.000000
parameters related	0.250000
if uttered	0.035714
output ,	0.038462
study	0.000116
desired identification	0.200000
overall contextual	0.166667
to specific	0.001328
benchmark tests	1.000000
to discrete	0.001328
threshold is	0.250000
statistics of	0.125000
states such	0.250000
be run	0.004219
world knowledge	0.133333
applies directly	0.142857
false starts	0.500000
annotation process	0.250000
but article	0.014706
Conference Technolangue\/Easy	0.500000
phrase-structure grammars	1.000000
Rabiner	0.000029
boundary information	0.166667
check for	0.500000
Digital Syphon	1.000000
direct a	0.166667
service ,	0.400000
service .	0.200000
identified the	0.200000
Even though	1.000000
analytical artificial	0.500000
could	0.000463
<s> Again	0.000769
sentence-ending markers	1.000000
analyze all	0.250000
sequential lines	1.000000
Another project	0.076923
indifferent	0.000029
automata that	1.000000
term artificial	0.055556
changes which	1.000000
negligence ''	1.000000
TextRank does	0.071429
Realisation :	1.000000
is strong	0.002033
SHRDLU provided	0.166667
classifying	0.000145
speech of	0.006579
as needed	0.003484
-LRB- OCR	0.002710
are some	0.004149
expressivity of	1.000000
problems and	0.117647
as mentioned	0.003484
people to	0.125000
nascent	0.000029
a restricted	0.001227
conducted with	0.200000
<s> Extractive	0.000769
a suitable	0.003681
digitalized :	1.000000
consonants and	0.333333
choose	0.000058
result -LRB-	0.090909
Variation	0.000029
human --	0.021739
later users	0.100000
, Teun	0.000561
part that	0.037037
and simply	0.001445
newspaper pages	0.333333
sub-field	0.000029
VISTA -RRB-	1.000000
unmanageable .	1.000000
potentially	0.000087
then	0.001013
them	0.000550
affected	0.000029
is broken	0.002033
contain multiple	0.083333
amenable	0.000029
they	0.001158
Environmental	0.000029
models ...	0.038462
punctuation marks	0.285714
at run-time	0.014706
this case	0.010989
classified	0.000029
backgrounds	0.000029
<s> Discursive	0.000769
provide a	0.333333
MARGIE	0.000029
Language ,	0.083333
ATNs and	0.333333
'' approaches	0.010753
classifies	0.000029
classifier	0.000203
Words ,	0.250000
while Church	0.050000
instance ,	0.642857
Words :	0.250000
posts and	1.000000
reasonable approximation	0.500000
over the	0.250000
ones focus	0.100000
DUC 2001	1.000000
if-then	0.000058
to and	0.001328
forth	0.000029
entities ''	0.142857
the fact	0.002768
language constructs	0.006757
that says	0.003546
produce output	0.090909
was walking	0.012987
to very	0.001328
generally more	0.181818
bigrams ,	1.000000
When a	0.142857
incorporates	0.000029
Eastern	0.000029
noise problem	0.125000
prisoner of	1.000000
hand-annotated	0.000058
still quite	0.066667
a hidden	0.001227
and larger	0.002890
simply requires	0.083333
logical ,	0.166667
' lengths	0.052632
two steps	0.034483
polarity and	0.125000
Vocabulary size	0.333333
What are	0.363636
rev ,	1.000000
appropriately ,	0.500000
simply guessed	0.083333
the HTK	0.000692
B	0.000029
locate the	1.000000
patterns of	0.200000
of democracy	0.000891
add them	1.000000
the similarity	0.000692
translating	0.000116
translation -RRB-	0.027027
pre-determined	0.000029
will replace	0.028571
See	0.000174
been changed	0.014706
solely	0.000029
during the	0.400000
Challenges shared-task	1.000000
graphics	0.000029
manner	0.000116
to himself	0.001328
appropriately spelled	0.500000
Correct	0.000029
strength	0.000145
given corpus	0.041667
related data	0.066667
`` Mr.	0.005291
response ,	0.500000
questioner 's	0.250000
-LRB- more	0.005420
to government	0.001328
Rule-based	0.000058
Mr. Smith	0.500000
Ren√©	0.000029
translation programs	0.013514
left	0.000174
notion	0.000116
heuristics	0.000058
if you	0.071429
required the	0.142857
Verbyx VRX	1.000000
the essence	0.001384
of potential	0.001783
possible sentences	0.041667
specification is	0.500000
latent	0.000029
existing multilingual	0.200000
standard corpora	0.071429
<s> Correct	0.000769
-LRB- see	0.032520
etc. --	0.045455
figure out	0.500000
splitting may	0.500000
ability of	0.250000
such keyphrases	0.008130
contains errors	0.200000
do	0.000753
de	0.000058
paper-intensive	0.000029
while LexRank	0.100000
Rule-based The	0.500000
du	0.000029
Statistics derived	0.333333
to much	0.001328
so has	0.033333
by computer	0.017143
user needs	0.071429
, text-to-speech	0.001123
Using almost	0.500000
using both	0.016949
output of	0.153846
QA -RRB-	0.047619
depends	0.000232
of printed	0.001783
these numbers	0.047619
room acoustics	1.000000
likelihood linear	0.666667
High-performance	0.000029
are being	0.008299
the Pyramid	0.000692
by highlighting	0.005714
researchers undertake	0.100000
increasing G-loads	0.333333
a sample	0.001227
demonstrations ,	1.000000
correct summary	0.066667
medial and	1.000000
restricted world	0.250000
extraction is	0.064516
particularly effective	0.200000
Navy	0.000029
con	0.000029
it up	0.008547
Initial	0.000029
eyes-busy	0.000029
polynomial	0.000029
top ranking	0.200000
their system	0.029412
STT ''	1.000000
require extensive	0.090909
XML documents	1.000000
sounds of	0.133333
dozens	0.000029
sounds on	0.066667
Greek ,	0.333333
Turkish ,	1.000000
computer databases	0.022727
coherent	0.000145
or identical	0.004505
translation tries	0.013514
principle ,	1.000000
This article	0.015873
physician	0.000029
and Lao	0.001445
and classifying	0.001445
-LRB- Microsoft	0.002710
first -LRB-	0.030303
algorithms which	0.028571
voice	0.000376
usually do	0.031250
compared syntactic	0.142857
if there	0.071429
, mail	0.000561
discourses	0.000058
Rubin	0.000029
prepare formal	1.000000
Number =	1.000000
80 %	1.000000
comparative	0.000029
sort of	0.666667
confirmed	0.000029
patent	0.000116
punctuation	0.000203
meaningless tokens	1.000000
chunk of	1.000000
ambiguities or	0.250000
very small	0.048780
black holes	1.000000
training data	0.357143
is quite	0.002033
representations such	0.250000
the task	0.004844
detail but	0.500000
That is	1.000000
kept	0.000029
1979	0.000029
local collection	0.333333
1977	0.000029
1976	0.000058
1975	0.000029
1974	0.000029
questions and	0.038462
1971	0.000087
1970	0.000087
different parts	0.040816
Many ATC	0.083333
the	0.041834
for POS	0.003610
distinguish between	0.400000
Forces Security	1.000000
become well	0.250000
on less	0.004717
label discourse	1.000000
adding	0.000058
life scientists	0.250000
transformed	0.000029
helped the	0.333333
more appropriately	0.010526
variables such	1.000000
pronoun ,	1.000000
caps	0.000029
PageRank on	0.166667
The hidden	0.005208
<s> Referring	0.000769
limit is	0.250000
Sept. 1955	1.000000
security	0.000029
see it	0.050000
, signed	0.000561
see is	0.050000
text analytics	0.006289
Web-based +	0.333333
Sound is	0.333333
, rhetoric	0.000561
, roughness	0.000561
productions	0.000029
of documents	0.004456
telephony ,	0.666667
Lee	0.000029
Relationship	0.000029
Leo	0.000029
slot represents	1.000000
produce one	0.045455
questions can	0.038462
The human	0.005208
and differing	0.001445
to mental	0.001328
summarization task	0.020000
clean hand-printed	0.500000
and can	0.011561
of linguistic	0.001783
implementations of	1.000000
online reviews	0.250000
as English	0.010453
a horizontal	0.001227
among named	0.125000
by voice	0.011429
the common	0.000692
degree .	0.166667
typewritten reports	0.200000
avoids overfitting	1.000000
when summarizing	0.028571
determine which	0.086957
strongly than	0.500000
<s> Dictionary-based	0.000769
words ,	0.137615
words .	0.146789
test as	0.100000
difficult task	0.035714
accordingly	0.000029
, sales	0.000561
150,000	0.000029
and represented	0.001445
for determining	0.007220
<s> Manual	0.001537
Harris beginning	0.111111
analytical approaches	0.500000
Kurzweil	0.000203
waves and	0.142857
as statistical	0.003484
general cursive	0.045455
-LRB- U.S.	0.005420
mapping each	0.500000
responding	0.000029
two possibilities	0.034483
second layer	0.200000
MCE	0.000029
automate about	0.333333
for singular	0.007220
-RRB- applications	0.002817
in abstractive	0.001873
Helicopters The	1.000000
evidence	0.000058
salience .	1.000000
productions .	1.000000
Accuracy for	0.142857
structure that	0.083333
words immediately	0.009174
Style Studies	1.000000
a document	0.008589
handmade	0.000029
Running	0.000029
interested	0.000029
: give	0.019608
on casual	0.004717
state-of-the-art abstractive	0.500000
evaluation step	0.037037
Airline	0.000029
or stochastic	0.004505
Schank ,	0.200000
been heard	0.014706
Although humans	0.125000
unsupervised ``	0.125000
class of	0.750000
anymore ,	1.000000
together	0.000232
<s> Applications	0.001537
by extracting	0.005714
to machine	0.003984
requires each	0.062500
worked on	0.400000
cluster of	1.000000
On what	0.166667
demonstration that	0.200000
`` Spoken	0.005291
global	0.000087
datum	0.000029
human-like	0.000029
known	0.000753
include Chinese	0.037037
graph	0.000376
this character	0.010989
rightmost	0.000058
of idioms	0.000891
wreck a	1.000000
life experience	0.250000
questions in	0.038462
, Brazil	0.000561
Encouraging results	1.000000
is limited	0.002033
orthogonal	0.000029
as opposed	0.003484
classroom lectures	1.000000
and find	0.001445
began selling	0.142857
fail during	0.333333
procedures used	0.250000
negative sentiment	0.125000
This research	0.015873
syntax are	0.090909
objective document	0.200000
revolution	0.000029
any capitalization	0.032258
solid state	1.000000
repetitive	0.000058
parser proposes	0.062500
can help	0.005525
for clarification	0.003610
Vocabulary Size	0.333333
During	0.000116
filling may	1.000000
Early work	0.500000
two -LRB-	0.034483
in their	0.007491
standard is	0.071429
while some	0.050000
appears	0.000145
change	0.000029
when we	0.057143
or weapon	0.004505
precursor	0.000029
Cynthia	0.000029
and features	0.001445
, Walter	0.000561
the English-French	0.000692
-LRB- NLG	0.008130
inference	0.000116
Aided summarization	0.333333
management applications	0.142857
-LRB- NLP	0.008130
forums -LRB-	1.000000
rarely	0.000087
language use	0.027027
included question-answering	0.125000
many higher	0.019231
Creating the	0.500000
to ask	0.001328
words were	0.018349
to proper	0.001328
syllables but	0.500000
rate the	0.090909
, US	0.001123
thus returning	0.100000
precisely an	1.000000
comes into	0.200000
specific right	0.047619
NLP tasks	0.042553
& Hollenbach	0.125000
, Malcolm	0.000561
in spirit	0.001873
of edge	0.000891
MMR	0.000029
Brill	0.000087
labeled	0.000087
MMI	0.000029
would have	0.056604
, rushing	0.000561
vary in	0.500000
meant	0.000058
dedicated	0.000087
in which	0.014981
be correct	0.004219
expanding	0.000029
the speech	0.006920
editor ,	1.000000
from 71	0.009615
accurate program	0.142857
human-made	0.000058
pre-defined	0.000058
retail sales	1.000000
, neural	0.002246
criterion	0.000058
allowable	0.000058
-LRB- or	0.027100
-LRB- speed	0.002710
-RRB- and	0.056338
designed for	0.142857
-LRB- of	0.005420
found recognition	0.071429
collection sizes	0.200000
-LRB- on	0.005420
just seen	0.111111
expensive and	0.142857
different times	0.020408
Jump to	1.000000
explicit	0.000145
Rescoring is	1.000000
geological analysis	1.000000
-RRB- that	0.005634
tagged	0.000087
indeed	0.000087
, resource	0.000561
get bunch	0.142857
tagger	0.000261
dominance of	1.000000
are robust	0.004149
Transactions	0.000058
window	0.000058
between two	0.051282
Grace	0.000029
N-best list	1.000000
writer with	1.000000
<s> Knowing	0.000769
Digest coupons	0.333333
algorithm ,	0.107143
algorithm .	0.142857
algorithm ?	0.035714
entirely	0.000058
concerned with	0.800000
and model	0.001445
reading and	0.250000
significantly	0.000029
entrants companies	1.000000
the longest	0.000692
et	0.000029
Leeuwen	0.000029
shown	0.000145
opened	0.000029
use this	0.027778
algebra	0.000058
but machines	0.014706
more strongly	0.010526
the real	0.002076
by human	0.017143
shows	0.000029
to multi-document	0.001328
U.S. Army	0.142857
Hafiz	0.000029
all such	0.023256
specific domain	0.142857
<s> Another	0.009992
<s> A	0.033820
keep track	0.333333
both affine	0.032258
into rule-based	0.012821
necessary for	0.300000
going backward	0.250000
Even	0.000029
Microphone	0.000029
with 17	0.005464
omitted	0.000029
following -LRB-	0.066667
Optophone	0.000029
require that	0.045455
speech -LRB-	0.026316
Rates	0.000029
comprises	0.000029
impossible	0.000058
size	0.000174
category that	0.500000
governmental proceedings	1.000000
be statistically	0.004219
GRACE	0.000029
are simple	0.004149
` hit	0.062500
the end	0.001384
mostly	0.000058
relative position	0.333333
One study	0.076923
subjectivity of	0.500000
Inc.	0.000058
Further restricted-domain	0.333333
is compounded	0.002033
be parsed	0.004219
it word	0.008547
the periods	0.000692
Human judgement	0.200000
generating index	0.200000
PhD	0.000029
Querying application	1.000000
Call	0.000029
, other	0.000561
evaluation Intrinsic	0.018519
software Annotate	0.037037
are BASEBALL	0.004149
often it	0.022727
successfully for	0.333333
omitted -RRB-	1.000000
have the	0.009615
objective	0.000145
best -RRB-	0.055556
clearly many	0.333333
often using	0.022727
contain words	0.083333
offered the	1.000000
appear as	0.062500
a comprehensive	0.003681
combinations of	1.000000
Markov	0.000521
notations of	0.500000
retrieval results	0.142857
fundamental errors	0.500000
elements containing	0.250000
and Arabic	0.002890
simple procedure	0.038462
methods when	0.022727
ground	0.000029
be unique	0.004219
making the	0.285714
these every	0.023810
much useful	0.045455
developed	0.000753
fusion techniques	1.000000
verbs are	0.200000
Some critics	0.047619
from some	0.009615
Language Constraints	0.083333
converts a	1.000000
rate -LRB-	0.090909
shapes of	0.666667
, stemming	0.000561
been hand-annotated	0.029412
<s> Automatic	0.005380
Another area	0.076923
techniques ,	0.086957
techniques .	0.043478
for heavily	0.003610
can represent	0.011050
The 26	0.005208
concern	0.000029
parsing and	0.035714
realizations as	1.000000
'' in	0.037634
be viewed	0.016878
'' it	0.005376
Weizenbaum sidestepped	0.333333
'' is	0.048387
uses the	0.071429
vertices be	0.111111
applications including	0.040000
was dramatically	0.012987
`` Who	0.010582
are four	0.004149
because there	0.066667
`` Why	0.015873
article	0.000840
what linguistic	0.031250
and attempt	0.001445
Santoni	0.000029
is edited	0.002033
rejecting those	0.333333
voicemail	0.000029
be difficult	0.004219
it should	0.008547
pre-existing corpus	0.500000
comes	0.000145
in conjunction	0.003745
<s> Rescoring	0.000769
an eyes-busy	0.007576
increase recognition	0.250000
non-whitespace character	1.000000
, symbols	0.000561
assumed that	1.000000
Known	0.000029
use multiple	0.013889
center ,	1.000000
accuracy may	0.032258
the management	0.000692
recogniton vary	0.500000
is especially	0.004065
input sales	0.024390
CWA -RRB-	1.000000
stems	0.000058
an arbitrarily	0.007576
both speech	0.032258
The NIST	0.005208
what sense	0.031250
developing	0.000116
suitable translation	0.250000
been more	0.029412
both individual	0.032258
or emotion	0.004505
flood-control pumps	1.000000
1954 involved	0.333333
organization documents	0.200000
emphasize different	1.000000
all perform	0.023256
simply do	0.083333
<s> Conferences	0.000769
answers are	0.083333
media	0.000174
easily portable	0.222222
: ``	0.019608
document	0.001042
looks natural	0.250000
grown .	1.000000
answering -LRB-	0.083333
their spoken	0.029412
quality standards	0.100000
is one	0.012195
text corresponds	0.006289
pre-marked .	1.000000
archiving and	1.000000
, cultural	0.000561
was hand-written	0.012987
Virtually any	1.000000
software has	0.037037
the contents	0.000692
character alone	0.045455
is recognizing	0.002033
environment .	0.333333
count for	0.200000
environment ,	0.166667
software had	0.037037
simplified the	0.500000
others seem	0.083333
speed	0.000203
Multilingual -LRB-	1.000000
syntactic analysis	0.153846
desktop	0.000029
, i.e.	0.003930
momentum	0.000029
real	0.000261
read	0.000203
usefully	0.000029
be thought	0.004219
wide variance	0.250000
which makes	0.021739
, Jef	0.000561
centrality ''	0.500000
-LRB- predict	0.002710
Before	0.000058
to save	0.001328
monetary value	1.000000
MT has	0.200000
can assign	0.005525
are usually	0.012448
recorded	0.000058
mixture of	1.000000
a variety	0.008589
reduced set	0.250000
Interface	0.000029
toy project	0.500000
Marilyn	0.000029
Morpholympics	0.000029
a positive	0.001227
full comprehension	0.200000
embedded lists	0.250000
information into	0.043478
`` bag	0.005291
often difficult	0.022727
Orientation --	1.000000
ontology	0.000058
central	0.000087
Solutions	0.000029
internalize	0.000029
normally requires	0.500000
to rate	0.002656
might use	0.076923
in helicopters	0.003745
and news	0.001445
even though	0.074074
contain subjective	0.083333
, on	0.003930
prepare	0.000029
, of	0.002246
1997 ,	0.500000
greater risk	0.333333
relaxed parser	1.000000
is similar	0.004065
each feature\/aspect	0.022222
surprisingly ,	0.333333
either explicit	0.100000
programer 's	1.000000
fairly often	0.250000
run an	0.200000
trying	0.000145
least to	0.200000
waves .	0.142857
of knowledge	0.001783
Veterans Administration	1.000000
very broad	0.048780
be more	0.021097
to incorporate	0.001328
tables to	0.333333
vocabulary ,	0.125000
describe	0.000174
moved	0.000029
sales	0.000087
for simple	0.003610
moves	0.000029
or ICR	0.004505
new insights	0.041667
and use	0.004335
modeling are	0.142857
Research Projects	0.125000
or ''	0.004505
the human-readable	0.000692
the article	0.000692
<s> Programming	0.001537
processed Airline	0.166667
parameters ,	0.250000
for more	0.007220
by ears	0.005714
the United	0.004844
coverage	0.000087
to OCR	0.001328
answering methods	0.083333
first-order logic	1.000000
-RRB- the	0.002817
This sequence	0.015873
and sources	0.001445
of top-down	0.001783
red .	1.000000
information usually	0.021739
capitalization can	0.333333
act theory	0.250000
limited number	0.200000
existing hand-written	0.200000
sequence alignment	0.125000
being processed	0.055556
splitting	0.000058
much better	0.045455
Sentence boundary	0.200000
Francis ,	1.000000
product became	0.142857
higher order	0.142857
<s> Chinese	0.000769
speech is	0.006579
referring	0.000058
and HLT	0.001445
involve working	0.166667
generally achieved	0.090909
tagger is	0.111111
more reliable	0.031579
involve grammar	0.166667
market their	0.333333
up In	0.045455
2,026,329	0.000029
job ;	0.500000
away -LRB-	0.500000
30 years	0.666667
job ,	0.500000
verb	0.000376
Another approach	0.153846
the wife	0.000692
financial benefits	0.250000
sentence breaking	0.020833
choices that	0.200000
usually thought	0.031250
unit vertices	0.333333
a classification	0.001227
also the	0.028986
but IR	0.014706
into linguistically	0.012821
each phoneme	0.022222
many advantages	0.019231
This corpus	0.031746
be sequences	0.004219
make up	0.100000
but IE	0.014706
canonical	0.000029
Latin	0.000116
, USMC	0.000561
HLDA	0.000029
-RRB- can	0.008451
source language	0.125000
less than	0.250000
the F35	0.000692
, relationship	0.000561
rudimentary	0.000058
answers	0.000347
Schiffrin ,	1.000000
a cosine	0.001227
actual measurement	0.200000
and ushered	0.001445
Hafiz ,	1.000000
the nouns	0.000692
columns and	1.000000
naturalness .	1.000000
used through	0.008850
new text	0.083333
, Santoni	0.000561
But unfortunately	0.166667
This allows	0.031746
chunks	0.000029
names .	0.285714
names ,	0.285714
checked after	0.500000
the voice	0.000692
is why	0.002033
easy-to-use	0.000029
Network classifies	1.000000
Creating	0.000058
a well-defined	0.001227
hours of	0.500000
algorithm to	0.071429
of nodes	0.003565
-LRB- Kittredge	0.002710
by inputting	0.005714
document 7110.65	0.027778
they can	0.150000
one another	0.015385
occurs in	1.000000
commonly defined	0.125000
nine	0.000029
dynamic study	0.200000
spontaneous	0.000087
to conduct	0.001328
greatly on	0.142857
lacks	0.000029
1957 and	1.000000
linguistic informational	0.062500
explained by	1.000000
belong to	1.000000
or program	0.004505
formal or	0.111111
were identified	0.024390
rather can	0.062500
the dynamics	0.000692
inter-word spaces	1.000000
important words	0.062500
robustness against	0.500000
in-depth analysis	0.333333
keyboard and	0.333333
Deep	0.000029
be retrained	0.004219
contains embedded	0.100000
be required	0.004219
final language	0.111111
web ,	0.125000
believed that	1.000000
People with	1.000000
by increasing	0.005714
using conventional	0.016949
similarity scores	0.100000
subsequent concepts	0.500000
by Jurafsky	0.005714
developed in	0.230769
left-most	0.000058
role in	0.250000
from text	0.019231
Glass-box	0.000029
food	0.000029
Ratliff originally	1.000000
results in	0.047619
that connects	0.003546
Semantic	0.000087
fully	0.000174
Beatrice Santorini	1.000000
overfitting the	0.500000
Slembrouck	0.000029
<s> Natural	0.005380
segmentation approaches	0.030303
referred	0.000232
language during	0.006757
pauses between	0.500000
great success	0.333333
to parsers	0.001328
written languages	0.192308
software to	0.074074
local document	0.333333
video captioning	0.200000
Rescoring	0.000029
to database	0.001328
system typically	0.010753
as pseudo-pilot	0.003484
since	0.000290
grammatical analysis	0.090909
reranking in	1.000000
efforts based	0.142857
Computed every	1.000000
resolve ambiguities	0.500000
file to	1.000000
Ingria R.	1.000000
assertion ,	1.000000
and usefulness	0.001445
Many documents	0.083333
input-stream	0.000029
binary judgement	0.250000
LexisNexis	0.000029
base	0.000116
from randomly	0.009615
put	0.000116
, Stef	0.000561
with two	0.010929
Answering QA	1.000000
developing new	0.250000
schemata	0.000029
and substitution	0.001445
characteristics .	0.500000
be representative	0.004219
probability	0.000203
encoding	0.000029
resulting graph	0.250000
frame ;	0.500000
for continuous	0.003610
Corpus developed	0.062500
collection of	0.400000
Schober ,	1.000000
together with	0.125000
CANDIDE	0.000029
shifted	0.000029
storm	0.000029
recursively	0.000058
would generate	0.018868
interactive program	0.250000
hidden Markov	0.875000
one reference	0.015385
be approximated	0.004219
; in	0.021277
specific letter	0.047619
can condense	0.005525
still not	0.066667
A second	0.020000
Once performed	0.400000
CSIS -RRB-	0.500000
deciding	0.000174
ROUGE-1	0.000145
issues were	0.200000
and analytical	0.001445
substantial	0.000145
<s> Inclusive	0.000769
vulnerable	0.000029
<s> Current	0.002306
sentences flow	0.013158
Big wave	1.000000
evaluation with	0.018519
Some writing	0.047619
, rejecting	0.000561
<s> Human	0.002306
will indicate	0.028571
and confusability	0.001445
unigram ,	0.600000
put the	0.250000
towards	0.000029
text -RRB-	0.006289
closed-captioning of	1.000000
strength of	0.600000
task-effectiveness	0.000058
The	0.005559
understand why	0.142857
NLP algorithms	0.042553
audio	0.000058
. ''	0.437500
VTLN -RRB-	1.000000
Sager at	0.500000
ratings on	0.111111
Such strategy	0.125000
early 1990s	0.100000
blend	0.000087
, producing	0.000561
OCR accuracy	0.020408
of pilot	0.000891
ROUGE-1 -LRB-	0.200000
completion	0.000029
necessary therefore	0.100000
Mention	0.000029
context-free grammar	0.454545
its speakers	0.028571
industry .	0.333333
just validated	0.111111
` kit	0.125000
trees	0.000174
famous	0.000087
ambiguity in	0.125000
during	0.000290
cases make	0.055556
translate between	0.166667
, Edward	0.000561
coherent summary	0.200000
with one	0.005464
which sounds	0.007246
<s> Methods	0.002306
Therefore ,	1.000000
tagging systems	0.040000
Romanseval	0.000029
scanning	0.000058
in advanced	0.001873
by using	0.017143
1 -RRB-	0.250000
its utility	0.028571
, computer	0.001123
Xerox eventually	0.500000
assistants	0.000029
Fighter	0.000029
notoriously	0.000029
Segmentation	0.000029
are measured	0.004149
approximation thereof	0.166667
paradigm calls	0.333333
genre	0.000058
automatically created	0.047619
Hard	0.000058
still somewhat	0.066667
One way	0.076923
time in	0.030303
is best	0.002033
as 10	0.003484
many types	0.019231
dynamic character	0.200000
- EVALITA	0.062500
behavior of	0.500000
news domain	0.230769
US baseball	0.142857
products in	0.250000
<s> Morphological	0.000769
ontologies '	0.166667
involves deciding	0.100000
Efficient algorithms	1.000000
ontologies .	0.500000
translations using	0.500000
Most	0.000058
maintenance	0.000029
the objectives	0.000692
, real	0.000561
+ Mobile	0.166667
partly	0.000029
word ``	0.016667
probabilities .	0.181818
probabilities ,	0.090909
the reCAPTCHA	0.000692
If probabilities	0.100000
, therefore	0.001684
our knowledge	0.200000
`` recommendation	0.010582
the single	0.000692
Since 2000	0.200000
these algorithms	0.023810
Issues	0.000058
van Dijk	0.500000
seems to	1.000000
Furthermore	0.000174
‚Üí dogs	0.333333
evaluation metrics	0.018519
assume there	0.500000
provided significant	0.200000
anymore	0.000029
belong	0.000029
by giving	0.005714
the conceptual	0.000692
become more	0.250000
for them	0.007220
used	0.003271
HMT	0.000029
uses	0.000405
user	0.000405
Word-sense	0.000029
underlies	0.000029
power increased	0.250000
Giro	0.000029
distances	0.000058
linguistics -RRB-	0.100000
top level	0.200000
PhD thesis	1.000000
than precision	0.022222
exhibited good	1.000000
important .	0.062500
extract the	0.250000
or its	0.004505
transformation	0.000029
use by	0.027778
...	0.000058
interlingua .	1.000000
evaluate	0.000116
finding	0.000145
parsers for	0.153846
interference between	1.000000
automatically answer	0.047619
overriding	0.000029
with applications	0.005464
Computing	0.000058
signal	0.000174
-RRB- coefficients	0.002817
Learning	0.000029
past thirty	0.333333
AI-complete	0.000087
January ,	0.250000
the grammar-based	0.000692
enumerate every	1.000000
creation	0.000058
, Michel	0.001123
trends	0.000029
centers of	1.000000
the Austrian	0.000692
over vertices	0.083333
run	0.000145
models Main	0.038462
processing	0.001563
instead of	0.571429
deciding where	0.166667
Australia	0.000029
Human sentences	0.200000
book does	0.125000
Computer Speech	0.333333
notations ,	0.500000
and include	0.002890
Search collections	0.500000
71	0.000029
while capturing	0.050000
Their	0.000058
maximum likelihood	0.333333
draft document	0.500000
area include	0.090909
potential redundancy	0.142857
lend well	1.000000
lexical and	0.153846
heritage	0.000029
researchers to	0.100000
finalized .	1.000000
tag of	0.062500
himself	0.000058
`` look	0.005291
and LILOG	0.001445
, matching	0.000561
multi-document	0.000116
minute ,	1.000000
Grammatical	0.000029
Attribute	0.000029
Rajman	0.000029
with human	0.010929
it even	0.008547
identification of	0.400000
several ways	0.045455
to fulfill	0.002656
and LUNAR	0.001445
have included	0.009615
multilingual questions	0.333333
Northern Isles	0.666667
that area	0.003546
a translator	0.003681
Neural	0.000116
Speaking	0.000029
vector machines	0.333333
-LRB- based	0.005420
path sentences	0.500000
Federation of	1.000000
allowing for	0.333333
in virtually	0.001873
incremental improvements	1.000000
of human	0.004456
using digital	0.016949
reliance on	1.000000
analyser to	1.000000
early successes	0.100000
and control	0.004335
English alphabet	0.054054
that preclude	0.003546
discourse are	0.027778
rules :	0.046512
applications include	0.080000
required	0.000203
that domain	0.003546
depth	0.000087
decomposing it	1.000000
or length	0.004505
semiotic event	1.000000
rules .	0.139535
rules ,	0.116279
can translate	0.005525
says phrases	1.000000
shorter and	0.500000
, verbs	0.001123
France has	0.250000
entirety ,	1.000000
reasons that	0.500000
program ,	0.045455
program .	0.136364
originally developed	0.500000
say that	0.142857
In terms	0.009524
Technologies that	1.000000
into account	0.038462
management environments	0.142857
fueled interest	1.000000
document formats	0.027778
produce useful	0.045455
see List	0.050000
program a	0.090909
tonal	0.000029
generating examples	0.200000
extrinsic performance	0.166667
becomes .	0.250000
'' standards	0.005376
translation Automotive	0.013514
with maximal	0.005464
should not	0.052632
program to	0.090909
1974 Ray	1.000000
n-gram ROUGE	0.500000
always a	0.333333
experiment	0.000145
setting radio	0.200000
;	0.001361
example -LRB-	0.012346
this makes	0.010989
focuses	0.000058
spoken text	0.071429
recognition efforts	0.008264
which do	0.007246
Greek	0.000087
focused	0.000318
Cynthia Hardy	1.000000
especially those	0.200000
always ,	0.333333
is also	0.020325
products	0.000116
' properties	0.052632
English ,	0.162162
summarization :	0.020000
of keyphrases	0.002674
SIGGEN	0.000029
and human	0.001445
general term	0.045455
a trivial	0.001227
summarization .	0.120000
anomalies	0.000029
<s> metrics	0.000769
manipulate	0.000087
social media	0.285714
its performance	0.028571
being based	0.055556
context-free	0.000318
, NNS	0.000561
entertaining last	0.500000
domotic appliance	1.000000
Sentences ;	1.000000
optimizing	0.000029
<s> Based	0.000769
a count	0.001227
and regions	0.001445
benchmark	0.000029
printing ,	1.000000
The Brown	0.015625
polarity ''	0.250000
target value	0.090909
and volume	0.001445
implemented on	0.200000
other medium	0.014286
<s> Comparing	0.000769
ISO\/TC37\/SC4	0.000029
Evaluation An	0.111111
providers	0.000029
This model	0.031746
would allow	0.018868
When the	0.142857
short ,	0.125000
Accuracy is	0.142857
poetry	0.000029
located	0.000029
<s> Like	0.000769
clusters .	1.000000
not all	0.017857
Document Understanding	0.250000
likely be	0.062500
whether documents	0.076923
vary from	0.166667
difficult for	0.035714
summarization involves	0.020000
spelling	0.000029
are implemented	0.004149
numerous approaches	1.000000
Corpus ,	0.062500
Corpus .	0.062500
a short	0.006135
given -LRB-	0.041667
Smith	0.000029
sub-problems ,	1.000000
sorting center	1.000000
interface Home	0.250000
done in	0.454545
tag to	0.062500
both of	0.064516
automatic methodology	0.043478
that looks	0.003546
of marking	0.000891
to overcome	0.001328
succession of	1.000000
been using	0.029412
printed text	0.250000
speech Adverse	0.006579
or might	0.004505
reliable results	0.500000
removes the	1.000000
chunk	0.000203
connects to	1.000000
values for	0.125000
recording conditions	1.000000
Why do	0.142857
problem from	0.022727
the breadth	0.000692
We also	0.142857
what information	0.031250
to overfitting	0.001328
, Speereo	0.000561
Beginning	0.000058
assumptions about	0.200000
handles both	1.000000
the reference	0.000692
diagonal	0.000029
containing words	0.125000
keep	0.000087
of real-world	0.000891
a computer	0.018405
likely not	0.062500
Lamb	0.000029
<s> Issues	0.001537
at .	0.014706
probability of	0.142857
Callaghan which	1.000000
MUC	0.000029
of conversations	0.000891
ASR	0.000174
smaller .	0.142857
high ranks	0.055556
Automated	0.000058
saying .	1.000000
warping is	0.500000
data will	0.012987
at a	0.058824
DUC	0.000029
contain names	0.083333
funding has	0.125000
R	0.000029
suitability	0.000058
of standard	0.000891
achieves	0.000058
In short	0.009524
address field	0.250000
distinguishes	0.000058
movies ,	1.000000
particular types	0.076923
common components	0.040000
providing	0.000058
distinguished	0.000029
Information	0.000145
of assertions	0.000891
closely approximates	0.200000
constrained	0.000029
that investigates	0.003546
newswire reports	1.000000
segmentation problems	0.060606
Generally ,	0.600000
in overall	0.001873
Giv√≥n ,	1.000000
instance	0.000405
generated .	0.200000
it becomes	0.034188
although these	0.166667
the front	0.002076
going thus	0.250000
1975 -RRB-	1.000000
is Reiter	0.002033
CLAWS ,	0.500000
on whether	0.004717
those influenced	0.045455
a logical	0.001227
effect of	0.500000
major constituents	0.083333
proceedings	0.000029
sample of	0.333333
a Cognitive	0.001227
mostly as	0.500000
pioneered this	0.333333
highest probability	0.333333
choose from	0.500000
material may	0.500000
commands are	0.200000
such systems	0.008130
a technique	0.001227
dynamics of	0.500000
be around	0.004219
supervised classification	0.125000
attained	0.000029
differently on	1.000000
can improve	0.005525
Robert de	0.250000
automates the	1.000000
to publish	0.001328
evident	0.000058
on complex	0.004717
input and\/or	0.024390
the input	0.005536
she	0.000029
to narrative	0.001328
of repeated	0.000891
by statistics	0.005714
d'Albe developed	1.000000
and unexpected	0.001445
of public	0.000891
DTW -RRB-	0.333333
usefulness	0.000029
looking waves	0.200000
its use	0.028571
, incomplete	0.000561
and cross-lingual	0.001445
James Deese	0.250000
the concepts	0.000692
time-consuming .	0.333333
written	0.000753
correctly	0.000029
ISRI -RRB-	1.000000
particular part	0.076923
, LinguaSys	0.000561
describing language	0.250000
Recall	0.000087
an upper-case	0.007576
OCR technology	0.183673
computational concerns	0.100000
\* ,	0.500000
much like	0.045455
be useful	0.012658
`` The	0.015873
Realisation	0.000029
forecast -LRB-	1.000000
be computed	0.004219
scanner that	0.333333
impersonate a	1.000000
when integrated	0.028571
addition	0.000174
an experiment	0.007576
going to	0.250000
scores significantly	0.200000
synthesizer .	1.000000
: Speech	0.009804
do research	0.038462
the 2006	0.000692
large variety	0.043478
two benefits	0.034483
speech single	0.006579
Dragon	0.000058
1970s and	0.666667
Subsequently	0.000029
in another	0.007491
, maybe	0.000561
documents obtained	0.026316
pass .	1.000000
contexts	0.000203
Corpus -LRB-	0.062500
in predicate	0.001873
first-cut can	1.000000
real-valued weights	0.666667
CCD flatbed	1.000000
words surrounding	0.009174
unfamiliar input	1.000000
statistical analysis	0.030303
, rapidly	0.000561
own sentence	0.166667
reader designed	0.200000
are reported	0.004149
given formal	0.041667
excess of	1.000000
whereas when	0.333333
approaches can	0.035714
or Arabic	0.004505
significant effort	0.111111
the quantitative	0.000692
`` He	0.005291
underlying knowledge	0.333333
-RRB- may	0.002817
Emergent	0.000029
`` diverse	0.005291
categories and	0.222222
module that	0.333333
Communications -LRB-	1.000000
accurate	0.000203
number should	0.023256
of 500,000	0.000891
search engines	0.181818
documents onto	0.026316
topics and	0.142857
segmentation Sentence	0.030303
independence Isolated	1.000000
how they	0.103448
ushered	0.000029
kick	0.000029
as weapon	0.003484
news-gathering	0.000029
solved problem	0.400000
of texts	0.001783
accuracy using	0.032258
National Federation	0.333333
full-text search	1.000000
sizes	0.000087
still largely	0.066667
a human	0.013497
controllers	0.000087
answers might	0.083333
the high	0.001384
TextRank and	0.142857
would be	0.169811
article by	0.034483
what Biden	0.031250
-LRB- ParaEval	0.002710
health and	1.000000
non-Western scripts	1.000000
be used	0.080169
nodes represents	0.142857
language representation	0.006757
to different	0.001328
-LRB- POS	0.005420
Character Recognition	1.000000
the diagramming	0.001384
associated score	0.250000
both learn	0.032258
CyberEmotions project	1.000000
updated textbook	1.000000
expansion	0.000087
digitized ,	1.000000
deterministic rule	0.250000
metrics are	0.111111
Ensemble methods	1.000000
recognized	0.000174
be modified	0.004219
Its main	0.500000
EVALITA campaign	0.500000
recognizes	0.000087
-RRB- Critical	0.002817
successfully in	0.333333
Graph	0.000029
, pronoun	0.000561
, people	0.000561
of objects	0.000891
intelligence systems	0.125000
Lawrence	0.000029
speakers to	0.250000
fast-evolving	0.000029
merging the	0.500000
there may	0.025000
Hence the	0.500000
artificial intelligence	0.636364
poetry passages	1.000000
will usually	0.028571
the company	0.000692
choices -LRB-	0.200000
run the	0.400000
he	0.000203
- processing	0.062500
Sentence	0.000145
in any	0.001873
limit	0.000116
`` sounds	0.005291
by numbers	0.005714
speech recognition-related	0.006579
operate on	1.000000
attitude may	0.500000
typewritten text	0.200000
on broad	0.004717
then given	0.028571
A Universal	0.020000
-LRB- http:\/\/haydn.isi.edu\/ROUGE\/	0.002710
worse	0.000029
no incorrect	0.076923
The accuracy	0.010417
would also	0.018868
, Shipibo	0.000561
complete sentences	1.000000
Smartphones .	1.000000
useful work	0.071429
Perhaps the	1.000000
discussed below	0.428571
blogs	0.000058
work ,	0.125000
work .	0.083333
PageRank ,	0.166667
PageRank .	0.166667
above -RRB-	0.076923
covariance Gaussians	0.500000
choices What	0.400000
that approximate	0.003546
dynamic	0.000145
headed by	1.000000
tasks -LRB-	0.031250
varies greatly	1.000000
assign labels	0.200000
possible without	0.041667
about following	0.025000
Adam Jaworski	1.000000
stochastic taggers	0.125000
on smaller	0.004717
those languages	0.090909
affect	0.000087
grammar formalisms	0.027027
and discontinuous	0.001445
certain e-communities	0.142857
companies	0.000058
solution	0.000029
vector	0.000087
Keyphrases	0.000029
among humans	0.125000
one typically	0.015385
recognition we	0.008264
in Germany	0.003745
question processing	0.071429
text about	0.012579
categories ;	0.111111
, Roger	0.000561
categories ,	0.111111
new	0.000695
times a	0.200000
best single	0.055556
Booth	0.000029
a certain	0.001227
in many	0.014981
never	0.000145
to upload	0.001328
different languages	0.020408
interpret	0.000029
fighter applications	0.166667
times ,	0.200000
more interest	0.010526
the 100	0.000692
Business-card OCR	1.000000
these natural	0.023810
shortened	0.000029
professionals .	1.000000
than polarity	0.022222
many speech	0.019231
Italy	0.000058
counts	0.000029
languages like	0.020000
lightweight ontologies	1.000000
text from	0.012579
recommend	0.000058
type	0.000405
tell	0.000087
consecutive words	0.500000
research also	0.023810
and interaction	0.001445
pre-processing	0.000029
sentences -LRB-	0.026316
and broadband	0.001445
impact of	0.500000
impact on	0.500000
Annotate	0.000029
An example	0.187500
performance continued	0.055556
possibly linked	0.500000
decision-support	0.000029
or -LRB-	0.004505
answer corpus	0.033333
often work	0.022727
<s> Deep	0.000769
comparing its	0.500000
separated by	0.666667
term applies	0.111111
large percentage	0.043478
those pauses	0.045455
created ,	0.285714
does the	0.100000
created .	0.142857
led to	0.666667
individual cursive	0.083333
it conducted	0.008547
are averaged	0.004149
provide manually	0.166667
elaboration ,	1.000000
feature\/aspect is	1.000000
information -LRB-	0.021739
used when	0.017699
needs of	0.100000
Besides the	1.000000
approaches have	0.071429
with matching	0.005464
regions .	0.500000
internalize the	1.000000
cosine similarity	0.333333
DTW has	0.333333
non -	1.000000
spectral-domain of	1.000000
courses of	1.000000
keyboard	0.000087
given CFG	0.041667
that it	0.010638
vertices are	0.111111
turn also	0.166667
not .	0.017857
Query expansion	1.000000
earliest-used	0.000058
grammar '	0.027027
-LRB- natural	0.002710
company to	0.333333
to do	0.003984
Alternatively	0.000058
the phenomenon	0.001384
and answer	0.001445
setting steer-point	0.200000
rhetoric	0.000029
on part-of-speech	0.004717
subtasks .	0.500000
The examples	0.005208
which its	0.007246
Michigan ,	1.000000
not a	0.008929
sophisticated methods	0.142857
2009 -LRB-	0.333333
major OCR	0.166667
parties du	1.000000
at its	0.014706
and you	0.004335
= singular	0.111111
`` correct	0.005291
occur ,	0.200000
and experience	0.001445
most likely	0.051724
a sub-field	0.001227
semantic theory	0.095238
Goodwin	0.000029
, recommendations	0.000561
research necessary	0.023810
very complex	0.024390
Determine the	1.000000
HMM	0.000087
language question-answering	0.006757
linguistics and	0.050000
-LRB-	0.010683
that in	0.007092
also obtained	0.014493
judges ,	0.500000
found most	0.071429
from one	0.028846
can produce	0.005525
slowly but	0.500000
holes ''	1.000000
and Italian	0.001445
simply focused	0.083333
analyzed ,	0.200000
WebOCR	0.000116
Discontinuous	0.000029
messages	0.000058
conditions Environmental	0.200000
teach that	1.000000
loud	0.000029
of stock	0.000891
then appear	0.028571
systems sold	0.008929
set on	0.025641
environment as	0.166667
set of	0.717949
of simple	0.001783
features would	0.038462
for results	0.003610
as subject	0.003484
progressed over	1.000000
, human	0.003369
Corps of	1.000000
, speech	0.004492
the tag	0.001384
still be	0.066667
tokens	0.000203
restricted-domain	0.000029
the left	0.001384
keyword	0.000029
instructed to	1.000000
matter	0.000087
descriptions ;	1.000000
<s> Subsequently	0.000769
aural	0.000029
<s> Prior	0.000769
a dictionary	0.003681
Clancy 's	1.000000
in essentially	0.001873
it vibrates	0.008547
identified .	0.200000
algorithm essentially	0.035714
Summarization	0.000116
predict keyphrases	0.166667
methods presented	0.022727
<s> There	0.006918
on computational	0.004717
-LRB- which	0.008130
two include	0.034483
technology This	0.045455
communication -LRB-	0.400000
increasingly difficult	0.333333
be given	0.004219
, developed	0.000561
process to	0.111111
mining ,	0.200000
mining .	0.200000
Why did	0.142857
medical	0.000174
development of	0.583333
hurricane season	1.000000
Two of	0.285714
only as	0.026316
car or	1.000000
only at	0.026316
multilingual textual	0.333333
decoding	0.000029
SPOTLIGHT	0.000029
judges	0.000058
no evident	0.076923
TextRank ,	0.142857
TextRank .	0.071429
the ranking	0.001384
integrate	0.000029
on Speech	0.004717
expertise ,	1.000000
standard techniques	0.071429
stop	0.000058
guesses '	1.000000
Organization	0.000029
Johnstone	0.000029
, simple	0.001123
n't vice	0.250000
fields	0.000174
a Fourier	0.001227
cover .	1.000000
linguist	0.000058
rhetoric ,	1.000000
simple domains	0.038462
reference	0.000232
being considered	0.111111
, opening	0.000561
It proved	0.026316
Basically ,	1.000000
Environment Canada	1.000000
very specific	0.024390
10,000 to	1.000000
Eurofighter	0.000029
Lifeline as	1.000000
a given	0.014724
tied to	1.000000
mouse driven	1.000000
AVRADA -RRB-	0.500000
modeling	0.000203
placement of	1.000000
software ,	0.037037
, yielding	0.000561
of original	0.000891
edition published	1.000000
culture of	1.000000
distinction	0.000145
they relate	0.025000
The SATZ	0.005208
are spoken	0.004149
; e.g.	0.042553
, mathematical	0.000561
reports into	0.400000
as discussed	0.003484
top of	0.200000
<s> Advanced	0.002306
1960s .	0.333333
both algorithms	0.032258
final keyphrase	0.111111
a speaker	0.002454
as just	0.003484
Translator -RRB-	1.000000
Ontology	0.000029
formalized	0.000029
Units -LRB-	1.000000
quantities	0.000087
night .	1.000000
news ,	0.076923
based speech	0.018519
exception	0.000029
example above	0.012346
-LRB- EMR	0.002710
other in	0.014286
beings ,	1.000000
near	0.000029
neat	0.000029
many authors	0.019231
large number	0.086957
entropy-based	0.000029
AVRADA	0.000058
is	0.014244
it	0.003387
scans paper	1.000000
in	0.015460
if	0.000811
Woods introduced	1.000000
summary -RRB-	0.023810
many chatterbots	0.019231
linguistic resources	0.062500
an AI-complete	0.007576
relationships of	0.166667
is definite	0.002033
recognizing named	0.200000
cognitive operation	0.500000
be broken	0.004219
entities employed	0.142857
data category	0.012987
of sentence	0.000891
R. Howarth	0.166667
, list	0.000561
of anomalies	0.000891
QA Questions	0.047619
De	0.000029
mail since	0.500000
Orleans	0.000058
treat words	0.500000
that contains	0.010638
identify	0.000347
facts	0.000029
realm of	1.000000
on ;	0.004717
templates may	1.000000
on .	0.018868
A comprehensive	0.020000
Dec. 2011	1.000000
track of	1.000000
Grishman	0.000029
Current state	0.200000
In such	0.009524
ATNs used	0.333333
Applications The	0.500000
contain densely	0.083333
directed .	1.000000
, handling	0.001123
evaluation in	0.055556
input into	0.024390
Server OCR	1.000000
each example	0.044444
is true	0.002033
Jef	0.000029
most importantly	0.017241
or deferred	0.004505
recognition :	0.016529
on a	0.108491
transition network	1.000000
power The	0.250000
include overt	0.037037
schematic organization	1.000000
Problem Solving	1.000000
their part	0.029412
, etc.	0.011230
telephone .	0.500000
English are	0.027027
grammar of	0.054054
10 .	0.125000
in-depth knowledge	0.666667
10 %	0.250000
political discourse	0.333333
judgement often	0.333333
systems dynamically	0.008929
text generation	0.006289
keyphrases to	0.028571
multitude of	1.000000
psychotherapy .	1.000000
was CANDIDE	0.012987
is crucial	0.002033
Dynamic Programming	0.200000
taggers can	0.142857
recognition ,	0.115702
would produce	0.037736
parsing written	0.035714
parses the	0.500000
that causes	0.003546
: fact	0.009804
about it	0.025000
were ``	0.024390
<s> n	0.000769
be measured	0.004219
to more	0.002656
Critical	0.000058
continued to	0.333333
contrast ,	0.625000
rule-based machine-translation	0.142857
<s> N	0.000769
cartoon animation	1.000000
what extent	0.031250
such large	0.008130
Aided Human	0.333333
form	0.000579
<s> ,	0.000769
entry .	0.250000
a whole	0.002454
concepts are	0.400000
interlingual machine	0.750000
Screenshot OCR	1.000000
system to	0.053763
the Gene	0.000692
language using	0.006757
tests ,	0.250000
tests .	0.250000
lattice -RRB-	1.000000
-RRB- dogs	0.002817
<s> Maximum	0.001537
what you	0.031250
1970 -LRB-	0.333333
based therapy	0.018519
Pallet D.S.	0.500000
Anthology	0.000029
Lifeline	0.000029
1950s ,	0.500000
critical tasks	0.250000
the idea	0.001384
require in	0.045455
text image	0.006289
correct -RRB-	0.066667
one feasibility	0.015385
accuracy .	0.225806
of TF-IDF	0.000891
digital	0.000203
of text	0.021390
of hand-printed	0.001783
Haton	0.000029
, needed	0.000561
-- the	0.120000
approximates the	0.500000
felt	0.000029
on contrastive	0.004717
this meaning	0.010989
Guidelines for	0.500000
billion	0.000029
G	0.000029
assume	0.000058
frequency with	0.500000
vocabulary .	0.250000
<s> Significant	0.000769
receivers .	1.000000
correlation is	0.500000
a societal	0.001227
skip	0.000029
morphology	0.000203
typically finds	0.055556
Center ,	1.000000
condensation operations	1.000000
the U.S.	0.002768
10 digits	0.125000
answered	0.000145
EAGLi for	1.000000
marks	0.000116
phonemes	0.000174
only because	0.026316
string	0.000116
time-scales -LRB-	1.000000
written English	0.038462
because two	0.033333
sets from	0.090909
, these	0.001123
sentences presented	0.013158
Where	0.000029
extractive keyphrase	0.142857
of distinct	0.000891
the desired	0.002768
<s> Recent	0.002306
accidentally	0.000029
Harris had	0.111111
sets to	0.090909
J. ,	0.666667
looks for	0.250000
word context	0.016667
involves doing	0.100000
new part	0.041667
broadband technologies	1.000000
Romance	0.000029
by parser	0.005714
and generating	0.001445
human -RRB-	0.043478
general purpose	0.090909
untagged corpus	1.000000
better decisions	0.111111
Substantial	0.000058
industry ,	0.333333
template	0.000116
learning from	0.046512
speed .	0.428571
scanned page	0.333333
speed ,	0.285714
-LRB- IE	0.005420
are likely	0.016598
automatic procedures	0.043478
matter how	0.333333
the Parseval\/GEIG	0.000692
Makoto	0.000029
of TextRank	0.000891
summaries or	0.023256
summaries of	0.093023
across a	0.200000
which soon	0.007246
the mid-1960s	0.000692
encode	0.000029
of 1956	0.000891
Processes	0.000029
Constraint	0.000029
the segmentation	0.000692
to summarise	0.003984
or names	0.004505
step neural	0.066667
think that	0.333333
then noun	0.028571
effort	0.000116
cepstral	0.000058
capturing	0.000029
using punctuation	0.016949
often disagree	0.022727
arithmetic expression	1.000000
growing	0.000116
of semantics	0.000891
in driving	0.001873
Evaluation As	0.111111
information request	0.021739
A. Woods	0.200000
result will	0.090909
breaking	0.000058
normalize	0.000029
`` Sentiment	0.005291
a display	0.001227
Intrinsic evaluations	0.333333
<s> Although	0.005380
more easily	0.010526
Verschueren	0.000029
generation :	0.222222
applications seek	0.040000
Junqua and	1.000000
generation .	0.222222
generation ,	0.111111
designed	0.000203
`` Meaningful	0.005291
grow	0.000029
's software	0.019608
text are	0.006289
maybe	0.000029
fluent	0.000029
and linguistic	0.001445
because it	0.100000
are particularly	0.004149
understanding evaluation	0.030303
pointed	0.000029
entity	0.000145
stability	0.000029
Relevance	0.000029
heavy-noise	0.000029
resolution is	0.250000
Newton pioneered	1.000000
semantic ;	0.047619
and social	0.004335
reviews respectively	0.166667
like HTML	0.035714
Methods	0.000116
to integrate	0.001328
cognition	0.000029
sentences so	0.013158
-LRB- basically	0.002710
analyzed and	0.200000
deployed in	0.500000
a natural	0.006135
detected ,	0.500000
processing the	0.018519
, either	0.001123
meaningful .	0.125000
answers can	0.083333
requirements .	0.500000
tasks ;	0.031250
interference	0.000029
generate translations	0.055556
3 or	0.200000
tasks ,	0.125000
tasks .	0.125000
's voices	0.019608
communicative event	0.333333
conventional computer	1.000000
make it	0.100000
mechanisms	0.000058
least partly	0.200000
time window	0.030303
deal primarily	0.250000
and rule	0.001445
Deciding	0.000029
promising line	1.000000
language	0.004285
the leaders	0.000692
-LRB- among	0.005420
techniques offer	0.043478
content-analysis	0.000029
achieved ,	0.200000
actually more	0.333333
of disassembling	0.000891
; for	0.042553
Sandra Thompson	1.000000
Both QA	0.333333
ISO	0.000058
carry	0.000029
for real-world	0.007220
started to	0.250000
cell phone	1.000000
to threshold	0.001328
yielding thousands	1.000000
approach using	0.028571
to tell	0.001328
see wide	0.050000
printer using	1.000000
Post	0.000058
have explicit	0.009615
Deirdre	0.000029
of features	0.000891
continuous	0.000174
accurately	0.000058
Bayes classifier	0.333333
selects the	0.500000
Parsing is	0.400000
scanning solution	0.500000
or cross-lingual	0.004505
analyze	0.000116
sets of	0.363636
were	0.001187
, SAM	0.000561
words not	0.009174
and Dragon	0.001445
translator need	0.142857
Thai do	0.500000
`` black	0.005291
Sociologist Harold	1.000000
an allowable	0.007576
subtopic	0.000029
robotic arm	1.000000
adequately solved	1.000000
The paradigm	0.005208
Genre	0.000058
finding a	0.400000
2001 and	0.500000
human-written ones	0.500000
far from	0.125000
recognition such	0.008264
are known	0.012448
high rank	0.055556
book a	0.125000
and documents	0.001445
creating an	0.285714
divided up	0.333333
summaries to	0.046512
by Lawrence	0.005714
baseball league	1.000000
runs PageRank	1.000000
correctly-developed	0.000029
thus makes	0.100000
stands for	1.000000
black	0.000029
out in	0.142857
Aletta Norval	1.000000
= 2PR	0.111111
-RRB- to	0.011268
image representing	0.333333
their ratings	0.029412
by both	0.005714
e.g. person	0.017857
summary	0.001216
based approach	0.018519
to automatizing	0.001328
holder of	1.000000
ID card	1.000000
which would	0.014493
user-provided number	1.000000
nouns ,	0.666667
tagset by	1.000000
College -LRB-	0.500000
reading	0.000232
no assumptions	0.076923
and TextRank	0.001445
its grammatical	0.028571
invalid constructs	1.000000
with speech	0.010929
according	0.000145
sidestepped the	1.000000
substitutions .	1.000000
Some ISO	0.047619
of possible	0.002674
to act	0.002656
possessive	0.000029
200 ,	0.500000
by The	0.005714
-RRB- Telematics	0.002817
progress is	0.142857
production	0.000087
perform automated	0.090909
progress in	0.285714
offered	0.000029
the equivalent	0.000692
bilingual corpus	0.500000
can of	0.005525
those	0.000637
are certain	0.004149
allow discriminative	0.200000
n't	0.000116
far too	0.125000
as ME	0.003484
readable summary	0.333333
Mr. is	0.500000
available resources	0.058824
or an	0.009009
can identify	0.005525
or as	0.009009
methods In	0.022727
Liu 's	1.000000
the emergence	0.000692
or keyphrases	0.004505
same	0.000724
- for	0.062500
of proper	0.000891
years after	0.047619
operating on	0.500000
intermediary	0.000087
driven ,	1.000000
card number	0.250000
Solutions have	1.000000
lexical functional	0.076923
another language	0.230769
element of	1.000000
rule that	0.333333
be derived	0.008439
\/ -LRB-	0.333333
Two years	0.428571
had failed	0.142857
by the	0.154286
answers that	0.083333
text on	0.006289
safety critical	1.000000
parse natural	0.111111
can make	0.016575
-LRB- Keyphrase	0.002710
text of	0.006289
what a	0.093750
aspect ,	0.500000
text or	0.018868
feature transformation	0.076923
novel proposal	1.000000
4	0.000145
Although	0.000232
differ from	0.333333
been achieved	0.029412
that OCR	0.003546
creation of	1.000000
containing examples	0.125000
Summarization of	0.250000
pilot effectiveness	0.200000
which make	0.014493
BORIS system	1.000000
Lehnart .	1.000000
system in	0.021505
and Civil	0.001445
its communicative	0.028571
their ``	0.029412
specified	0.000029
referring expressions	0.500000
New	0.000058
with language	0.005464
users	0.000261
-5 to	1.000000
positive and	0.285714
, factors	0.000561
has two	0.011905
Sentence boundaries	0.200000
lunar	0.000029
seconds	0.000029
problems	0.000492
data where	0.012987
broken	0.000145
paper is	0.090909
Statistical machine	0.222222
refers	0.000145
understanding system	0.030303
makes it	0.250000
separately from	1.000000
require to	0.045455
Basic sound	1.000000
meaning	0.000666
book applies	0.125000
which consisted	0.007246
; applies	0.021277
where ``	0.028571
as categories	0.003484
some glue	0.012048
course of	0.333333
TNO	0.000029
other sentences	0.014286
assessments of	1.000000
tense of	0.500000
became the	0.200000
text segmentation	0.044025
aircraft Substantial	0.142857
flexibility and	1.000000
but far	0.014706
fully automatic	0.500000
sub-titling ,	1.000000
platform to	0.500000
discriminate between	0.333333
Correct answers	1.000000
structure of	0.333333
1978 -RRB-	0.666667
the measurement	0.000692
Technolangue\/Easy Text	0.500000
involves paraphrasing	0.100000
projects in	0.500000
to form	0.005312
also growing	0.014493
, while	0.007861
assessing	0.000029
filtering out	1.000000
USMC	0.000029
school-age	0.000029
fast and	1.000000
ICASSP	0.000029
a piece	0.002454
nature of	1.000000
students	0.000087
narrative	0.000029
vertex	0.000087
building a	1.000000
handmade list	1.000000
necessary to	0.200000
Major	0.000058
derive meaning	0.500000
Higher rates	1.000000
, Barbara	0.000561
business rules	0.250000
one there	0.015385
starting	0.000029
represent	0.000261
rich lexicon	0.600000
other disciplines	0.014286
Wayne	0.000029
from printed	0.009615
competitions devoted	1.000000
December 2010	1.000000
More advanced	0.111111
is no	0.002033
they create	0.025000
Company for	0.500000
that ten	0.003546
fall	0.000116
desired language	0.200000
for sound	0.003610
, QUALM	0.000561
per page	0.250000
Text linguistics	0.166667
titled	0.000029
titles	0.000058
the magazine	0.000692
d'Albe	0.000029
Envelopes may	1.000000
summaries known	0.023256
surfer	0.000029
OCR -RRB-	0.020408
operating	0.000058
Makoto Nagao	1.000000
EHR will	0.333333
unigram ``	0.200000
person reads	0.052632
training step	0.071429
search	0.000318
post-processing step	0.666667
flow together	1.000000
a paper	0.001227
<s> consider	0.000769
anaphora .	1.000000
contain punctuation	0.083333
conduct with	1.000000
seek to	1.000000
semi-supervised	0.000058
read text	0.142857
they rely	0.025000
achieving	0.000058
Larry Page	0.500000
the US	0.001384
in US	0.001873
the UK	0.002768
be semantic	0.004219
controlling	0.000029
from computer	0.009615
the UC	0.000692
to video	0.001328
that corresponded	0.003546
Truecasing Statistical	1.000000
of 500	0.001783
diversity as	0.250000
the Tablet	0.000692
des	0.000029
effectiveness in	0.333333
best candidate	0.055556
strategies	0.000058
compare	0.000203
token is	0.500000
the challenge	0.000692
breathing	0.000029
Recent applications	0.333333
<s> Today	0.000769
both appear	0.032258
standard result	0.071429
attempted by	1.000000
followed by	0.500000
is whether	0.002033
a correct	0.002454
as part	0.006969
vary considerably	0.166667
letter ?	0.166667
What is	0.272727
see and	0.050000
letter ,	0.166667
system and	0.032258
semantic disambiguation	0.047619
<s> Besides	0.000769
and Sentences	0.001445
sometimes open-ended	0.076923
Dependent ''	1.000000
-LRB- Hirschman	0.002710
never been	0.400000
In all	0.009524
per minute	0.250000
Genres of	1.000000
Typical questions	0.500000
much funding	0.045455
analogy and	1.000000
most often	0.017241
What	0.000318
finalized	0.000029
, among	0.000561
pilots in	0.500000
humans would	0.083333
found that	0.357143
handheld	0.000029
late	0.000261
measure of	0.181818
very attractive	0.024390
transcriptions -LRB-	0.500000
tasks due	0.031250
spoken natural	0.071429
1990s there	0.333333
of semantic	0.004456
morphologically	0.000029
character-by-character	0.000029
into basic	0.012821
Spontaneous Speech	1.000000
expectancy of	1.000000
Gdaniec	0.000029
incorporates a	1.000000
-LRB- rescoring	0.002710
cross-lingual -RRB-	0.500000
and non-linear	0.001445
token	0.000116
can increase	0.005525
logical inference	0.166667
http:\/\/arxiv.org\/abs\/1104.2086	0.000029
another	0.000376
idea	0.000203
voice is	0.076923
voice in	0.076923
insurance	0.000029
Machinery and	1.000000
funding	0.000232
Our evaluation	0.333333
this reason	0.021978
McDonald -LRB-	1.000000
comprehension of	0.285714
could recognize	0.062500
that Piron	0.003546
the controller	0.001384
of related	0.002674
`` up	0.005291
`` uh	0.005291
`` um	0.005291
Semi-supervised and	1.000000
the role	0.001384
verbalization .	1.000000
are dealing	0.004149
Further applications	0.333333
to action	0.001328
a genetic	0.001227
very slow	0.024390
construct	0.000087
formulaic language	1.000000
<s> Dragon	0.000769
take the	0.200000
only complete	0.026316
1987 ,	0.666667
that human	0.007092
newswire	0.000029
based only	0.018519
e-communities die	0.500000
<s> Keyphrases	0.000769
b	0.000029
such signals	0.008130
information display	0.021739
Gisting Evaluation	1.000000
recognition of	0.074380
interactive	0.000116
ink -LRB-	1.000000
as input	0.006969
Pike	0.000029
-RRB- tagger	0.002817
sentence-end after	1.000000
well-defined problem	1.000000
'' by	0.026882
field .	0.148148
with any	0.005464
field ,	0.037037
together to	0.125000
vertices in	0.111111
extracted	0.000029
vertices is	0.111111
boolean syntactic	1.000000
window of	1.000000
select the	0.333333
depths	0.000029
Communications	0.000058
significant	0.000261
Markov model	0.444444
specialised expertise	0.500000
, extracting	0.000561
used similar	0.008850
is permuted	0.002033
Robinson	0.000029
, taking	0.000561
or POST	0.004505
of neural	0.000891
human-made model	0.500000
oral talk-in-interaction	1.000000
are pre-marked	0.004149
walk on	0.400000
corresponded	0.000029
a human-language	0.001227
carefully	0.000029
measurement is	0.500000
ambiguous context-free	0.083333
generators	0.000058
all about	0.023256
, LUNAR	0.000561
world assumption	0.133333
proper evaluation	0.142857
achieve performance	0.500000
for each	0.025271
words -RRB-	0.027523
campaign dedicated	0.200000
computerization	0.000029
market for	0.333333
Kurzweil sold	0.142857
do ''	0.038462
Wayne Ratliff	1.000000
Retrieval Conference	1.000000
learns a	1.000000
individual	0.000347
as classifying	0.003484
much more	0.181818
needs a	0.200000
authoritative of	1.000000
blend into	0.333333
Consortium has	1.000000
word was	0.016667
normalization to	0.166667
that accuracy	0.003546
it appropriately	0.008547
interfaces	0.000058
clauses ,	1.000000
Programming	0.000087
needs .	0.100000
correct output	0.066667
picture quality	0.250000
permuted automatically	1.000000
: rule-based	0.009804
also :	0.028986
an utterance	0.015152
a page	0.001227
interoperability between	1.000000
construction ,	0.333333
throughout	0.000029
AFTI	0.000029
, Gina	0.000561
discriminant	0.000058
create	0.000492
feeling that	1.000000
discourse processing	0.027778
legends and	1.000000
translated ,	0.250000
, conversation	0.000561
Symantec Corporation	0.500000
understand	0.000203
translation when	0.013514
the relative	0.000692
reformulate the	1.000000
bill	0.000058
well known	0.035714
annotation or	0.250000
is another	0.004065
, tables	0.000561
the computerization	0.000692
order logic	0.071429
Tagset	0.000029
learn features	0.076923
states are	0.250000
speaker of	0.111111
evaluated by	0.142857
different method	0.020408
approaches based	0.035714
subtopic of	1.000000
medium or	0.333333
speaker or	0.055556
emphasize	0.000029
copying	0.000029
made explicit	0.062500
into individual	0.012821
dissertation at	0.333333
assignment	0.000058
hybrid system	0.500000
may suffer	0.019231
software resources	0.037037
part of	0.814815
environment in	0.166667
Quechua ,	1.000000
that PageRank	0.003546
spend	0.000029
the string	0.000692
, when	0.003369
formatted output	1.000000
French in	0.125000
sound to	0.050000
a reader	0.001227
: Decoding	0.009804
In 1950	0.019048
being expended	0.055556
termed coarticulation	0.250000
In 1955	0.009524
Solving this	0.500000
injuries	0.000029
alignment	0.000058
it ends	0.017094
overall polarity	0.166667
still very	0.066667
where successively	0.028571
instance when	0.071429
further clues	0.125000
are traditionally	0.008299
of processing	0.000891
machine-learning approach	0.250000
a cheque	0.001227
Markov models	0.333333
The extrinsic	0.005208
of language-processing	0.000891
in languages	0.001873
the N-best	0.000692
alphabetic	0.000029
leaving the	1.000000
to create	0.011952
meets the	0.500000
President Obama	0.250000
is orthogonal	0.002033
of them	0.001783
stage is	0.400000
examples	0.000695
at A.C.	0.014706
integration	0.000029
per	0.000116
Interspeech -RRB-	1.000000
linked because	0.333333
ellipsis	0.000029
advanced pattern	0.200000
video the	0.200000
narrowest and	1.000000
e.g. space	0.017857
speaker deliberately	0.055556
<s> Eight	0.000769
only in	0.052632
and used	0.001445
keyphrase using	0.052632
are less	0.004149
through sentiment	0.125000
-LRB- CWA	0.002710
Word Error	0.142857
or characters	0.004505
neural networks	0.533333
Speaker Dependent	0.166667
requiring all	0.500000
scripts	0.000087
more widely	0.010526
mathematical rules	0.500000
Speech	0.000897
<s> Higher	0.000769
Shared	0.000029
jokes -LRB-	1.000000
the harder	0.002076
somewhat recent	0.500000
Joe Biden	1.000000
associate or	0.500000
'' can	0.026882
, news	0.000561
forward	0.000029
range from	0.285714
extract subjective	0.250000
a native	0.002454
semantic similarity	0.047619
paper-to-computer	0.000029
to recognize	0.007968
very limited	0.048780
Pyramid Method	1.000000
of formalisms\/languages	0.000891
content-analysis .	1.000000
language search	0.006757
Web as	0.111111
Genre Analysis	1.000000
input -RRB-	0.024390
language ,	0.040541
language .	0.074324
guessing wrong	1.000000
or phrase	0.004505
to search	0.001328
is embedded	0.002033
skilled linguist	1.000000
The Eurofighter	0.005208
a frame	0.001227
have many	0.048077
the morphology	0.000692
, like	0.001684
fail for	0.333333
it off	0.008547
them -LRB-	0.052632
inter-texual ones	0.500000
by keyphrase	0.005714
Tell me	1.000000
medical data	0.333333
one has	0.015385
probabilities to	0.090909
of HMM-based	0.000891
needed without	0.047619
years various	0.047619
discards	0.000029
algorithm or	0.035714
Their methods	0.500000
are marked	0.004149
query	0.000087
with diversity	0.005464
wear a	1.000000
approach that	0.057143
attention to	0.500000
Ernesto	0.000029
maximum entropy	0.500000
of four	0.000891
or MLLT	0.004505
a rudimentary	0.001227
Angenot	0.000029
determine keyphrases	0.043478
Grishman R.	1.000000
a pollen	0.001227
with Swedish	0.005464
bites ''	0.333333
networks make	0.071429
demonstrations	0.000029
the fields	0.000692
might shed	0.038462
and Zacharov	0.001445
dictionary entries	0.142857
Why unsupervised	0.142857
computer code	0.022727
adaptive document\/text	0.333333
giving	0.000058
in smaller	0.001873
involved disabilities	0.166667
These systems	0.235294
50 to	0.333333
research efforts	0.023810
Where such	1.000000
on one	0.009434
-LRB- MEAD	0.002710
focused on	0.909091
with morphological	0.005464
nonexistent	0.000029
to date	0.002656
to data	0.002656
World War	0.142857
HMMs	0.000232
this is	0.098901
10 -RRB-	0.125000
taggers .	0.142857
past the	0.333333
about an	0.025000
named	0.000203
evaluation considers	0.018519
boundaries .	0.363636
Given enough	0.071429
Research Corporation	0.125000
theoretical underpinnings	0.333333
notably by	0.333333
names	0.000203
Europe was	0.200000
from first	0.009615
different approaches	0.020408
citation needed	1.000000
of Pennsylvania	0.000891
themselves	0.000116
picture distortion	0.250000
database queries	0.100000
Text-to-speech Text-proofing	1.000000
Some tag	0.047619
RDF .	1.000000
pages concluded	0.142857
computer performance	0.022727
accuracy under	0.032258
-LRB- VTLN	0.002710
, standard	0.001123
Both acoustic	0.333333
given amount	0.041667
outside the	0.500000
levels are	0.045455
speech recognition	0.421053
detect the	1.000000
discors pour	1.000000
analyzing a	0.200000
effectively	0.000087
making them	0.142857
for measuring	0.003610
13 parsers	0.500000
; but	0.042553
regions	0.000058
most later	0.017241
providers began	1.000000
Authorities	0.000029
overfitting	0.000058
: Why	0.009804
an intermediary	0.007576
estimate the	0.500000
precursor to	1.000000
the open-access	0.000692
the ACL	0.000692
ISO standards	0.500000
one natural	0.030769
RAE -RRB-	1.000000
using paraphrases	0.016949
aid users	0.250000
discourse studies	0.027778
parsers is	0.076923
techniques from	0.043478
similarity or	0.100000
who have	0.200000
parsers in	0.076923
Hindle	0.000029
bunch	0.000058
le	0.000029
enough to	0.200000
to some	0.006640
the tokens	0.001384
resorting	0.000029
the abbreviation	0.000692
both its	0.032258
labor involved	0.500000
processing Statistical	0.018519
systems developed	0.017857
syntactic and	0.153846
intensive as	1.000000
involved fully	0.333333
programmed	0.000058
OCR machines	0.020408
an investigation	0.007576
method .	0.125000
doctors -RRB-	0.333333
rev	0.000029
automate the	0.333333
red	0.000029
build an	0.666667
different methods	0.020408
generate textual	0.055556
how a	0.068966
retrieved	0.000029
implied challenges	1.000000
<s> Lexical	0.001537
receipts	0.000029
innumerable studies	1.000000
idioms ,	1.000000
from NLP	0.009615
learning algorithm	0.116279
Ochs	0.000029
statistical machine	0.090909
retail	0.000029
to impersonate	0.001328
various levels	0.055556
more deeply	0.010526
Administration	0.000029
a worldwide	0.001227
might co-occur	0.038462
to prepare	0.001328
though ROUGE-1	0.100000
semantic model	0.047619
the expectancy	0.000692
Universal	0.000029
hyphenation .	1.000000
practical systems	0.500000
the removal	0.000692
represented by	0.333333
include :	0.111111
OCR ,	0.142857
disambiguation -RRB-	0.200000
OCR .	0.020408
the ROUGE-1	0.000692
include .	0.037037
of filtering	0.000891
assessment ,	1.000000
interface for	0.250000
a referring	0.001227
first choice	0.030303
emerge that	1.000000
contains the	0.200000
sciences concurrently	0.500000
VOLSUNGA .	1.000000
include a	0.111111
'' other	0.005376
by transfer-based	0.005714
<s> Two	0.005380
is Hard	0.002033
it learns	0.008547
techniques in	0.043478
Elinor	0.000029
It thus	0.026316
at the	0.220588
supported	0.000029
MARGIE -LRB-	1.000000
details of	0.500000
<s> Markov	0.000769
Nuance Communications	0.666667
of course	0.001783
L. 1998	1.000000
due especially	0.200000
what day	0.031250
ambiguity	0.000232
content selection	0.083333
the Standard	0.000692
Adriana	0.000029
is too	0.002033
can still	0.005525
areas	0.000174
by whom	0.005714
pruned to	1.000000
medical informatics	0.166667
Bois	0.000029
organised by	1.000000
entering a	0.500000
would both	0.018868
an excerpt	0.007576
the analog	0.000692
terms	0.000376
summarization based	0.020000
target language	0.727273
bank .	1.000000
exploited	0.000029
more widespread	0.010526
of news	0.001783
on OCR	0.004717
conversion .	0.333333
knowledge to	0.037037
which to	0.007246
, inter-texual	0.000561
compare various	0.142857
because fast	0.033333
implementing	0.000029
Merging	0.000029
accuracy -RRB-	0.064516
different co-occurring	0.020408
or structured	0.004505
range .	0.142857
freely	0.000029
early systems	0.100000
might learn	0.038462
famous QA	0.333333
dBase	0.000029
RAF employs	1.000000
, discourse	0.000561
filtered out	0.333333
machine representation	0.025316
in polynomial	0.001873
the Amount	0.000692
use in	0.013889
is particularly	0.004065
use it	0.027778
several seconds	0.045455
use is	0.013889
Harris 1991	0.111111
piecewise	0.000029
problems of	0.058824
<s> Jump	0.000769
Increase as	1.000000
the generated	0.001384
odd looking	1.000000
preliminary ,	0.333333
one 10msec	0.015385
Center	0.000029
structured documents	0.166667
key area	0.333333
meet a	0.250000
no effects	0.076923
emotion ,	1.000000
highlighted ,	1.000000
value	0.000087
-LRB- SWER	0.002710
Human Aided	0.200000
Guidelines	0.000058
thousands or	0.333333
500 texts	0.500000
prose	0.000029
valuable new	0.500000
than optimizing	0.022222
unreferenced section	1.000000
98.5 %	1.000000
+ Cloud	0.166667
parses -LRB-	0.500000
feature .	0.153846
northeast of	1.000000
been superseded	0.014706
How to	0.285714
man-hours	0.000029
algorithms work	0.028571
knowledge source	0.037037
center	0.000029
-RRB- amongst	0.002817
human summaries	0.021739
letter to	0.166667
been used	0.073529
have specific	0.009615
and support	0.001445
written conversation	0.038462
approximate at	0.500000
that consider	0.003546
as voice	0.003484
hybrid	0.000058
underlying	0.000087
are very	0.016598
languages text	0.020000
field	0.000782
kind of	0.727273
Friday	0.000087
as Greek	0.003484
of evaluation	0.004456
, semantically	0.000561
as blogs	0.003484
answered questions	0.600000
submit them	0.500000
tests	0.000116
elementary sounds	1.000000
MIT wrote	0.500000
worlds	0.000029
began offering	0.142857
the true	0.000692
10 parsers	0.125000
above techniques	0.076923
automatic lip-synch	0.043478
that combine	0.003546
are interpreted	0.004149
on finding	0.004717
direction of	0.333333
output by	0.038462
hear this	0.500000
of Speech	0.000891
analysis can	0.030769
works	0.000058
imprints	0.000029
domain-independent	0.000029
JSF -RRB-	1.000000
or words	0.004505
Further information	0.333333
Conferences ,	0.500000
measure ,	0.090909
for tagging	0.003610
M. ,	0.500000
character error	0.045455
encouraging	0.000029
are rarely	0.004149
them out	0.052632
tell it	0.333333
morphology of	0.142857
pilot workload	0.200000
depths of	1.000000
of Natural	0.000891
<s> Optical	0.001537
measure a	0.090909
only study	0.026316
simpler	0.000087
core elements	0.500000
processes such	0.200000
output distribution	0.038462
\/ target-language-independent	0.333333
sound that	0.050000
all possibilities	0.023256
Questions	0.000029
rendered	0.000029
dataset	0.000029
not invented	0.008929
phrase-structure	0.000029
the Senseval	0.000692
<s> Some	0.012298
for 1-July-2005	0.003610
1987	0.000087
1984	0.000029
1985	0.000029
1982	0.000087
1983	0.000029
language ''	0.013514
online assistant	0.125000
1989	0.000058
was later	0.012987
on Hidden	0.004717
potential and	0.142857
disambiguate	0.000087
and associated	0.001445
but	0.001969
human capabilities	0.021739
single source	0.142857
1949 .	0.500000
a score	0.001227
partially	0.000029
noun phrases	0.071429
same information	0.040000
Wall	0.000058
or 100000	0.004505
allowing greater	0.333333
similar measure	0.037037
clarification of	0.666667
or it	0.004505
or in	0.004505
autopilot system	1.000000
which of	0.007246
battle management	1.000000
a topic	0.001227
full sentenced	0.200000
virtual	0.000029
Schank 's	0.200000
assess the	0.333333
a separate	0.002454
report finalized	0.250000
Zellig Harris	1.000000
dependency for	0.200000
variation	0.000029
Act	0.000029
supervised learning	0.312500
or nonexistent	0.004505
<s> Winograd	0.000769
same topic	0.040000
system whose	0.010753
presentation of	1.000000
, bigram	0.001684
augmented	0.000029
be necessary	0.008439
probably use	0.250000
, potentially	0.000561
<s> Virtually	0.000769
to mimic	0.001328
analyses ,	0.200000
analyses .	0.400000
Introduction and	1.000000
produce textual	0.045455
data entry	0.038961
shown that	0.200000
the parts	0.000692
every	0.000087
current efforts	0.142857
linguistic analysis	0.062500
Another resource	0.076923
final sounds	0.111111
and paste	0.001445
and power	0.001445
Some notably	0.047619
writing SHRDLU	0.111111
to seize	0.001328
these tasks	0.047619
leaders	0.000029
logical deduction	0.166667
post-processing	0.000087
Gaussians	0.000029
related .	0.066667
estimated	0.000029
keyphrases	0.001013
publication devoted	0.333333
specification	0.000058
Continuous	0.000029
<s> Apart	0.000769
both rules	0.032258
their more	0.029412
conduct	0.000029
house -LRB-	0.500000
the nautical	0.000692
remains another	0.250000
four together	0.142857
aid	0.000116
path	0.000058
<s> Basically	0.000769
Beatrice	0.000029
recognized draft	0.166667
than supervised	0.022222
-RRB- showed	0.002817
-RRB- classifier	0.002817
the Optophone	0.000692
visible	0.000087
as decision	0.010453
'' sentence	0.005376
-LRB- one	0.002710
up with	0.136364
lessening	0.000029
as shallow-transfer	0.003484
possibilities multiply	0.200000
, HMM-based	0.000561
<s> From	0.000769
size of	0.166667
real-time	0.000058
about 25	0.025000
revolutionized bill	1.000000
me	0.000029
was drawn	0.012987
join	0.000029
may require	0.038462
my	0.000029
space complexity	0.200000
become repetitive	0.250000
be specified	0.004219
left-recursion and	1.000000
<s> An	0.008455
key words	0.166667
deemed most	0.500000
<s> As	0.010761
<s> At	0.002306
Dog bites	1.000000
right -LRB-	0.100000
entering the	0.500000
end	0.000232
efforts have	0.571429
statistics :	0.125000
Fundamentals	0.000058
, Art	0.000561
statistics ,	0.125000
statistics .	0.375000
Deborah Tannen	0.500000
pre-existing keyphrases	0.500000
we have	0.066667
Essentially	0.000029
can greatly	0.005525
reduced amount	0.250000
thereby editing	1.000000
task usually	0.023810
Semantic Evaluation	0.333333
looking to	0.400000
Prolog generally	1.000000
religious services	1.000000
as doctors	0.003484
bootstrap	0.000029
maybe to	1.000000
algorithms	0.001013
or syntactic	0.004505
quantitative one	0.250000
descriptor in	1.000000
thesis	0.000029
a context	0.002454
such name	0.008130
expectations	0.000058
comprehend	0.000029
<s> DTW	0.000769
fade	0.000029
to assist	0.001328
`` unsupervised	0.005291
to compiled	0.001328
<s> Both	0.001537
`` nine	0.005291
parse individual	0.111111
of mobile	0.000891
decimal point	1.000000
unreferenced	0.000029
of action	0.000891
wave and	0.111111
single ``	0.071429
Carmen Rosa	1.000000
signing	0.000029
-- including	0.040000
structured real-world	0.166667
combining	0.000116
the use\/mention	0.000692
1929 Gustav	1.000000
authors provide	0.200000
object ``	0.500000
got	0.000029
semantic representation	0.047619
1955 ,	1.000000
word British	0.016667
to carefully	0.001328
'' and	0.069892
in turn	0.009363
directly from	0.200000
each state	0.022222
does not	0.500000
with Tom	0.005464
mining have	0.200000
revolution in	1.000000
system had	0.010753
automatic translation	0.086957
already	0.000145
typically agree	0.055556
was unveiled	0.012987
coding	0.000029
quite different	0.375000
accurate even	0.142857
new methods	0.041667
Widdowson ,	1.000000
Summarization systems	0.250000
-LRB- MLLR	0.002710
aircraft ,	0.285714
aircraft .	0.142857
verbs -LRB-	0.200000
Lexical segmentation	0.500000
of certain	0.000891
words two	0.009174
several classifiers	0.045455
text mining	0.012579
to corpus	0.001328
tool	0.000058
serve	0.000145
took	0.000029
triples and	0.333333
human linguists	0.021739
Sydney Lamb	1.000000
Features	0.000029
summary '	0.023810
where clear	0.028571
summary ,	0.142857
summary .	0.261905
these heuristics	0.023810
others they	0.083333
be translated	0.012658
a trend	0.001227
this data	0.010989
fashion	0.000029
of automatic	0.001783
nonsensical to	1.000000
talking	0.000029
single document	0.071429
1,915,993 -RRB-	1.000000
behavior even	0.500000
respect to	1.000000
and time-consuming	0.001445
approach is	0.142857
oriented	0.000029
Dale -LRB-	1.000000
upper level	1.000000
effectiveness	0.000087
coarse-grained	0.000029
preliminary recognition	0.333333
of dependency	0.000891
been popular	0.014706
can indeed	0.005525
summarization Machine	0.020000
ways by	0.125000
movement to	1.000000
CWA	0.000029
, leading	0.000561
this technology	0.010989
used during	0.008850
flow	0.000029
a wide	0.002454
enterprise	0.000029
Word sense	0.285714
allow spoken	0.200000
the Latin	0.000692
random	0.000203
languages such	0.100000
nice properties	0.250000
design the	0.250000
this approach	0.021978
<s> Research	0.001537
salience	0.000029
pages getting	0.142857
semantics -RRB-	0.071429
statistical properties	0.030303
mixture	0.000029
; while	0.021277
followed perhaps	0.250000
has also	0.035714
, Henry	0.000561
the problem	0.006228
Kolodner .	1.000000
perhaps because	0.166667
The USAF	0.005208
other areas	0.028571
isolation	0.000058
learned is	0.200000
the question	0.011073
omni-font OCR	1.000000
of laws	0.000891
analysis Sublanguage	0.015385
when it	0.028571
smaller tag-sets	0.142857
larger corpora	0.062500
limiting	0.000029
benefits :	0.500000
made available	0.062500
data within	0.012987
a matter	0.001227
Sound Graph	0.333333
handwritten	0.000058
grammars -RRB-	0.142857
confusion	0.000029
better measure	0.111111
things ,	0.333333
Telephone Company	1.000000
is both	0.002033
built in	0.333333
improve	0.000376
20,000 words	1.000000
protect	0.000029
itself is	0.200000
each known	0.022222
merging	0.000058
we say	0.044444
the stationary	0.000692
skip the	1.000000
epidemic	0.000029
the expression	0.001384
algorithm for	0.071429
leftmost derivation	1.000000
Each sample	0.166667
another he	0.076923
been	0.001969
beer	0.000029
overlap ,	0.250000
overlap .	0.250000
i.e. it	0.052632
but also	0.073529
User profiling	0.500000
, one	0.003369
Interactional sociolinguistics	1.000000
objects of	0.200000
turns-at-talk	0.000029
, resolve	0.000561
are still	0.016598
to identify	0.006640
were then	0.024390
their reputations	0.029412
Bush	0.000058
translation capabilities	0.013514
up a	0.090909
easily ,	0.111111
relevance or	0.333333
recursion	0.000029
it affects	0.008547
complex	0.000695
several	0.000637
government and	0.333333
<s> Big	0.000769
from large	0.009615
-LRB- 2000	0.002710
-LRB- 2001	0.002710
-LRB- 2004	0.002710
-LRB- 2005	0.002710
-LRB- 2008	0.002710
compiler ,	0.333333
expected -LRB-	0.142857
models derived	0.038462
answers the	0.083333
impressive results	0.500000
Statistical Methods	0.111111
Success Rate	1.000000
approximation of	0.166667
idea is	0.142857
than metrics	0.022222
, we	0.009545
a naive	0.001227
Speech recogniton	0.032258
it into	0.042735
proposed keyphrases	0.222222
take into	0.300000
up an	0.045455
G. ,	0.500000
applies those	0.142857
National Giro	0.333333
in software	0.001873
Research on	0.125000
a 3	0.001227
topic boundaries	0.125000
a 4	0.001227
template containing	0.250000
D	0.000029
the entities	0.000692
James	0.000116
while on-line	0.050000
estimation and	1.000000
-LRB- See	0.010840
as it	0.003484
<s> Main	0.000769
article on	0.034483
specific	0.000608
This parses	0.015873
Gismo .	0.500000
F-16 aircraft	0.500000
fixed static	0.500000
indirect	0.000029
identified which	0.200000
the strings	0.000692
more words	0.010526
implemented in	0.200000
agreement is	0.333333
, content	0.000561
a test	0.003681
outputs of	1.000000
core	0.000058
translation method	0.013514
Formal equivalence	1.000000
data at	0.012987
Journal .	0.333333
Hollenbach	0.000029
that without	0.003546
-RRB- Cohesion	0.002817
limitation	0.000029
run-time	0.000029
the implications	0.000692
objects and	0.200000
of AI	0.000891
left-most and	0.500000
BASEBALL	0.000058
geospatial questions	1.000000
signal can	0.333333
than other	0.022222
primitive	0.000029
Much effort	0.333333
readily produces	0.333333
accommodate	0.000145
it has	0.034188
modern approaches	0.200000
Given the	0.071429
called the	0.111111
wishes to	1.000000
Language modeling	0.083333
rely	0.000203
categorization	0.000029
words have	0.009174
ambiguous when	0.083333
Competing	0.000029
head	0.000058
medium	0.000087
statistical and	0.030303
radios ,	1.000000
, Pang	0.000561
hear	0.000058
computer OCR	0.022727
authors decide	0.200000
generate keyphrases	0.055556
Electronic	0.000058
`` sailor	0.010582
be implemented	0.008439
increasingly focused	0.333333
, large-vocabulary	0.000561
it was	0.025641
classification looks	0.058824
production has	0.333333
requires an	0.062500
performance and	0.111111
print a	1.000000
`` be	0.010582
no	0.000376
time are	0.030303
concepts .	0.400000
of special	0.000891
further discussed	0.125000
translation components	0.013514
besides words	1.000000
preceding	0.000029
-RRB- Commissioned	0.002817
reason is	0.250000
more such	0.010526
e.g. vocabulary	0.017857
typically one	0.055556
Latin very	0.250000
assumptions such	0.200000
region in	1.000000
discussions about	0.333333
representation .	0.210526
taggers for	0.142857
we need	0.133333
Artificial Intelligence	0.500000
input data	0.146341
algebra .	0.500000
varying	0.000029
like relevance	0.035714
and one	0.001445
web 2.0	0.125000
case-based reasoning	1.000000
procedure still	0.333333
Japanese -RRB-	0.125000
translation can	0.027027
of concern	0.000891
vital .	1.000000
discrete terms	0.333333
field of	0.444444
advantage	0.000145
your system	0.500000
as noun	0.003484
Chinese is	0.142857
be seen	0.012658
faster but	0.333333
recognition and	0.057851
extraction Answer	0.032258
was greatly	0.012987
political forums	0.333333
It follows	0.026316
accumulation	0.000029
tasks has	0.031250
taggers	0.000203
likely uttered	0.062500
more generally	0.010526
to acquire	0.001328
Red	0.000029
shorter the	0.500000
creates a	0.500000
large-vocabulary	0.000087
isolated NLP	0.200000
document classification	0.055556
yesterday with	0.666667
realizations	0.000029
less likely	0.166667
for Greek	0.003610
normally do	0.500000
groups	0.000145
articulation ,	1.000000
delimited	0.000116
thirty	0.000029
what happens	0.031250
delimiter	0.000029
efforts are	0.142857
offs in	1.000000
language -LRB-	0.013514
strong feeling	0.250000
Much remains	0.333333
speaker reads	0.055556
can use	0.016575
`` dogs	0.021164
this understanding	0.010989
ACL ,	0.500000
stored	0.000029
into smaller	0.012821
tagging for	0.040000
available on	0.058824
are limited	0.004149
; An	0.021277
documents than	0.026316
, e.g.	0.005615
on linguistic	0.004717
methods need	0.045455
were undertaken	0.024390
R. ,	0.333333
In any	0.019048
an English-like	0.007576
successful NLG	0.111111
major influence	0.083333
below .	0.400000
German	0.000116
Digitized Sound	1.000000
domain of	0.100000
from several	0.009615
for use	0.007220
classification error	0.058824
successful NLP	0.111111
domain or	0.050000
laughter	0.000029
written text	0.115385
sub-signals .	1.000000
learning approaches	0.023256
-LRB- selecting	0.002710
performed	0.000290
some local	0.012048
an easy	0.007576
foreign ''	0.500000
few sentences	1.000000
require significant	0.045455
requirements	0.000058
innumerable	0.000029
many similar	0.019231
's the	0.019608
to the	0.102258
patents .	1.000000
computers and	0.111111
aircraft platforms	0.142857
news release	0.076923
the primary	0.001384
also programs	0.014493
methodology to	0.500000
targets to	1.000000
both LexRank	0.032258
training and	0.035714
shows ,	1.000000
word co-occurrence	0.016667
best algorithms	0.055556
coordinates	0.000029
Who invented	0.500000
recognition systems	0.082645
sequence of	0.875000
<s> OCR	0.003075
a high	0.003681
symbol in	0.250000
conversations	0.000087
original voice	0.076923
common plural	0.040000
detailed background	0.500000
Web is	0.111111
as described	0.006969
until the	0.500000
language documents	0.006757
possibilities	0.000145
than one	0.066667
weighted	0.000087
noise and	0.125000
as early	0.003484
out ''	0.071429
dictionary-based	0.000029
of John	0.000891
coherent or	0.200000
Critical discourse	0.500000
adequately	0.000029
lexicon ,	0.111111
ultimately	0.000029
lexicon .	0.111111
belongs to	1.000000
process of	0.333333
replicated his	1.000000
theory	0.000376
basic approach	0.076923
List	0.000058
essentially to	0.125000
a specific	0.006135
morphemes and	0.333333
word-category disambiguation	1.000000
the addressee	0.000692
speech the	0.006579
units ,	0.142857
English this	0.027027
units ;	0.142857
searching and	0.333333
automatic metric	0.043478
person-years of	1.000000
simplified	0.000058
little inflectional	0.333333
have been	0.250000
millions	0.000058
language in	0.006757
sequences of	0.333333
their associated	0.029412
and Canada	0.001445
convention	0.000029
Such	0.000232
proposed .	0.111111
language is	0.033784
LexRank has	0.083333
who ''	0.100000
each one	0.044444
and analysis	0.001445
known to	0.076923
QA computer	0.047619
holder	0.000029
cryptanalyst	0.000029
proposed a	0.222222
text that	0.025157
pre	0.000029
Computationally	0.000029
's students	0.019608
statistically evaluated	1.000000
pro	0.000029
machine speech	0.012658
recognition conferences	0.008264
context that	0.030303
any	0.000897
semantic lexicons	0.047619
or continuous	0.004505
transcription	0.000058
informal behavior	0.500000
, political	0.000561
choice :	0.125000
of input	0.002674
expression or	0.100000
regards to	1.000000
comprises all	1.000000
payment systems	1.000000
the areas	0.001384
isolated word	0.200000
banking system	1.000000
is worth	0.004065
segmentation :	0.090909
or places	0.004505
require their	0.045455
distribution ;	0.250000
and count	0.001445
can present	0.005525
statistical models	0.212121
segmentation ,	0.090909
include the	0.185185
several million	0.045455
input and	0.048780
the approximate	0.000692
June 1990	1.000000
his ``	0.083333
business data	0.250000
, allowing	0.000561
formed Symantec	0.200000
that capture	0.003546
any font	0.032258
explicitly	0.000116
movie reviews	0.333333
V.J.	0.000029
Roger Fowler	0.250000
1998 The	0.250000
estimating the	1.000000
others ,	0.083333
others .	0.250000
floods	0.000029
is preferable	0.002033
Mirage	0.000029
disambiguation on	0.100000
are displayed	0.004149
expensive ,	0.428571
simpler sounds	0.666667
; rejecting	0.042553
years to	0.047619
maximum	0.000174
undertook	0.000029
. -RRB-	0.500000
, whose	0.001123
stream is	0.500000
detect	0.000029
rules are	0.023256
in source	0.001873
artificial neural	0.090909
and RCA	0.001445
was one	0.012987
Voice Control	0.200000
English for	0.027027
between Internet	0.025641
T to	0.166667
Chomskyan	0.000029
these are	0.047619
receivers	0.000029
the legends	0.000692
segmentation tools	0.060606
least historically	0.200000
content of	0.083333
and removed	0.001445
to interface	0.001328
opinions or	0.500000
similarity between	0.200000
successes	0.000029
region	0.000029
During the	0.500000
confusions with	1.000000
at NYU	0.014706
not pursued	0.008929
separate out	0.100000
new .	0.041667
were compared	0.048780
color	0.000029
Transform	0.000029
, Ernesto	0.000561
Note	0.000261
some new	0.012048
are explicitly	0.004149
the computer	0.001384
But	0.000174
Typhoon	0.000029
mean of	0.500000
are the	0.045643
hardly	0.000029
output simply	0.038462
define several	0.500000
smart keyboard	1.000000
QA Before	0.047619
put together	0.250000
a podcast	0.001227
evaluations ,	0.166667
evaluations .	0.166667
Barbara	0.000029
paying	0.000029
specialised	0.000058
Computer Problem	0.166667
exploits the	1.000000
, evaluation	0.000561
thus it	0.100000
technique in	0.142857
tested in	0.500000
chatterbots	0.000058
LexRank The	0.083333
for Amharic	0.003610
values correlate	0.125000
punched	0.000029
Hidden	0.000174
via the	1.000000
and Natural	0.001445
POS-tagging algorithms	1.000000
be applied	0.012658
alphabet	0.000087
is insufficient	0.002033
information .	0.086957
information ,	0.043478
the choice	0.000692
events	0.000029
Sentence breaking	0.200000
about to	0.025000
Homayoon	0.000029
in accordance	0.001873
of robustness	0.000891
changing	0.000029
on either	0.004717
discourse analyst	0.027778
Automatic vs.	0.111111
model	0.000869
much time	0.045455
at emotional	0.014706
guided	0.000029
On January	0.166667
<s> Whether	0.001537
language usually	0.006757
uh ''	1.000000
Piron mentions	0.333333
, Naive	0.000561
13 ,	0.500000
% correct	0.025641
except	0.000029
Penn Treebank	0.666667
, individual	0.000561
system on	0.010753
includes -LRB-	0.142857
UC and	0.500000
, dimensions	0.000561
recent news	0.125000
available soon	0.058824
system or	0.021505
desired structure	0.200000
success and	0.200000
also attempt	0.014493
, regardless	0.001684
Nikolas	0.000029
defined by	0.166667
mechanisms of	0.500000
Army	0.000116
of its	0.007130
successful .	0.111111
voice commands	0.076923
subtypes	0.000029
provided	0.000145
disambiguate parts	0.333333
prolific	0.000029
legal	0.000087
systems included	0.008929
provider	0.000058
'' where	0.005376
programming language	0.200000
the time	0.004152
item may	1.000000
low-resolution	0.000029
Schegloff ,	1.000000
analyzing human-written	0.200000
John Swales	0.250000
real-world applications	0.166667
formal grammar	0.222222
on	0.006138
of	0.032483
and languages	0.001445
vs. independence	0.083333
<s> User	0.000769
six -LRB-	0.500000
communication	0.000145
use an	0.013889
the data	0.002768
originally as	0.500000
separate tokens	0.100000
categories could	0.111111
house	0.000058
of 21	0.000891
`` natural	0.015873
from limited	0.009615
Sandra	0.000029
typically uses	0.055556
against a	0.200000
applying	0.000116
qualitative	0.000058
strongly	0.000058
of prisoner-of-war	0.000891
or classified	0.004505
's subscription	0.019608
recognition scores	0.008264
of several	0.002674
superseded by	1.000000
politics	0.000029
methods parse	0.022727
negative to	0.125000
systems were	0.053571
generates a	0.666667
printed texts	0.083333
feature statistical	0.076923
that within	0.007092
recognize all	0.111111
art .	0.500000
has already	0.011905
spoken language	0.142857
to reliable	0.001328
usually abbreviated	0.031250
worldwide view	1.000000
includes	0.000203
for input	0.003610
ICR	0.000087
font .	0.666667
recall .	0.666667
see above	0.050000
a reference	0.002454
abbreviated to	1.000000
many of	0.038462
Brain	0.000029
are much	0.008299
-RRB- do	0.002817
sublanguage	0.000087
are given	0.012448
open ,	0.250000
OS or	0.500000
independently developed	1.000000
canonical form	1.000000
polarity	0.000232
contexts .	0.285714
contexts ,	0.285714
those organised	0.045455
devices take	0.250000
removal	0.000029
program	0.000637
presentation	0.000029
the summarization	0.002076
scores are	0.200000
Michael Halliday	0.250000
in further	0.001873
system proposed	0.010753
distinction with	0.200000
, systems	0.001123
spoken version	0.071429
a training	0.001227
Record or	1.000000
Ontology -RRB-	1.000000
ten	0.000029
embedded quotations	0.250000
theory -RRB-	0.076923
<s> Sometimes	0.000769
battle	0.000058
rate	0.000318
's necessary	0.019608
design	0.000116
meanings of	0.250000
humanities and	1.000000
Morpheme	0.000029
software started	0.037037
systems that	0.062500
are popular	0.004149
deeply	0.000029
the position	0.000692
segmentation	0.000955
task depends	0.023810
recent development	0.125000
- based	0.187500
developing a	0.250000
phones and	0.500000
speaking -RRB-	0.125000
and named	0.001445
, imagery	0.000561
summaries do	0.023256
not resulted	0.008929
modified in	1.000000
understanding systems	0.030303
Style	0.000029
for evaluation	0.003610
without limits	0.076923
article ,	0.103448
<s> When	0.004612
and Church	0.001445
texts	0.000492
accomplished in	1.000000
and Chinese	0.001445
article :	0.448276
associate discrete	0.500000
to support	0.002656
evaluation -LRB-	0.018519
is formed	0.002033
for special	0.003610
-LRB- Adda	0.002710
happens when	1.000000
support personnel	0.250000
repetitive stress	0.500000
Confusable	0.000029
serve as	0.800000
= accusative	0.111111
framework .	0.750000
with using	0.005464
networks are	0.071429
debates	0.000058
and introducing	0.001445
mimic the	1.000000
Of particular	1.000000
features describing	0.038462
Jacob Rabinow	1.000000
other English	0.014286
type provided	0.071429
good source	0.076923
, predicting	0.000561
be programmed	0.008439
've seen	0.500000
taggers are	0.142857
predicate	0.000029
arise	0.000029
and going	0.001445
combining the	0.250000
have humans	0.009615
publishing ,	1.000000
grammatical constituents	0.090909
reported for	0.200000
textual weather	0.200000
continued with	0.111111
for sentence	0.003610
the mid	0.000692
available -LRB-	0.058824
was only	0.012987
engaging in	1.000000
capitalize	0.000029
reader processed	0.100000
ontologies -LRB-	0.166667
ports .	1.000000
tokens 12	0.142857
understanding :	0.030303
segment in	0.111111
mission	0.000029
understanding ,	0.090909
understanding .	0.060606
spoken sentences	0.071429
summaries available	0.023256
Carnegie	0.000058
model mechanisms	0.033333
might	0.000753
Caldas-Coulthard ,	1.000000
creating a	0.285714
attempts have	0.166667
Cleave	0.000029
Front-End speech	1.000000
character .	0.045455
for grammars	0.003610
character ,	0.090909
1954 -RRB-	0.333333
even ``	0.037037
why automatic	0.142857
affected by	1.000000
inherent	0.000029
difficult	0.000811
10msec section	0.500000
of languages	0.000891
sublanguage domains	0.333333
Jefferson	0.000029
issue for	0.125000
include all	0.037037
is 8000	0.002033
naive Bayes	0.500000
an attractive	0.007576
health	0.000029
hand-compiled	0.000029
in excess	0.003745
experimenting	0.000029
such application	0.008130
in text	0.001873
profile may	0.333333
teach	0.000029
SemEval -RRB-	1.000000
generate	0.000521
captures data	1.000000
typical to	0.111111
Evaluation exercises	0.111111
People	0.000058
writing rules	0.111111
significantly .	1.000000
both summarization	0.032258
for instance	0.018051
, hypothetical	0.000561
as they	0.010453
spelling .	1.000000
degradation in	1.000000
Frost	0.000029
to get	0.005312
themselves .	0.250000
speech sounds	0.006579
information Popular	0.021739
-RRB- If	0.005634
by describing	0.005714
automatic speech	0.130435
the undercarriage	0.000692
Armed Forces	1.000000
One step	0.076923
information are	0.021739
Romance languages	1.000000
includes Turney	0.142857
first such	0.030303
-- computer	0.040000
usually takes	0.031250
or query	0.004505
<s> It	0.026134
VISTA	0.000029
versa first-cut	1.000000
<s> In	0.074558
of shared	0.000891
expected for	0.142857
<s> If	0.006149
F-score ,	1.000000
, Talmy	0.000561
process -LRB-	0.027778
, contains	0.000561
what might	0.031250
available from	0.058824
summary in	0.047619
measures	0.000174
later the	0.100000
<s> Therefore	0.001537
sense a	0.125000
summary is	0.047619
measured	0.000174
may then	0.019231
person .	0.052632
person ,	0.210526
also important	0.014493
email Multimodal	0.500000
, Gdaniec	0.000561
fluent native	1.000000
children ,	0.500000
team led	1.000000
other POS	0.014286
work at	0.041667
difficulty using	0.142857
worked by	0.200000
memorandum	0.000029
Morse Code	1.000000
word .	0.133333
, from	0.000561
To perform	0.111111
and architecture	0.001445
concentrates on	1.000000
speech segmentation	0.032895
Why it	0.142857
walk is	0.200000
Grace project	1.000000
-LRB- SemEval	0.002710
of bottom-up	0.000891
Why ,	0.142857
following is	0.066667
function for	0.125000
an Electronic	0.007576
performance .	0.166667
performance ,	0.111111
Mellon University	1.000000
and life	0.001445
TF-IDF	0.000029
1,000,000	0.000029
2.0	0.000058
periods in	0.333333
whereas in	0.333333
simulation is	0.333333
approached in	0.500000
2,663,758 .	1.000000
recently	0.000087
be quite	0.004219
grammatical structure	0.090909
generally used	0.090909
with high	0.010929
see Inter-rater	0.050000
breadth ''	0.500000
there was	0.075000
oriented systems	1.000000
to all	0.003984
on Mirage	0.004717
of grammar	0.001783
reasons	0.000058
a group	0.001227
billing purposes	1.000000
AI systems	0.666667
Willig	0.000029
due	0.000145
strategy	0.000145
restricted-domain QA	1.000000
by combining	0.005714
metric for	0.333333
tokens that	0.142857
technology is	0.136364
trying to	1.000000
era of	1.000000
text-to-speech synthesizer	0.250000
of war	0.000891
has characterized	0.011905
character stream	0.045455
and ``	0.028902
p.	0.000029
pronouns and	0.500000
Biden was	0.333333
A morphosyntactic	0.020000
Hindle D.	1.000000
the European	0.001384
blocks world	0.250000
, then	0.006176
turns-at-talk .	1.000000
after the	0.166667
, they	0.004492
technologies have	0.250000
pumps ''	0.500000
with sentences	0.005464
from social	0.009615
answers rather	0.083333
exactly this	0.333333
linguistic controversy	0.062500
efficient manner	0.333333
languages using	0.020000
robust	0.000116
Man bites	0.500000
lower	0.000145
characters \*	0.062500
optimization methods	1.000000
tools mostly	0.166667
aim of	0.500000
Constraints are	0.333333
Examples	0.000087
also granted	0.014493
Parsing :	0.200000
whom -RRB-	0.500000
abilities	0.000029
<s> First	0.000769
, comprehend	0.000561
produce such	0.045455
one distinguishes	0.015385
stationary probabilities	0.142857
variety of	1.000000
analyzed with	0.200000
exclusively	0.000029
in conference	0.001873
States .	0.285714
could read	0.062500
some large	0.012048
President Bush	0.500000
larger chunk	0.062500
, Richard	0.000561
tongues sharing	1.000000
Penn -RRB-	0.111111
integer	0.000029
Often a	0.333333
phrasing the	1.000000
translators	0.000029
ones in	0.100000
only five	0.026316
for a	0.104693
understood	0.000029
of canned	0.000891
in these	0.005618
gradually	0.000029
translates to	1.000000
prisoner-of-war camp	1.000000
tends	0.000029
fragments	0.000029
useful for	0.214286
for .	0.003610
itself as	0.200000
an early	0.007576
for 5	0.003610
by a	0.102857
for mental	0.003610
also need	0.014493
One task	0.076923
being psychotherapy	0.055556
the typewritten	0.000692
a prior	0.001227
each pilot	0.022222
fast	0.000029
keyphrases of	0.028571
vendors	0.000116
Every	0.000029
paraphrase .	1.000000
needed for	0.095238
OCR Document	0.020408
more deterministic	0.021053
40 %	1.000000
as weighted	0.003484
corpus of	0.225806
deployed	0.000058
platforms	0.000029
to language	0.001328
associated	0.000116
priorities .	1.000000
Syntactic	0.000029
Encouraging	0.000029
word-forms	0.000029
Establishment	0.000029
Marilyn Monroe	1.000000
form logical	0.050000
research articles	0.023810
try to	1.000000
, idioms	0.000561
all governmental	0.023256
<s> Note	0.006918
called query-biased	0.055556
multiple languages	0.076923
inter-word	0.000058
ground established	1.000000
helping people	1.000000
conversational content	1.000000
Rogerian	0.000029
weights	0.000145
The systems	0.005208
methods more	0.022727
Increasingly ,	1.000000
expert that	1.000000
issued	0.000029
tables with	0.333333
were later	0.024390
-LRB- JSF	0.002710
issues	0.000145
work based	0.041667
democratizing publishing	0.500000
deterministic	0.000116
levels or	0.045455
, preposition	0.000561
levels of	0.318182
division rather	0.500000
overlaps	0.000058
, exploring	0.000561
some programming	0.012048
the 1950s	0.002076
check how	0.500000
expectations ,	1.000000
car	0.000029
and speed	0.002890
farther forward	1.000000
term used	0.111111
Google used	0.250000
reliability ,	0.500000
idea ,	0.142857
correct software	0.066667
alternative approach	0.333333
for commercial	0.003610
rephrase sentences	1.000000
<s> Shepard	0.000769
subjective sentences	0.166667
-LRB- end	0.002710
stochastic matrix	0.125000
on Shepard	0.004717
The profile	0.005208
desired	0.000145
and see	0.001445
earliest example	0.500000
Eastern Peru	1.000000
up in	0.090909
or highly	0.004505
quality .	0.100000
covers speech	0.250000
Hybrid MT	0.500000
this article	0.043956
Treebank project	0.166667
in Jones	0.001873
for what	0.007220
were rare	0.024390
reading credit	0.125000
addressee	0.000029
biomedical domain	1.000000
use	0.002084
&	0.000232
GenEx algorithm	1.000000
few	0.000029
Objectives The	1.000000
timing	0.000029
sort	0.000087
but is	0.029412
are obtained	0.008299
specially designed	1.000000
but it	0.058824
schematic	0.000029
recorded all	0.500000
Blind In	0.500000
a QA	0.004908
, can	0.003369
Supervised	0.000029
Tannen	0.000029
scope of	1.000000
might be	0.230769
but in	0.029412
of reasons	0.000891
topic	0.000232
barmaid .	0.166667
with many	0.005464
Deferred speech	1.000000
need context	0.047619
iteration ,	1.000000
tagging program	0.040000
initially clear	1.000000
visit Iraq	0.500000
Emanuel Goldberg	0.500000
entirely committed	0.500000
source sentence	0.083333
canned phrases	0.500000
summers	0.000029
in embedded	0.001873
edge cases	0.333333
capitalizes all	1.000000
, Google	0.000561
, hence	0.000561
possible improvement	0.041667
abstractive methods	0.333333
tractability	0.000029
and probably	0.001445
marks are	0.250000
and direction	0.001445
and practice	0.001445
applications can	0.040000
gold standards	0.166667
neighbors .	0.333333
looks	0.000116
neighbors ,	0.333333
given a	0.166667
aloud from	1.000000
or uncertainties	0.004505
linguistics	0.000579
Did Marilyn	1.000000
but could	0.014706
more precise	0.010526
Optical Character	0.333333
sub-categories	0.000029
estimating	0.000029
has wide	0.011905
orange	0.000029
GRM library	1.000000
relate to	1.000000
defining	0.000029
singular ,	0.250000
evaluations are	0.333333
did fail	0.200000
given ,	0.041667
the cosine	0.000692
all caps	0.023256
<s> Books	0.000769
unfortunately ,	1.000000
; that	0.021277
and whether	0.001445
human knowledge	0.021739
`` centrality	0.005291
algorithms --	0.028571
sentences with	0.013158
be defined	0.004219
a lunar	0.001227
induction	0.000058
, identifying	0.001684
starts with	0.500000
plant OCR	1.000000
the reader	0.002768
This	0.001824
that users	0.003546
numbers on	0.142857
LOB Corpus	1.000000
relay services	1.000000
phrases	0.000463
, grammars	0.000561
which research	0.007246
one may	0.015385
contains additional	0.100000
phrased	0.000029
John Du	0.125000
pieces as	1.000000
of off-line	0.000891
cognition and	1.000000
It converted	0.026316
ALPAC	0.000058
of Question	0.000891
of London	0.000891
cited the	1.000000
ICASSP ,	1.000000
Intra-texual	0.000029
shallow	0.000174
its decomposition	0.028571
regards	0.000029
intonation	0.000029
tables of	0.333333
to submit	0.001328
casual speech	1.000000
hearings	0.000029
and ICR	0.002890
study ,	0.250000
or paragraphs	0.009009
narrative text	1.000000
<s> Anaphor	0.000769
By 1985	0.333333
Processing -LRB-	0.750000
a first	0.002454
mention in	0.333333
talk-in-interaction .	1.000000
for descriptive	0.003610
2PR \/	1.000000
the Alenia	0.000692
first use	0.030303
the relevance	0.000692
impossible when	0.500000
deteriorated with	1.000000
would correspond	0.018868
many cases	0.038462
The problem	0.015625
=	0.000261
Parseval\/GEIG	0.000029
historical data	1.000000
key phrases	0.166667
data redundancy	0.012987
prose text	1.000000
known keyphrase	0.038462
the basis	0.002768
of finite	0.000891
often possible	0.022727
be referred	0.004219
these summaries	0.047619
the basic	0.001384
sailor ‚Üí	0.200000
aims at	0.333333
not obvious	0.008929
wingmen	0.000029
no.	0.000029
, Court	0.000561
planning	0.000058
Document	0.000116
Recovery	0.000029
of perspective	0.000891
then chosen	0.028571
formal language	0.222222
left to	0.166667
spun	0.000029
verification .	1.000000
a reasonable	0.002454
words -LRB-	0.027523
displayed	0.000058
but to	0.014706
non-existent words	1.000000
users sometimes	0.111111
blend smoothly	0.666667
generate jokes	0.055556
termed Direct	0.250000
split it	0.250000
make no	0.050000
brain	0.000087
to extract	0.003984
version ;	0.333333
Desktop &	1.000000
Fundamentals of	1.000000
on specific	0.004717
fail to	0.333333
machines to	0.250000
reducing the	0.500000
Units	0.000029
the stage	0.000692
: Deciding	0.009804
cepstral normalization	0.500000
unigrams and	0.083333
Programming methods	0.333333
, sentiment	0.000561
arguably	0.000058
below	0.000145
industry currently	0.333333
NASA 's	1.000000
medical professionals	0.166667
the additional	0.000692
keeping a	0.500000
commands	0.000145
before .	0.166667
dividing written	0.333333
Voice2Go -RRB-	1.000000
most upper	0.017241
interpretable rules	1.000000
sentence also	0.020833
some interrogative	0.012048
why Vice	0.142857
the authors	0.000692
to guide	0.001328
it began	0.008547
table	0.000203
contexts in	0.142857
very widely	0.024390
domain ,	0.150000
domain .	0.300000
language as	0.006757
Klavans	0.000029
Gripen cockpit	1.000000
inadequate	0.000029
<s> Coreference	0.000769
analysis as	0.015385
, Chantal	0.000561
sufficient	0.000145
<s> Decoding	0.000769
whether they	0.076923
for breathing	0.003610
15-20 million	1.000000
or most	0.004505
Force	0.000058
declared before	0.500000
possessive ,	1.000000
not worked	0.008929
results were	0.047619
untagged	0.000029
Matches between	1.000000
layer	0.000087
information deemed	0.021739
Reinvestment	0.000029
Electronic Medical	0.500000
range of	0.571429
a member	0.001227
expressions .	0.666667
company Kurzweil	0.333333
Scotland .	0.400000
Scotland ,	0.200000
linear discriminant	0.285714
rare .	0.500000
parsers are	0.153846
member	0.000029
that much	0.003546
transform ,	0.400000
still just	0.066667
reliability -RRB-	0.500000
by analogy	0.005714
only be	0.026316
only by	0.052632
representation and	0.105263
TF-IDF vectors	1.000000
even disappear	0.037037
at input	0.014706
navigation systems	0.500000
general concepts	0.045455
States	0.000203
before or	0.166667
each year	0.022222
the token	0.000692
meaningful symbols	0.125000
not	0.003243
of online	0.000891
queries on	0.333333
rapid	0.000029
Morphological	0.000029
or moderate	0.004505
capabilities	0.000145
, spacecraft	0.000561
success of	0.600000
But recognition	0.166667
yes-no	0.000029
uses search	0.071429
the World	0.003460
T	0.000174
presume	0.000029
2007 -RRB-	0.200000
Energy -LRB-	1.000000
or generators	0.004505
have approached	0.009615
undirected and	1.000000
lowest level	1.000000
Section	0.000029
entry -LRB-	0.250000
the mid-90s	0.000692
larger corpus	0.125000
to physicians	0.001328
applications have	0.080000
text normalization	0.006289
information contained	0.021739
markers	0.000087
\* -LRB-	0.250000
as 1946	0.003484
<s> Evaluating	0.001537
Algorithm	0.000029
expressed on	0.333333
conveyed	0.000029
Lightning II	1.000000
analyses	0.000145
analyser	0.000029
perspectives	0.000029
extension	0.000029
column	0.000029
an understanding	0.015152
Zacharov	0.000029
generally rely	0.090909
that sentences	0.003546
own	0.000174
a bank	0.001227
Star Trek	1.000000
consecutively	0.000029
distinction is	0.400000
SRI International	1.000000
disagree on	0.333333
EHR -RRB-	0.333333
of parser	0.001783
smoothing	0.000029
in 1953	0.001873
in 1952	0.001873
in 1954	0.003745
, possibly	0.000561
compare their	0.142857
conferences held	1.000000
or word-category	0.004505
triggered	0.000029
Science	0.000058
Intuitively ,	1.000000
bill stub	0.500000
machine printed	0.012658
-RRB- mark	0.002817
in popular	0.001873
articles from	0.125000
obvious at	1.000000
documents or	0.026316
came from	0.500000
the Reader	0.000692
record	0.000058
computer analysis	0.022727
demonstrate	0.000029
Once the	0.200000
, medial	0.000561
better data	0.111111
freely available	1.000000
knowledge specific	0.037037
Potentially	0.000029
person to	0.105263
pilot ,	0.200000
Lander	0.000058
given loss	0.041667
widespread .	1.000000
other	0.002027
horoscope machines	1.000000
software that	0.037037
can have	0.011050
a tonal	0.001227
: Information	0.009804
texts so	0.058824
or transfer-based	0.004505
opened ,	1.000000
scale -LRB-	0.166667
Attribute grammars	1.000000
in using	0.005618
four	0.000203
or nature	0.004505
the probable	0.000692
increase	0.000116
language require	0.006757
often marked	0.022727
Hard to	0.500000
Test of	1.000000
sampling rate	1.000000
Apparatus for	1.000000
the ALPAC	0.001384
between positive	0.025641
MIT .	0.500000
weights .	0.400000
the EVALITA	0.000692
basics	0.000029
inadequate protection	1.000000
alphabet are	0.333333
Paul	0.000145
Models In	0.333333
John 's	0.250000
specially	0.000029
definition of	0.600000
`` higher	0.005291
as dynamic	0.003484
later ,	0.500000
connected regions	0.200000
who applied	0.100000
optical character	1.000000
typical sentences	0.111111
the unigram	0.000692
an opinion	0.007576
whether -LRB-	0.076923
common .	0.080000
similar kind	0.037037
between 1964	0.025641
real progress	0.111111
GRM	0.000029
seize the	1.000000
starting to	1.000000
techniques used	0.043478
elaborate	0.000029
of parameters	0.000891
identification pattern	0.200000
addition might	0.166667
advantages	0.000029
Dyer developed	1.000000
processes used	0.400000
queries to	0.333333
replace	0.000029
their features\/aspects	0.029412
could usefully	0.062500
, punctuation	0.000561
; we	0.021277
Harris 's	0.222222
framework based	0.250000
part-of-speech	0.000434
% accuracy	0.102564
Recent	0.000087
that access	0.003546
false positives	0.500000
Inc. and	0.500000
NLG applications	0.047619
combining decisions	0.250000
<s> Before	0.000769
any sentences	0.032258
to correlate	0.001328
example	0.002345
LMF	0.000029
to discriminate	0.002656
and often	0.004335
help determine	0.111111
currency	0.000029
the fly	0.000692
, sometimes	0.000561
sentiment in	0.080000
feature	0.000376
sentiment is	0.040000
cryptanalyst at	1.000000
ones already	0.100000
abstraction	0.000116
mid-90s	0.000029
the relationships	0.000692
include straightforward	0.037037
types	0.000405
English or	0.027027
-LRB- i.e.	0.029810
-LRB- Speereo	0.002710
English of	0.027027
orally	0.000029
objectives :	0.500000
English on	0.027027
database or	0.200000
wave is	0.222222
possibility of	0.750000
is more	0.006098
database of	0.200000
wave in	0.111111
of tasks	0.000891
was quite	0.012987
-LRB- HMT	0.002710
Machines Research	1.000000
subjects with	1.000000
easier	0.000232
MySpace -RRB-	1.000000
experiment -LRB-	0.200000
to merge	0.001328
entire banking	0.333333
e.g. ``	0.017857
created by	0.285714
proper declaration	0.142857
is focused	0.002033
a keyphrase	0.002454
next token	0.142857
discourse in	0.055556
light on	0.333333
discourse is	0.083333
lexical segmentation	0.076923
definitional	0.000029
series	0.000232
Recognizing	0.000029
substantially	0.000029
person or	0.105263
running English	0.333333
scaling system	1.000000
Home automation	1.000000
suffer .	1.000000
Word	0.000203
Peter Turney	1.000000
Work	0.000058
systems for	0.017857
measured in	0.166667
the more	0.003460
LDA-based projection	1.000000
the dialog	0.000692
enormous	0.000029
Chafe ,	1.000000
`` Customized	0.005291
from advertisements	0.009615
, including	0.004492
superimpose one	1.000000
Closed-domain question	1.000000
1970s	0.000087
caught	0.000029
speeds	0.000058
comparison ,	0.333333
languages .	0.160000
languages ,	0.220000
Due	0.000029
combines the	1.000000
triggered other	1.000000
Nations and	0.500000
levels but	0.045455
sentences to	0.078947
hypothetical	0.000029
which will	0.021739
different people	0.020408
more complicated	0.010526
the talk	0.000692
and performance	0.001445
Intra-texual methods	1.000000
to re-encode	0.001328
the holder	0.000692
it quite	0.008547
those two	0.045455
showed	0.000116
tree	0.000029
project	0.000376
the past	0.001384
`` beyond	0.005291
chosen domain	0.200000
GRASSHOPPER for	0.333333
in recognizing	0.003745
readily conveyed	0.333333
hypothetical ,	1.000000
of applications	0.002674
state transducers	0.071429
of campaigns	0.000891
virtually impossible	0.500000
anything ,	1.000000
process correctly	0.027778
first-order	0.000029
appropriate action	0.250000
ANR-Passage	0.000029
<s> Speaker	0.001537
the polarity	0.000692
visit .	0.500000
evaluation would	0.055556
The first	0.036458
Jones	0.000029
du discors	1.000000
without documents	0.076923
's promise	0.019608
campaigns were	0.500000
, also	0.002807
gracefully with	1.000000
testing the	0.200000
and combining	0.001445
came	0.000058
incorporate	0.000029
result of	0.272727
descriptive rather	0.333333
within the	0.166667
but these	0.014706
examples Performance	0.041667
participate	0.000029
explicitly delimited	0.250000
`` speech	0.005291
constructs can	0.333333
lessons	0.000029
samples per	0.500000
by expanding	0.005714
Running PageRank\/TextRank	1.000000
relationship extraction	0.333333
particular dataset	0.076923
<s> Discourse	0.002306
by A.	0.005714
commands issued	0.200000
meant and	0.500000
Henry Kucera	0.500000
are exploited	0.004149
physician ,	1.000000
sentences are	0.092105
even several	0.037037
experimenting .	1.000000
how many	0.103448
not aid	0.008929
OCR Accuracy	0.020408
translating texts	0.250000
transcriptions is	0.500000
training in	0.035714
similarity score	0.100000
large set	0.043478
in Europe	0.003745
text normally	0.006289
software often	0.037037
, containing	0.001123
Battle Management	0.500000
country	0.000116
spite of	1.000000
probably the	0.250000
logic	0.000116
semantic constraints	0.047619
essence of	1.000000
held each	1.000000
the tasks	0.000692
or may	0.009009
un-supervised ''	1.000000
adverb	0.000029
funding for	0.250000
one must	0.015385
indirect left-recursion	1.000000
How are	0.285714
this work	0.010989
dynamically	0.000058
` local	0.062500
approximation .	0.166667
generate high-quality	0.055556
references .	0.250000
table that	0.142857
texts seems	0.058824
worked	0.000145
lengths -RRB-	1.000000
running publication	0.333333
so-called delta	0.333333
number 20	0.023256
HMMs underlie	0.125000
NLP using	0.021277
Harrison	0.000029
the 1990s	0.001384
delta-delta	0.000058
toolkit	0.000058
several sub-problems	0.045455
hear sound	0.500000
and does	0.001445
Main	0.000347
and above	0.001445
what new	0.031250
across most	0.600000
computationally ;	0.500000
Video games	1.000000
a printed	0.001227
out that	0.071429
used include	0.008850
maintains that	1.000000
simulates	0.000029
<s> Therein	0.000769
of trying	0.000891
world currently	0.066667
not be	0.107143
controversial .	1.000000
historically used	0.500000
simulated	0.000058
quantitative	0.000116
`` Conversational	0.005291
the frequency	0.000692
selecting duplicate	0.200000
that ,	0.003546
and space	0.001445
produces usable	0.250000
dependence vs.	1.000000
year or	0.166667
previous	0.000087
teletype typewritten	1.000000
<s> Perhaps	0.000769
used being	0.008850
connected Web	0.200000
in Star	0.001873
text conversion	0.006289
make better	0.050000
methods were	0.045455
determine whether	0.043478
percentage of	1.000000
that a	0.010638
collection .	0.200000
`` semi-supervised	0.005291
of simpler	0.001783
as machine	0.003484
Evaluation of	0.111111
opposite of	1.000000
instead for	0.142857
decade to	0.333333
speech .	0.065789
speech ,	0.072368
to involved	0.001328
Lexical	0.000058
rate .	0.090909
in translating	0.001873
consists of	1.000000
of grammatical	0.000891
input six	0.024390
The vectors	0.005208
fine degrees	0.500000
speech a	0.006579
somewhat shallow	0.500000
multiple subtasks	0.076923
rules for	0.046512
accuracy because	0.032258
work in	0.125000
be fully	0.008439
entrants	0.000029
by grid	0.005714
approximates that	0.500000
to consistently	0.001328
work is	0.125000
-LRB- allowing	0.002710
raised	0.000029
Knowledge	0.000058
speaker-dependent	0.000029
Hybrid	0.000058
segment to	0.111111
Few	0.000029
kind ,	0.090909
, computational	0.000561
OS .	0.500000
F-score	0.000029
support	0.000116
-LRB- counselling	0.002710
resulted	0.000058
typical real-world	0.111111
-RRB- Current	0.002817
on-line	0.000087
, flexibility	0.000561
article accuracy	0.034483
non-trivial techniques	0.500000
many years	0.019231
Latin alphabet	0.250000
a particular	0.004908
<verb>	0.000029
devices	0.000116
not able	0.008929
currently using	0.142857
can form	0.005525
automating abstractive	1.000000
characters using	0.062500
likely to	0.437500
lexicon with	0.111111
steady	0.000058
textbook	0.000058
''	0.005617
formed by	0.200000
`` pseudo-pilot	0.005291
multiscript texts	1.000000
Digitized	0.000029
e.g. The	0.035714
first commercial	0.060606
relay	0.000029
most authoritative	0.017241
the lexical	0.000692
-LRB- especially	0.005420
Flickinger D.	1.000000
`` Intelligent	0.005291
answers from	0.166667
, find	0.001123
's	0.001477
's input	0.019608
models	0.000753
research has	0.142857
a rightmost	0.002454
text by	0.006289
analyzing it	0.200000
appropriate perspective	0.250000
Charles	0.000029
because while	0.033333
2006 ,	0.333333
<s> Trained	0.000769
and rich	0.001445
human in	0.021739
breadth	0.000058
8000 samples	1.000000
Realtime	0.000029
communication radios	0.200000
John Heritage	0.125000
sufficient include	0.200000
LexisNexis was	1.000000
DA began	0.333333
inflected	0.000058
extrinsic -RRB-	0.166667
the field	0.011765
various constructions	0.055556
Stef Slembrouck	1.000000
the naval	0.000692
meaningful portions	0.125000
vertices should	0.111111
Gender =	1.000000
or shifted	0.004505
treat them	0.500000
a tag	0.001227
recognizing and	0.200000
Recognize	0.000029
empirical solutions	1.000000
Stubbs ,	1.000000
, English-like	0.000561
IR relies	0.333333
being used	0.055556
except some	1.000000
e.g. the	0.053571
to artificial	0.002656
occurrence	0.000058
are extractive	0.004149
with edit	0.005464
Francis	0.000029
textbook of	0.500000
understanding	0.000955
a huge	0.001227
1970 -RRB-	0.333333
is unclear	0.002033
consistently achieve	0.333333
case ''	0.058824
a way	0.006135
tasks	0.000926
, relatively	0.000561
logical	0.000174
reliably --	1.000000
example shows	0.012346
than 150	0.022222
SHRDLU	0.000174
, artificial	0.001123
languages semantics	0.020000
and here	0.001445
LexRank simply	0.083333
voices	0.000029
angry	0.000058
, pronunciation	0.000561
<s> svg	0.000769
This problem	0.063492
scope	0.000058
theoretical	0.000087
as of	0.006969
semantic schemes	0.047619
, during	0.000561
organization ,	0.200000
have direct	0.009615
-RRB- This	0.002817
understanding approximates	0.030303
of hard	0.001783
help in	0.111111
other purposes	0.014286
`` My	0.005291
returned from	0.500000
the expected	0.001384
sublanguage of	0.333333
costly training	1.000000
language other	0.006757
this product	0.010989
between words	0.051282
sentence in	0.041667
need to	0.476190
sentence is	0.041667
including probabilistic	0.071429
unveiled	0.000029
Canada ?	0.166667
Lexical choice	0.500000
Tagging Guidelines	1.000000
with collecting	0.005464
optimize some	1.000000
to construct	0.001328
optimal	0.000029
: whereas	0.009804
He decided	0.125000
linguist working	0.500000
tagging techniques	0.040000
Development Activity	1.000000
corpora ''	0.090909
Xuedong	0.000029
1950 ,	1.000000
improving	0.000029
the best	0.008997
that the	0.081560
natural	0.002171
correlate	0.000087
Peru ,	0.500000
biographical	0.000029
by analyzing	0.011429
critical or	0.250000
opinionated	0.000029
<s> Components	0.000769
so	0.000869
broken in	0.200000
extraction task	0.032258
reasoning to	0.142857
constructions occur	1.000000
includes transfer-based	0.142857
issues Disambiguation	0.200000
popular in	0.111111
a valid	0.001227
tasks are	0.125000
about this	0.025000
and final	0.001445
an associated	0.007576
rate crossed	0.090909
as smart	0.003484
thereby	0.000029
language models	0.013514
not determine	0.008929
consonants ,	0.333333
SHRDLU for	0.166667
actually playing	0.333333
and consonants	0.001445
as phoneme	0.003484
and so	0.008671
methods of	0.045455
validated and	1.000000
two waves	0.034483
way they	0.041667
gaming	0.000029
The sub-committee	0.005208
dividing a	0.333333
about social	0.025000
rewrite it	1.000000
review of	0.333333
classifying the	0.200000
investigation	0.000029
likely a	0.062500
, you	0.000561
means the	0.166667
Task and	0.666667
numbers represent	0.142857
Head-driven phrase	1.000000
the requirements	0.000692
Penn tag	0.222222
is red	0.002033
accompanying HTK	1.000000
the factors	0.000692
right ''	0.100000
Brazil	0.000029
released ``	0.500000
on the	0.306604
evaluating summaries	0.400000
a form	0.001227
development has	0.083333
city	0.000029
efficient however	0.333333
have error	0.009615
other systems	0.028571
He taught	0.125000
following manner	0.066667
create edges	0.058824
, conjunction	0.000561
whole phrases	0.111111
shifting to	1.000000
other text	0.028571
look to	0.200000
Parliament of	0.500000
<s> Progress	0.000769
subfields	0.000029
artificial processes	0.181818
for QA	0.010830
, Speech	0.001684
usually a	0.031250
factors affect	0.333333
the Apollo	0.000692
would recognize	0.018868
instructed	0.000029
spoken -RRB-	0.071429
as artificial	0.003484
question marks	0.023810
how well	0.206897
non-annotated data	1.000000
in fact	0.001873
questioner might	0.250000
roughly proportional	0.333333
distorted by	0.500000
itself to	0.200000
l'assignation des	1.000000
Topic segmentation	1.000000
average	0.000058
the CCD	0.000692
successfully adapted	0.333333
be needed	0.004219
Conferences in	0.500000
dynamic background	0.200000
laws	0.000029
Genres	0.000029
shallowest ,	1.000000
, stutering	0.000561
examples for	0.041667
memory of	0.500000
Systems	0.000347
these techniques	0.023810
as to	0.013937
bought the	1.000000
of linguistics	0.000891
semi -	1.000000
ASR ''	0.166667
Applied	0.000058
, articulation	0.000561
assistant	0.000029
between	0.001129
linear-time versions	1.000000
discourse structure	0.027778
Paul W.	0.200000
resource	0.000145
a qualitative	0.002454
more accurate	0.031579
; this	0.063830
approximately 200	0.500000
from naive	0.009615
by simple	0.005714
a unified	0.001227
-RRB- has	0.008451
are variously	0.004149
labor intensive	0.500000
as many	0.006969
software tools	0.037037
That	0.000087
ostensibly	0.000029
complex NLG	0.041667
intelligence technologies	0.125000
Symbian	0.000029
processing The	0.018519
expression which	0.100000
Thai	0.000058
complex NLP	0.083333
screen	0.000029
reference to	0.250000
about basic	0.025000
many	0.001505
understand ''	0.142857
Whether NLP	0.500000
last night	0.200000
The Duchess	0.005208
left-recursion	0.000029
keyphrase	0.000550
<s> LexisNexis	0.000769
On-line systems	0.333333
FST	0.000029
considers	0.000058
, Nuance	0.000561
allow blind	0.200000
storing ,	1.000000
suitable department	0.250000
damping	0.000029
as latent	0.003484
to right	0.001328
+4 -RRB-	1.000000
relationship between	0.166667
enable	0.000058
Turney with	0.111111
E. ,	0.250000
thus avoiding	0.100000
parsing systems	0.035714
measure summary	0.090909
psychotherapy	0.000029
hidden	0.000232
Adda G.	0.500000
methods and	0.022727
Several research	0.333333
morphemes .	0.333333
<s> Unfortunately	0.000769
used speech	0.008850
especially common	0.133333
and Web	0.001445
boundary '	0.166667
applications such	0.040000
sales data	0.333333
binary	0.000116
problems for	0.058824
of to	0.000891
wrote that	0.166667
not words	0.026786
a short-time	0.001227
without confusions	0.076923
relevant text	0.142857
The technology	0.005208
methods achieved	0.022727
new cross-discipline	0.041667
convey intended	0.333333
Harris et	0.111111
about the	0.200000
, volume	0.000561
not rely	0.017857
Page\/Lex\/TextRank	0.000029
format .	0.500000
reviews to	0.166667
different related	0.020408
corporation does	1.000000
intended for	0.400000
and searching	0.001445
compensate for	1.000000
data-to-text systems	1.000000
efficiently .	1.000000
interested in	1.000000
were written	0.024390
records .	0.500000
aspects	0.000203
around	0.000232
, installed	0.000561
includes both	0.142857
mechanism for	1.000000
Algorithms	0.000058
`` mentions	0.005291
name -LRB-	0.200000
avoiding some	0.500000
to machine-learning	0.001328
the interim	0.000692
sub-sounds	0.000029
all view	0.023256
founder of	1.000000
large ;	0.043478
reference that	0.125000
Penicillin ''	1.000000
summary used	0.023810
and achieves	0.001445
consistently use	0.333333
that removing	0.003546
decorrelating	0.000029
text-understanding system	1.000000
- NC	0.062500
delta and	1.000000
refer	0.000174
unsupervised approach	0.125000
set to	0.025641
experience is	0.500000
formed ?	0.400000
action should	0.200000
is easily	0.002033
parsers can	0.076923
common ones	0.040000
the important	0.000692
will seem	0.028571
Dijk ,	1.000000
a five-star	0.001227
George Lakoff	1.000000
can get	0.005525
`` Army	0.005291
analysis is	0.015385
her	0.000058
guide the	1.000000
the textual	0.000692
The methods	0.010417
it formed	0.008547
Some systems	0.095238
often involve	0.022727
map to	0.500000
are delimited	0.012448
provide additional	0.166667
roughly ,	0.666667
Anaphor resolution	1.000000
Web .	0.222222
an equivalent	0.007576
desktop OCR	1.000000
, unless	0.000561
raised in	1.000000
first agree	0.030303
% in	0.025641
robustness	0.000116
away unlikely	0.500000
that did	0.007092
an approach	0.030303
is typical	0.002033
reasons .	0.500000
Front-End	0.000029
theory Functional	0.076923
of years	0.000891
Computing Machinery	0.500000
, communication	0.000561
, Eurospeech\/ICSLP	0.000561
recursive productions	1.000000
other related	0.014286
<s> Digitized	0.000769
been attained	0.014706
disambiguate the	0.333333
automatic machine	0.043478
-LRB- rather	0.002710
do predict	0.038462
Direct	0.000029
examples can	0.041667
EVALITA	0.000058
Gene Ontology	1.000000
to have	0.013280
, Oklahoma	0.000561
extent -RRB-	0.250000
the table	0.001384
<s> Most	0.001537
to	0.021800
computer-aided translation	0.333333
Treebank .	0.333333
<s> LREC	0.001537
returned	0.000116
have more	0.028846
epidemic which	1.000000
nodes in	0.142857
a fancy	0.001227
usually has	0.031250
large	0.000666
to assess	0.001328
very simple	0.048780
' stability	0.052632
it helps	0.008547
to say	0.003984
summarization have	0.020000
between IR	0.025641
handwritten ,	0.500000
to serve	0.001328
to two	0.001328
ROUGE is	0.400000
in computer-aided	0.001873
were developed	0.121951
favor	0.000058
CSR have	0.333333
been produced	0.014706
account context	0.333333
scientists	0.000029
Rhetoric	0.000029
sometimes referred	0.230769
a model	0.001227
influence in	1.000000
al. 1989	1.000000
at processing	0.014706
PageRank\/TextRank	0.000029
article quoting	0.034483
and required	0.001445
Information retrieval	0.200000
him or	0.500000
compiler or	0.333333
Agency -LRB-	0.500000
many examples	0.019231
; This	0.021277
meaning -LRB-	0.043478
is adaptive	0.002033
example Mr.	0.012346
recognition software	0.024793
reads it	0.500000
6	0.000116
This section	0.031746
orally speaking	1.000000
to robots	0.001328
using photocells	0.016949
pauses in	0.250000
reporter -LRB-	1.000000
The only	0.010417
: Word	0.009804
qualitative manner	0.500000
<s> ROUGE-1	0.000769
technology are	0.045455
100 %	0.666667
tasks that	0.031250
the training	0.002768
a corpus	0.003681
Nelson Francis	1.000000
the documents	0.002076
waves	0.000203
final letter	0.111111
glossary words	0.500000
It had	0.026316
register	0.000029
sounds -LRB-	0.133333
lexicon of	0.222222
the two	0.003460
fundamental	0.000058
topics .	0.142857
format called	0.500000
grammar because	0.027027
distortion	0.000029
another verb	0.076923
partly statistical	1.000000
of comprehensive	0.000891
method can	0.062500
of glass-box	0.000891
reranking	0.000029
is generated	0.006098
termed	0.000116
Wetherell ,	1.000000
computed with	0.500000
user interface	0.071429
reported -LRB-	0.200000
of scanned	0.000891
Sound	0.000087
Grammar	0.000029
Michael	0.000116
Mobile devices	0.333333
1980s the	0.111111
2006 hurricane	0.333333
during a	0.200000
recent years	0.500000
summarization It	0.020000
, T	0.000561
Graesser	0.000029
as length	0.003484
extraction removes	0.032258
letters blend	0.100000
found	0.000405
, Deirdre	0.000561
of scholars	0.000891
Progress mainly	1.000000
Rose	0.000029
main verb	0.125000
reduce	0.000029
Rosa	0.000029
, EMNLP	0.000561
measurement	0.000058
the systems	0.002076
Reading ''	0.500000
On-line	0.000087
degraded-images ,	1.000000
To address	0.111111
University 's	0.111111
itself while	0.200000
Defense	0.000029
words in	0.091743
In corpus	0.009524
United States	0.777778
were walking	0.024390
and curves	0.001445
same type	0.040000
POST	0.000029
to locate	0.001328
Halliday	0.000029
-RRB-	0.010683
the unigrams	0.001384
Behind this	1.000000
distances for	0.500000
's instructions	0.019608
recursively .	0.500000
<s> might	0.000769
is precision	0.002033
wingmen with	1.000000
jet	0.000029
introduction	0.000029
, Edmund	0.000561
Lemke ,	1.000000
long research	0.500000
elaboration	0.000029
application has	0.071429
nodes to	0.142857
readable human	0.333333
as gold	0.003484
Often	0.000087
algorithm optimizes	0.035714
not sufficient	0.008929
producing natural	0.333333
beforehand	0.000029
: Emergent	0.009804
MEAD -RRB-	1.000000
more basic	0.021053
for speech	0.014440
generalizes	0.000029
of what	0.003565
reliance	0.000029
internal	0.000145
generalized	0.000029
of Chomskyan	0.000891
extrinsic evaluation	0.500000
horizontal mark	1.000000
, too	0.000561
only automate	0.026316
machine-aided human	1.000000
of diagonal	0.000891
rare or	0.250000
Cloud	0.000029
gold	0.000174
went on	0.200000
coarticulation ,	1.000000
described above	0.500000
restaurant ,	0.500000
author of	0.333333
uses continuous	0.071429
Chantal	0.000029
'' would	0.010753
writer	0.000029
despite being	0.333333
factor	0.000058
its history	0.028571
fragments that	1.000000
and business	0.001445
Thai and	0.500000
systems favor	0.008929
methods can	0.022727
vs. Spontaneous	0.083333
the Information	0.000692
groups within	0.200000
calculates n-gram	1.000000
Different types	1.000000
effective in	0.333333
banking	0.000029
most can	0.017241
social interaction	0.071429
and speaker	0.001445
using edges	0.016949
beyond which	0.166667
the built	0.000692
medium levels	0.333333
multiple source	0.076923
permuted	0.000029
an expression	0.007576
OCR-A	0.000029
questions about	0.153846
influenced by	1.000000
a higher	0.002454
, Paroubek	0.000561
available	0.000492
speech -RRB-	0.026316
several ambiguous	0.045455
the largest	0.000692
been tried	0.029412
or interpreter	0.009009
war camp	1.000000
typical sentence	0.111111
the interactions	0.000692
-LRB- 3rd	0.002710
the chosen	0.000692
linguistics concerned	0.050000
find the	0.307692
Stilstudien	0.000029
potential parses	0.142857
computer input	0.022727
using the	0.101695
Tags	0.000029
Mariani	0.000029
system by	0.010753
and related	0.004335
that adjectives	0.003546
Effective natural	1.000000
but BLEU	0.014706
obstacles to	1.000000
The nodes	0.005208
representative	0.000029
1989 ?	0.500000
real world	0.333333
by humans	0.011429
isolation of	0.500000
out -LRB-	0.071429
reliable	0.000116
while an	0.050000
of classifying	0.000891
grouped into	0.500000
reliably	0.000029
and human-generated	0.001445
provided a	0.200000
read characters	0.142857
parsing In	0.035714
the ARCHILES	0.000692
capture speech	0.500000
Since OCR	0.200000
general principles	0.045455
-RRB- NASA	0.002817
provides additional	0.500000
Anaphor	0.000029
action .	0.200000
processing of	0.037037
comprehensive	0.000145
performed by	0.200000
languages -LRB-	0.040000
Fourier	0.000087
Army Avionics	0.250000
person	0.000550
used that	0.008850
refer to	1.000000
data and	0.025974
, their	0.000561
Labov	0.000029
abbreviation	0.000058
editing the	0.500000
conclusions	0.000029
advertisements	0.000058
first order	0.030303
compared German	0.142857
the sample	0.000692
and search	0.001445
Both	0.000087
format	0.000058
the metrics	0.000692
controllers .	0.333333
only want	0.026316
, most	0.004492
went past	0.200000
formal	0.000261
<s> LexRank	0.001537
sorting	0.000029
human speech	0.021739
reasoning .	0.142857
various NLP	0.055556
focus on	0.571429
which we	0.007246
language can	0.006757
hand coding	0.071429
kick '	1.000000
genres of	1.000000
plus some	1.000000
it will	0.017094
` caught	0.062500
7 %	0.142857
phonetic-based	0.000029
facemask ,	1.000000
Santorini	0.000029
or keep	0.004505
<s> Despite	0.000769
, web	0.000561
digitized	0.000029
, Words	0.000561
very optimistic	0.024390
broadcast news	1.000000
question types	0.023810
UPV	0.000029
relating	0.000029
` summary	0.062500
automated online	0.142857
<s> Much	0.002306
strategies to	0.500000
unlike brain	1.000000
the technique	0.000692
NER	0.000029
Perspectives The	1.000000
annotation and	0.250000
most linguists	0.017241
other than	0.014286
alignment method	0.500000
infinitive	0.000029
model all	0.033333
internal representation	0.600000
translation Interlingual	0.027027
the entire	0.000692
are fields	0.004149
up	0.000637
us	0.000058
um	0.000029
-LRB- normalized	0.002710
uh	0.000029
quotations ,	1.000000
storing	0.000029
automated ,	0.142857
parses	0.000058
parser	0.000463
nautical	0.000058
parsed	0.000116
by context-free	0.005714
University included	0.111111
visible under	0.333333
'' the	0.005376
the coherence	0.000692
both be	0.032258
times throughout	0.200000
extractive summarization	0.428571
holes	0.000029
equivalent set	0.200000
to blind	0.001328
the segment	0.000692
grammatical parts	0.090909
most positive	0.017241
having	0.000145
inference --	0.250000
complex images	0.041667
Progress	0.000029
on sentences	0.004717
, leads	0.000561
then the	0.057143
built a	0.333333
those running	0.045455
sentences in	0.105263
exigencies of	1.000000
machine-encoded	0.000029
handover system	1.000000
to backup	0.001328
but most	0.029412
prove impossible	1.000000
colloquially	0.000058
an objective	0.007576
matching and	0.200000
texts written	0.058824
recall-based measure	0.500000
Schroeder ,	1.000000
try	0.000087
functional grammar	0.500000
commercial .	0.090909
Words and	0.250000
summary tackles	0.023810
nuances and	1.000000
nuggets of	1.000000
licensed	0.000029
lower levels	0.400000
NLP An	0.021277
in recognition	0.003745
of science	0.000891
Janet	0.000058
words ''	0.018349
<s> Each	0.003843
consistently	0.000087
HTML	0.000029
were performed	0.024390
, researchers	0.001123
Fourier transform	0.666667
to select	0.005312
Prior	0.000029
invented	0.000058
explicit models	0.200000
On-line character	0.666667
-- i.e.	0.040000
bar code	1.000000
resulting	0.000116
F.	0.000029
a long-time	0.001227
can exploit	0.005525
retrieved .	1.000000
effect the	0.500000
Leading	0.000029
judge ,	0.250000
which many	0.007246
a sentiment	0.002454
small text	0.111111
different possible	0.020408
promoting diversity	1.000000
, shop	0.000561
Engineers ''	0.500000
<s> Speech	0.011530
e.g. elaboration	0.017857
a sense	0.001227
background knowledge	0.333333
category registry	0.500000
for understanding	0.003610
campaign compared	0.200000
sound creates	0.050000
for approximating	0.003610
Regardless	0.000029
challenge	0.000029
a speech-recognition	0.003681
publications	0.000029
perspective so	0.250000
for Friday	0.010830
's results	0.019608
compared a	0.142857
translation methodologies	0.013514
, thus	0.001123
entropy-based summarization	1.000000
Stilstudien -LRB-	1.000000
noun ''	0.071429
the keyphrases	0.001384
distinction ,	0.200000
the bridging	0.000692
multiple documents	0.153846
native	0.000116
compared -	0.142857
compared .	0.285714
a reliance	0.001227
entities -LRB-	0.142857
custom speech	0.500000
systems typically	0.008929
using natural	0.016949
that perform	0.003546
counter	0.000029
a camera	0.001227
element	0.000029
color images	1.000000
Semantic Orientation	0.333333
to deal	0.001328
Such models	0.250000
, Hafiz	0.000561
move	0.000029
`` Japanese	0.005291
would identify	0.018868
their routing	0.029412
Recall can	0.333333
even larger	0.037037
continue to	1.000000
chosen	0.000145
The phenomenon	0.005208
degrees	0.000058
2011	0.000058
2010	0.000087
2012	0.000029
by receivers	0.005714
never be	0.400000
tune the	1.000000
both use	0.032258
games ,	1.000000
random walks	0.285714
subset	0.000087
continued more	0.111111
between lexical	0.051282
Noise	0.000029
Early versions	0.500000
questions or	0.038462
the dictator	0.000692
approaches emphasize	0.035714
this right	0.010989
, statistics	0.001123
word processing	0.016667
adjectives ,	0.333333
often under	0.022727
highly-specialized natural	1.000000
to How	0.001328
and recognition	0.001445
bills returned	1.000000
concepts between	0.200000
for personal	0.003610
HLDA -RRB-	1.000000
like syntax	0.035714
If ``	0.100000
e-communities	0.000058
Summarizers -LRB-	1.000000
speakers were	0.250000
have already	0.009615
rules ATNs	0.023256
and mapping	0.001445
vocabulary sizes	0.125000
as conveniently	0.003484
system	0.002692
tagging was	0.080000
Labov ,	1.000000
speech designed	0.006579
in medical	0.001873
linear combination	0.142857
represent .	0.222222
-RRB- Interactional	0.002817
issued to	1.000000
To upgrade	0.111111
a rapidly	0.001227
linear algebra	0.142857
scanning applications	0.500000
<s> You	0.000769
Scansoft	0.000029
Understanding Conferences	0.500000
collecting	0.000029
tokens -LRB-	0.142857
manner rather	0.250000
<s> Hulth	0.002306
text units	0.018868
would consist	0.018868
is like	0.004065
grammar-based	0.000029
applications Robotics	0.040000
the acoustic	0.000692
accuracy	0.000897
abbreviations that	0.200000
book on	0.125000
delayed	0.000029
is speaking	0.002033
It stands	0.026316
segment	0.000261
target-language-independent representation	1.000000
, Type	0.000561
published at	0.142857
mechanical	0.000029
grammars that	0.071429
fact	0.000318
dataset -RRB-	1.000000
President Biden	0.250000
semantic interpretation	0.047619
and placement	0.001445
decade	0.000087
similarity of	0.100000
should	0.000550
predicted pollen	0.500000
is measured	0.006098
the ones	0.001384
available for	0.117647
representations are	0.250000
means	0.000174
, improving	0.000561
LREC Granada	1.000000
same words	0.040000
Once	0.000145
Because	0.000058
embedded	0.000116
<s> Neural	0.001537
scanned images	0.333333
the hypothesis	0.000692
which structured	0.007246
as Maximal	0.003484
emotional effect	0.250000
corpus -RRB-	0.129032
pointed out	1.000000
the eigenvector	0.000692
speech caused	0.006579
weapon release	0.500000
Spitzer	0.000029
not rare	0.008929
using all	0.016949
parse computationally	0.111111
project ongoing	0.076923
ends	0.000058
Jay Lemke	1.000000
into text	0.038462
The final	0.005208
better translations	0.111111
expect ;	0.333333
extremes ,	1.000000
pragmatics	0.000087
-RRB- with	0.008451
Vauquois	0.000029
in USA	0.001873
and print	0.001445
data ,	0.129870
, Klavans	0.000561
Note also	0.111111
'' aimed	0.005376
million word	0.333333
launched the	1.000000
individual unigrams	0.083333
denote an	0.500000
step is	0.066667
everyday life	1.000000
Intelligent ''	0.333333
systems usually	0.017857
retrieval module	0.142857
Neural networks	0.750000
more like	0.010526
: task-based	0.009804
JAS-39	0.000029
by decomposing	0.005714
corpora are	0.181818
summarization exactly	0.020000
parser are	0.062500
still used	0.066667
Text Segmentation	0.166667
other applications	0.014286
-RRB- ''	0.005634
<s> ...	0.000769
similar ``	0.037037
been a	0.029412
recognizers into	0.500000
keyword matching	1.000000
theory it	0.076923
site	0.000058
theory in	0.076923
<s> Formal	0.000769
the CKY	0.000692
to automatically	0.007968
scale -RRB-	0.166667
generate some	0.055556
When used	0.142857
Wordnet lexicon	1.000000
A possible	0.020000
Typical stages	0.500000
displayed on-line	0.500000
Research and	0.125000
from its	0.009615
letter that	0.166667
Carmen	0.000029
the speech-enabled	0.000692
sentiment based	0.040000
ask the	0.500000
Shipibo	0.000058
images environment	0.166667
inflected languages	1.000000
users .	0.222222
A. van	0.200000
rooms	0.000029
vocabularies ,	1.000000
Company	0.000058
Dictionary-based Main	0.500000
Rabiner can	1.000000
produce ,	0.045455
Content determination	1.000000
Hollenbach 1970	1.000000
corpus to	0.032258
Rose ,	1.000000
these words	0.047619
government	0.000087
checking	0.000029
could do	0.062500
conjunction ,	0.333333
like to	0.071429
and stochastic	0.001445
Extraction Algorithm	0.333333
learned model	0.200000
produce a	0.136364
summarization approaches	0.020000
as words	0.003484
to consult	0.001328
Eugene	0.000029
, to	0.007299
summaries qualitatively	0.023256
grammatical gender	0.090909
as voicemail	0.003484
English :	0.027027
segment and	0.111111
selecting	0.000145
and produce	0.002890
at Yale	0.029412
'' occurs	0.005376
Computational Linguistics	1.000000
if we	0.071429
English .	0.135135
vs.	0.000347
production and	0.333333
Because progress	0.500000
is relevant	0.002033
whether a	0.153846
software	0.000782
assess	0.000087
also that	0.014493
information databases	0.021739
Ray Kurzweil	1.000000
for verification	0.003610
became an	0.200000
reporting on	0.333333
'' -LRB-	0.048387
Martin presents	0.500000
has interest	0.011905
do all	0.038462
objective evaluation	0.200000
-LRB- arguably	0.002710
compute	0.000058
inter-annotator	0.000029
has improved	0.011905
signed language	1.000000
QA systems	0.285714
notable early	1.000000
Search to	0.500000
the vocabulary	0.000692
distribution	0.000116
and copying	0.001445
Unsupervised taggers	0.166667
agree on	0.333333
the letters	0.000692
contribute	0.000029
<s> human	0.000769
converting the	0.500000
be checked	0.004219
ink	0.000029
as often	0.003484
human judges	0.043478
biographical questions	1.000000
characterized by	0.500000
lookup	0.000029
schemes frequently	0.500000
that ``	0.021277
are summaries	0.004149
specific objects	0.047619
be effective	0.008439
<s> TextRank	0.002306
to them	0.002656
To find	0.111111
Longacre	0.000058
spaces or	0.200000
lessons learned	1.000000
spaces of	0.200000
with Nuance	0.005464
voice applications	0.076923
humans to	0.083333
simply by	0.083333
most significant	0.017241
produce numeric	0.045455
controversial	0.000029
is accomplished	0.002033
controllers Training	0.333333
evaluation programs	0.018519
all the	0.139535
various boolean	0.055556
use heteroscedastic	0.013889
which usually	0.007246
analysis was	0.030769
tagging	0.000724
development ,	0.166667
Morpheme Analysis	1.000000
especially useful	0.066667
<s> Ensemble	0.000769
of faster	0.000891
by silence	0.005714
been automatic	0.014706
source and	0.041667
Claude	0.000029
for training	0.010830
floods ''	1.000000
approximation	0.000174
Most of	0.500000
threshold to	0.250000
B ,	1.000000
thus reducing	0.100000
blue ''	1.000000
the DUC	0.000692
well a	0.035714
continuous similarity	0.166667
memorandum ``	1.000000
accepts some	0.500000
alone --	0.250000
data available	0.038961
advantage that	0.200000
components -RRB-	0.200000
of integration	0.000891
, modern	0.000561
Machinery	0.000029
did Joe	0.200000
whether ``	0.076923
well .	0.071429
well ,	0.035714
eyes-busy environment	1.000000
items	0.000058
and Roger	0.001445
the National	0.001384
browsing	0.000029
Penicillin	0.000029
at an	0.014706
an article	0.015152
disappear .	1.000000
highly	0.000261
opinion in	0.400000
tagger proceeds	0.111111
with reference	0.005464
total	0.000058
recognition As	0.008264
is commercially	0.002033
taggers The	0.142857
negative	0.000232
that handles	0.003546
foster	0.000029
, addressed	0.000561
and early	0.001445
not present	0.026786
Australia .	1.000000
a patent	0.002454
in document	0.003745
the preceding	0.000692
generate weather	0.055556
feasibility demonstration	0.500000
and derive	0.001445
European group	0.333333
theories	0.000145
<s> Psycholinguists	0.000769
HMM parameter	0.333333
Brill tagger	0.333333
validated	0.000029
explicit by	0.200000
verify	0.000029
coined the	1.000000
BASEBALL answered	0.500000
when necessary	0.028571
beach	0.000029
containing the	0.375000
coined	0.000029
after	0.000347
<s> Intrinsic	0.001537
of researchers	0.000891
services .	0.666667
services ,	0.333333
or match	0.004505
processed ,	0.166667
transform -RRB-	0.200000
accommodate left	0.200000
Koine Greek	1.000000
Judith M.	1.000000
south	0.000058
quality can	0.100000
differences in	0.333333
clues are	0.333333
at Stanford	0.014706
diverse set	0.500000
recognition-related project	1.000000
evaluate the	0.500000
key theorists	0.166667
speech into	0.013158
nets	0.000029
adjacent instances	0.166667
versus	0.000029
of product	0.000891
pertaining to	1.000000
generators of	0.500000
ambiguous English	0.083333
, Strzalkowski	0.000561
patent for	0.250000
Analysis	0.000145
likely source	0.062500
standard can	0.071429
bank	0.000029
based ,	0.037037
rocks	0.000029
Adriana Bolivar	1.000000
schemes	0.000058
using online	0.016949
to school-age	0.001328
Cuzco area	1.000000
in healthcare	0.001873
of life	0.000891
coefficients and	0.250000
+ R	0.166667
so phonemes	0.033333
but has	0.014706
medicine	0.000029
lies a	0.500000
to rewrite	0.001328
Deaf or	1.000000
where semantics	0.028571
sentences when	0.013158
Chomskyan theories	1.000000
, PangeaMT	0.000561
+ ,	0.333333
difference is	0.250000
standard	0.000405
campaigns	0.000058
the choices	0.000692
BORIS	0.000029
created	0.000203
boundaries in	0.090909
10msec	0.000058
creates	0.000058
builds a	0.500000
+5	0.000029
+4	0.000029
of aircraft	0.000891
between `	0.025641
a purely	0.001227
method for	0.125000
and discuss	0.001445
reduction ,	0.500000
trained automatically	0.333333
is positive	0.002033
hand-printed text	0.500000
template-matching OCR	1.000000
into machine-encoded	0.012821
generalizes as	1.000000
limited type	0.100000
perception of	0.500000
trivial due	0.250000
van Leeuwen	0.500000
on bilingual	0.004717
document gives	0.027778
trees using	0.166667
only the	0.105263
and parsing	0.001445
sold his	0.333333
Gene	0.000029
possibilities but	0.200000
Text-proofing Natural	1.000000
many others	0.019231
or discourse	0.009009
embedded system	0.250000
reverse -RRB-	0.500000
now absorbing	0.076923
normalization and	0.166667
of our	0.000891
disambiguation	0.000290
in recent	0.003745
<s> Document	0.001537
phenomenon is	0.200000
the machine	0.000692
a criterion	0.001227
other hand	0.071429
realm	0.000029
Vietnamese ,	1.000000
latter	0.000029
reported was	0.200000
easily copied	0.111111
corresponded to	1.000000
or knowledge	0.004505
the top	0.002768
Computers	0.000029
wave from	0.111111
exercises	0.000029
and previously-written	0.001445
Dynamic	0.000145
Haton -LRB-	1.000000
six numbers	0.500000
more -RRB-	0.010526
, intelligent	0.000561
similar sentences	0.111111
use directly	0.013889
calculates	0.000029
shallow approaches	0.166667
<s> HMMs	0.002306
most fonts	0.017241
to answer	0.003984
tagging will	0.040000
about as	0.025000
Computer Products	0.333333
HMM based	0.333333
However even	0.027027
keywords	0.000058
co-occur	0.000058
representations of	0.250000
positions as	1.000000
European	0.000087
summary ''	0.047619
Dec.	0.000029
are clearly	0.004149
which items	0.007246
properties and	0.250000
is some	0.002033
implementation	0.000058
others have	0.083333
polynomial-size	0.000029
in evaluation	0.001873
`` eat	0.005291
two ways	0.034483
writing style	0.111111
many are	0.019231
vowels	0.000087
carried on	0.500000
C. ,	1.000000
deep systems	0.142857
idioms	0.000058
summary 's	0.047619
a knowledge	0.001227
by part	0.005714
spoken languages	0.142857
of navigation	0.000891
equivalent to	0.200000
slow and	0.500000
person may	0.052632
unable	0.000058
draft is	0.500000
already discussed	0.200000
Chinese have	0.142857
ARRA -RRB-	1.000000
simple English	0.038462
to automated	0.001328
we	0.001303
vs. preposition	0.083333
words as	0.009174
strong correlation	0.250000
journal article	0.333333
Unfortunately ,	1.000000
complex sound	0.125000
dialogues	0.000029
are further	0.004149
been opinionated	0.014706
the JAS-39	0.000692
of guessing	0.000891
each of	0.111111
Mouffe ,	1.000000
Battle	0.000058
basic sound	0.153846
Understudy	0.000058
uttered ;	0.333333
Patent 2,026,329	0.333333
Harris The	0.111111
1993 .	0.333333
TextRank was	0.142857
researchers need	0.100000
trigrams ,	0.500000
an NLP	0.022727
classes :	0.200000
Often used	0.333333
sentence boundaries	0.083333
as :	0.003484
an NLG	0.007576
keyphrases and	0.028571
applied	0.000434
corpus such	0.032258
the algorithms	0.001384
publicly	0.000029
-LRB- orange	0.002710
air	0.000145
aim	0.000058
forecasts .	0.200000
Invoice	0.000029
applies	0.000203
citations to	0.666667
a preposition	0.001227
, video	0.001123
launched	0.000029
produce keyphrases	0.045455
gap between	1.000000
Pallet	0.000058
Virtually	0.000029
perform	0.000318
a person\/persons	0.001227
analysis depends	0.015385
readers processed	0.500000
are pulled	0.004149
and for	0.001445
incorrectly	0.000029
to explicitly	0.002656
of personalised	0.000891
statistical distribution	0.030303
form the	0.050000
methods based	0.022727
Institute	0.000029
posed	0.000087
in spite	0.001873
e.g. who	0.017857
the course	0.000692
done with	0.181818
closely associate	0.200000
model information	0.033333
the exception	0.000692
measure for	0.090909
were based	0.024390
comes from	0.400000
unified	0.000029
intervals like	1.000000
Science Research	0.500000
to another	0.003984
closed-domain might	1.000000
Recognize if	1.000000
constraint ,	1.000000
for test	0.003610
things .	0.333333
for translation	0.003610
overall speech	0.166667
results over	0.047619
belongs	0.000029
new scientific	0.041667
progressed	0.000029
the phrases	0.000692
recent book	0.125000
rate is	0.181818
morphemes	0.000087
distinct ideas	0.142857
clear .	0.250000
of analysis	0.000891
parametric values	1.000000
three basic	0.333333
Cohesion and	1.000000
me the	1.000000
news-gathering ,	1.000000
entities often	0.142857
web may	0.125000
Then ,	0.400000
Task description	0.333333
allows a	0.125000
WebOCR also	0.250000
worked out	0.200000
into English	0.025641
1946 by	1.000000
ambiguity of	0.125000
and algorithms	0.001445
summarization faces	0.020000
Further	0.000087
or left-to-right	0.004505
post	0.000029
For this	0.049180
takes	0.000087
-LRB- correct	0.002710
essentially two	0.125000
reported accuracy	0.200000
accepts	0.000058
within a	0.277778
local '	0.333333
graph -RRB-	0.076923
: Many	0.009804
the values	0.000692
stemming -RRB-	0.500000
French and	0.250000
are surprisingly	0.004149
Hard of	0.500000
associating a	1.000000
equivalent information	0.200000
be declared	0.004219
'' or	0.026882
or five	0.004505
was influenced	0.012987
HMMs are	0.250000
class they	0.250000
way	0.000695
not its	0.008929
was	0.002229
war	0.000029
something	0.000029
becoming	0.000029
converse	0.000029
Customized	0.000029
true	0.000058
meaning ``	0.043478
high-quality	0.000029
can determine	0.011050
prone to	1.000000
between dynamically	0.025641
a nice	0.002454
computing	0.000058
inferior results	1.000000
the opinions	0.000692
on-line ,	0.333333
projection followed	1.000000
Edmund Fournier	1.000000
`` good	0.005291
Multimodal interaction	1.000000
Margaret Wetherell	1.000000
labeled data	0.333333
extensive lexicons	0.333333
of part-of-speech	0.001783
Jonathan Potter	1.000000
degree of	0.500000
network -LRB-	0.166667
standard table	0.071429
with Fourier	0.005464
many other	0.096154
Winograd finished	0.333333
symbol .	0.500000
usually involves	0.031250
common to	0.040000
that making	0.003546
tried .	0.333333
tried ,	0.333333
trigram	0.000087
trivial -RRB-	0.250000
VRX and	1.000000
Sept.	0.000029
contains all	0.100000
Importance	0.000029
for specific	0.003610
an embedded	0.007576
compensate	0.000029
by any	0.005714
division	0.000058
rarely have	0.333333
individual phones	0.083333
segmentation and	0.060606
'' set	0.005376
entries	0.000058
smoothly with	0.500000
Just	0.000029
were published	0.024390
<s> Application-Oriented	0.000769
paraphrases -LRB-	1.000000
Duchess	0.000029
discrete	0.000087
generated texts	0.066667
phrases with	0.062500
possible on	0.041667
: setting	0.009804
when reading	0.028571
to include	0.009296
to determine	0.014608
in system	0.001873
indiscriminate .	1.000000
task remains	0.023810
appear	0.000463
: statistical	0.009804
simplified form	0.500000
machine-learning systems	0.250000
terms that	0.076923
multimedia documents	0.500000
based recognition	0.018519
sequential	0.000029
D.S.	0.000029
Imagine	0.000029
time-consuming	0.000087
problems colloquially	0.117647
<s> Prominent	0.000769
especially interested	0.066667
natural speech	0.026667
account how	0.333333
great deal	0.333333
been written	0.014706
usually	0.000926
application to	0.071429
Morphological segmentation	1.000000
subjectivity	0.000058
apparent from	1.000000
prove	0.000029
, along	0.000561
least one	0.200000
produce consonants	0.045455
of sentences	0.006239
measure one	0.090909
became part	0.200000
selects	0.000058
first ,	0.030303
entity about	0.200000
first .	0.030303
case that	0.058824
F	0.000029
automated technologies	0.142857
electronic conversion	0.500000
Automated essay	0.500000
organizations	0.000029
graphic	0.000029
with questions	0.010929
extraction or	0.032258
<s> Extraction	0.001537
machine learning	0.240506
, MySpace	0.000561
in part	0.001873
can	0.005240
, understanding	0.000561
War II	1.000000
extraction of	0.096774
Rosa Caldas-Coulthard	1.000000
attribute	0.000058
derivations of	1.000000
95 %	1.000000
1980s	0.000261
heard	0.000029
thanks to	1.000000
to converse	0.001328
sounds it	0.066667
redundancy	0.000087
from a	0.115385
uses cosine	0.071429
Gail	0.000029
construct an	0.333333
trigrams	0.000058
dominance	0.000029
understanding involves	0.030303
normalization -LRB-	0.166667
Black E.	0.500000
representations .	0.250000
Widdowson	0.000029
Wodak ,	1.000000
Langues	0.000029
, Digital	0.000561
-RRB- as	0.008451
Grammatical dependency	1.000000
-RRB- at	0.002817
from ,	0.009615
usually be	0.031250
and VOLSUNGA	0.001445
the Advanced	0.000692
-RRB- an	0.002817
accordingly .	1.000000
rates on	0.125000
machine-translation approaches	0.500000
an internal	0.022727
rates of	0.375000
different speaker	0.020408
sentences at	0.013158
statistical	0.000955
be able	0.021097
of converting	0.001783
Willig ,	1.000000
: extraction	0.009804
-LRB- May	0.005420
of DA	0.000891
fields such	0.166667
Although Harris	0.125000
NLP problems	0.042553
forms	0.000174
is Shift-Reduce	0.002033
earliest such	0.500000
gives less	0.500000
the industry	0.000692
these good	0.023810
elements from	0.250000
to automate	0.002656
from IBM	0.009615
1955	0.000058
1954	0.000087
1957	0.000029
1956	0.000029
1950	0.000058
1953	0.000029
1952	0.000058
P +	0.500000
P ,	0.500000
statement ,	1.000000
introducing models	1.000000
Parsers	0.000058
full-text	0.000029
domain	0.000579
analyses to	0.200000
visible Markov	0.333333
house through	0.500000
Peru	0.000058
happen	0.000029
on neat	0.004717
internal semantic	0.200000
algorithms that	0.057143
advances in	1.000000
, Emanuel	0.001123
looking	0.000145
an application	0.015152
suffix ''	1.000000
to HMMs	0.001328
unambiguous	0.000058
including ,	0.071429
on both	0.004717
the methods	0.000692
inputting	0.000029
throughout a	1.000000
card	0.000116
Duchess was	1.000000
important example	0.062500
form filling	0.050000
has thousands	0.011905
way is	0.041667
capitalized .	0.333333
directly	0.000145
capitalized ,	0.666667
message	0.000058
also concluded	0.014493
the mechanism	0.000692
checked	0.000058
Separate	0.000058
himself translated	0.500000
determine if	0.217391
Speaker Dependence	0.166667
including mobile	0.071429
vowel in	1.000000
Human Summarization	0.200000
a damping	0.001227
context-free grammars	0.363636
practical dimensions	0.500000
150 separate	0.500000
Starting in	1.000000
Handbook chapter	1.000000
and efficient	0.002890
of meaningful	0.000891
Pointwise	0.000029
Auto plant	1.000000
could understand	0.062500
surprising popularity	1.000000
rank ``	0.166667
require rapid	0.045455
and\/or producing	0.333333
row ,	1.000000
to focus	0.001328
would never	0.018868
Microsoft Voice	0.500000
book Language	0.125000
may dismiss	0.019231
setting ,	0.400000
the same	0.015225
distorted	0.000058
tested the	0.500000
In particular	0.028571
, decimal	0.000561
recognition algorithms	0.008264
fancy statistics	1.000000
of case-based	0.000891
concatenated	0.000029
researchers found	0.100000
<s> Algorithms	0.001537
convey meaning	0.333333
words involved	0.009174
, Svenka	0.000561
As with	0.055556
Speereo	0.000058
such template-matching	0.008130
skew ,	1.000000
successive	0.000058
, Aletta	0.000561
Goldberg	0.000058
typically	0.000521
crossed below	1.000000
is intended	0.004065
of key	0.000891
curves ,	1.000000
depend on	1.000000
on pilot	0.004717
what we	0.093750
upgrade	0.000029
can benefit	0.011050
Accuracy of	0.428571
only	0.001100
Inuit	0.000029
many more	0.019231
to contain	0.001328
texts and	0.058824
considerable commercial	0.200000
card imprints	0.250000
is considered	0.004065
-LRB- orally	0.002710
the key	0.000692
<s> Dynamic	0.002306
between automatically	0.025641
computer-understandable	0.000029
about a	0.025000
Beaugrande ,	1.000000
summaries .	0.139535
summaries ,	0.069767
or fade	0.004505
: complicated	0.009804
Arbor	0.000029
necessarily portable	0.500000
last decade	0.400000
<s> Commercial	0.001537
on some	0.042453
: Manual	0.009804
as individual	0.003484
microphone .	1.000000
identity of	1.000000
evaluation campaign	0.018519
evaluate an	0.250000
languages tend	0.020000
as keyphrases	0.003484
a name	0.002454
some systems	0.024096
an interactive	0.007576
perceptions	0.000029
pertain	0.000029
, candidacies	0.000561
of using	0.000891
enabling	0.000029
therefore help	0.200000
and achieved	0.001445
were similar	0.024390
into standard	0.012821
proved	0.000087
<s> Modern	0.000769
tagging ,	0.080000
tagging .	0.080000
and form	0.001445
tagging :	0.040000
essentially perfectly	0.125000
Schools	0.000029
linguistic	0.000463
a subtopic	0.001227
some but	0.012048
but instead	0.014706
be trained	0.004219
information and	0.021739
Kenneth Lee	1.000000
e.g. Known	0.017857
listens for	1.000000
differing contexts	1.000000
these	0.001216
as corresponding	0.003484
utterance can	0.333333
above all	0.076923
last example	0.200000
too similar	0.166667
remains the	0.250000
= masculine	0.111111
formalization .	0.500000
Envelopes	0.000029
Speech ''	0.032258
Noun ,	1.000000
standards are	0.200000
keyboard a	0.333333
automatic summarization	0.086957
larger text	0.062500
's dissertation	0.019608
or structures	0.004505
MEAD	0.000029
breaks exist	0.500000
closest	0.000058
n-dimensional	0.000029
Kurzweil Applied	0.142857
of over	0.000891
template-matching	0.000029
depending what	0.250000
keyboard .	0.333333
terminology ,	1.000000
optimizes parameters	1.000000
or custom	0.004505
inspired the	1.000000
severe	0.000029
communicative goal	0.666667
the POS	0.002076
<s> Every	0.000769
transmitting	0.000029
valuable	0.000058
A direct	0.020000
of Latin-script	0.000891
give a	0.250000
`` Computational	0.005291
uttered	0.000087
of units	0.000891
Nuance	0.000087
; Speech	0.021277
Compute features	1.000000
other .	0.028571
-RRB- Acoustical	0.002817
, psycholinguistics	0.000561
The main	0.015625
are useful	0.004149
quoted in	1.000000
favor accuracy	0.500000
complicated because	0.333333
ambitious	0.000029
the inter-word	0.000692
Unsupervised	0.000174
rules	0.001245
, current	0.000561
large corpus	0.043478
Project	0.000029
unveiled during	1.000000
listening	0.000029
-LRB- in	0.005420
on lower	0.004717
us to	0.500000
have higher	0.009615
Science ,	0.500000
Marc	0.000029
criteria and	0.250000
hand it	0.071429
Mars	0.000058
e.g. Syntactic	0.017857
Military High-performance	1.000000
and linear	0.001445
, but	0.026951
a feasibility	0.001227
Tokens	0.000029
project -LRB-	0.076923
It refers	0.026316
limited application	0.100000
statistical NLP	0.060606
the sentence	0.004152
tool .	0.500000
equivalent	0.000145
news conference	0.076923
supervised	0.000463
of assembling	0.000891
use vocal	0.013889
inclusion	0.000029
open problem	0.250000
ambiguities one	0.250000
electronically searched	1.000000
, Zellig	0.001123
MMI -RRB-	1.000000
removing	0.000058
Goldberg continued	0.500000
generic summaries	0.333333
low	0.000087
lot	0.000087
also considerable	0.014493
Speech is	0.064516
-LRB- greater	0.002710
asking why	0.500000
input feature	0.024390
with payments	0.005464
and Unsupervised	0.001445
copied	0.000058
<s> Isolated	0.000769
quantitatively	0.000029
by Piron	0.005714
In these	0.009524
that act	0.003546
unable to	1.000000
star ratings	0.500000
reliability	0.000058
History Some	0.500000
keyphrase extractor	0.052632
the source	0.008304
United Nations	0.222222
sound on	0.050000
deploy machine	1.000000
processed incorrectly	0.166667
terms of	0.538462
e.g. WordNet	0.017857
open-ended	0.000029
computerized	0.000058
OnStar ,	1.000000
peak	0.000029
distinguishes two	0.500000
are examples	0.012448
is provided	0.002033
corpus for	0.032258
Loriot	0.000029
1930s	0.000029
the Wordnet	0.000692
people speaking	0.125000
, often	0.001684
boundaries and	0.090909
allows the	0.375000
proper syntax	0.142857
a pre-structured	0.001227
task requires	0.023810
with little	0.005464
When punctuation	0.142857
Contrary to	1.000000
--	0.000724
control of	0.600000
case with	0.058824
-5	0.000029
any pauses	0.032258
The Unicode	0.005208
; Amplitude	0.021277
even so	0.037037
learner .	0.500000
a psychologist	0.001227
mobile processor	0.500000
typewritten or	0.200000
and very	0.001445
the delta	0.000692
widely-reported	0.000029
Animate =	1.000000
at SRI	0.014706
of nouns	0.000891
adaptive summarization	0.666667
are arranged	0.004149
is using	0.004065
printed documents	0.083333
interpretation capabilities	0.500000
effort has	0.250000
diversity ''	0.250000
at all	0.073529
or future	0.004505
large portion	0.043478
OnlineOCR	0.000087
usage is	1.000000
, -RRB-	0.000561
transform of	0.200000
aimed	0.000058
'' of	0.005376
or English	0.004505
probabilities	0.000318
contains	0.000290
identical to	1.000000
3 +4	0.200000
LOB	0.000058
machine-translation research	0.500000
specified in	1.000000
taken	0.000087
, such	0.019652
they require	0.050000
system .	0.118280
system ,	0.107527
metrics .	0.111111
metrics ,	0.111111
scoring Truecasing	0.500000
metrics :	0.111111
the first	0.010381
following issues	0.066667
`` sad	0.005291
30 %	0.333333
the meeting	0.000692
` conceptual	0.062500
An extrinsic	0.062500
= Human	0.111111
history	0.000116
entropy -LRB-	0.200000
detailed discussions	0.500000
The sailor	0.005208
, false	0.000561
Federation	0.000029
thereof -RRB-	1.000000
thousands of	0.666667
different output	0.020408
the sounds	0.001384
and Jabberwacky	0.001445
are systems	0.012448
given an	0.041667
is available	0.002033
orange in	1.000000
which simply	0.007246
portion of	1.000000
<s> Are	0.000769
has continued	0.011905
Another possible	0.076923
negligibly	0.000029
ISO\/TC37 and	1.000000
likelihood for	0.333333
`` tag	0.010582
first statistical	0.060606
explicit formalization	0.200000
help	0.000261
hierarchy	0.000058
soon	0.000087
held	0.000029
when such	0.057143
, within	0.000561
With continuous	0.142857
still translates	0.066667
English-like	0.000087
speaker recognition	0.055556
the impact	0.001384
they still	0.025000
from our	0.009615
languages can	0.040000
a window	0.001227
are beginning	0.004149
, both	0.001684
develop dedicated	0.200000
questioned the	1.000000
extraction ,	0.193548
even with	0.037037
Hopper ,	1.000000
east .	1.000000
context The	0.060606
are widely	0.004149
numbers that	0.142857
For other	0.016393
Recognition is	0.125000
the NLP	0.000692
is importance	0.002033
, impressive	0.000561
created based	0.142857
publish	0.000029
issue	0.000232
for terms	0.003610
plain text	1.000000
useful summary	0.071429
learner ,	0.500000
, rarity	0.000561
and gets	0.001445
reason	0.000116
by DARPA	0.005714
be linked	0.008439
Junqua	0.000029
trigrams without	0.500000
subtypes of	1.000000
User Interface	0.500000
assign	0.000145
Marginal Relevance	1.000000
language input	0.020270
complexity of	0.666667
technology would	0.045455
seem to	0.500000
followed .	0.250000
the analysis	0.002768
we may	0.022222
answer the	0.033333
pour le	1.000000
selling	0.000029
, split	0.000561
merely assigning	0.500000
Tannen ,	1.000000
authors	0.000145
like ca	0.035714
have assessed	0.009615
Because ROUGE	0.500000
is substantial	0.002033
major design	0.083333
in trying	0.001873
lexical analysis	0.076923
divided into	0.666667
wife of	1.000000
not initially	0.008929
weapon	0.000058
hybrid approach	0.500000
, comprising	0.000561
fran√ßais .	1.000000
The progress	0.005208
forward-backward	0.000029
-LRB- free	0.002710
from spelling	0.009615
the random	0.000692
constructions	0.000029
, in	0.019090
, if	0.005615
small ,	0.222222
Lehrberger 1982	1.000000
, is	0.007299
In 1983	0.009524
In 1987	0.009524
, it	0.013476
letters or	0.100000
application domain	0.071429
the platform	0.000692
letters of	0.200000
Evaluating	0.000058
direction .	0.333333
stories on	1.000000
popularity	0.000029
USAF ,	1.000000
Asian language	1.000000
can not	0.082873
new utterance	0.041667
accuracies	0.000029
an enormous	0.007576
labeled as	0.333333
flood-control	0.000058
of just	0.000891
author when	0.333333
into sentences	0.012821
assertion	0.000029
classifiers	0.000058
his famous	0.083333
, degraded-images	0.000561
While	0.000145
otherwise achieves	0.500000
& lines	0.125000
same general	0.040000
the next	0.004152
QA More	0.047619
from single	0.009615
<s> Open-domain	0.000769
One such	0.076923
With sufficient	0.142857
particularly the	0.200000
Phillips .	1.000000
considered good	0.111111
Biden visit	0.333333
, sentence	0.000561
Code ,	1.000000
tagger on	0.111111
their suitability	0.029412
measures try	0.166667
the semantic	0.001384
conditions	0.000145
addressed the	0.500000
have difficulty	0.009615
closely tied	0.200000
lexical units	0.076923
these databases	0.023810
distinguish	0.000145
very different	0.073171
toward	0.000029
In this	0.047619
even more	0.037037
to by	0.002656
<s> Unsourced	0.000769
to HMM	0.001328
`` right	0.005291
model temporal	0.033333
to be	0.057105
is prone	0.002033
companies -LRB-	0.500000
describe developments	0.166667
Turkish	0.000029
or aspect	0.004505
recognition refers	0.008264
Consortium	0.000029
well their	0.035714
Online	0.000058
Was	0.000029
War	0.000029
do n't	0.076923
to allow	0.003984
generating	0.000145
or verify	0.004505
, topics	0.000561
for summarization	0.003610
ontology are	0.500000
-RRB- Some	0.002817
disruptive	0.000029
words that	0.009174
Statistical models	0.111111
assigning	0.000029
dialing	0.000029
Software	0.000058
look	0.000145
by applying	0.005714
the possibilities	0.000692
ISO\/TC37\/SC4 .	1.000000
answered about	0.200000
explicitly present	0.250000
get some	0.142857
the foreign	0.000692
as Turkish	0.003484
EARS	0.000029
demonstration was	0.200000
and strength	0.001445
reads	0.000058
syntactic parser	0.076923
entropy ,	0.200000
tried to	0.333333
subject ,	0.250000
subject .	0.250000
major database	0.083333
emoticons	0.000029
redundant sentences	1.000000
their estimated	0.029412
A machine	0.020000
system which	0.010753
`` prestige	0.005291
formulation The	1.000000
counts are	1.000000
as each	0.003484
e-communities through	0.500000
context can	0.030303
, notably	0.000561
other types	0.014286
the term	0.003460
to run	0.001328
as there	0.003484
of Ethnomethodology	0.000891
Sound waves	0.333333
Speech-to-text reporter	1.000000
be analyzed	0.004219
still disagree	0.066667
one more	0.015385
south east	1.000000
being a	0.111111
assumption ,	0.500000
Anthology .	1.000000
a professional	0.001227
syntax ,	0.454545
Internet	0.000058
annual Loebner	0.500000
but weaker	0.014706
phonemes with	0.166667
<s> Short	0.000769
man ''	1.000000
speech for	0.026316
people would	0.062500
simple parsing	0.038462
and data	0.005780
Advanced Research	0.200000
article verb	0.034483
to detect	0.001328
mathematical	0.000058
you '	0.076923
release or	0.333333
Annex on	1.000000
<s> Informally	0.000769
Named entity	1.000000
in solving	0.001873
subfields of	1.000000
judge is	0.250000
how useful	0.034483
99 %	1.000000
describing	0.000116
a relic	0.001227
large sets	0.086957
more times	0.010526
naturally spoken	0.500000
ten years	1.000000
his work	0.083333
of efforts	0.000891
they also	0.025000
constituents such	0.500000
Specifically ,	1.000000
language by	0.006757
is largely	0.002033
D ,	1.000000
select whole	0.166667
positive	0.000203
following example	0.133333
approaches and	0.035714
classes are	0.200000
within	0.000521
Decoding	0.000058
of errors	0.000891
Longacre ,	1.000000
Ruth	0.000029
is commonly	0.004065
characters from	0.062500
.5	0.000029
has included	0.011905
fulfill expectations	0.500000
algebra word	0.500000
-LRB- grammatical	0.002710
properly	0.000058
Online software	0.500000
answering have	0.083333
for various	0.003610
linguists decided	0.333333
intuitive	0.000029
model taggers	0.033333
Error Rates	0.500000
similar contexts	0.037037
availability of	1.000000
data table	0.012987
most successful	0.034483
100 million	0.333333
we construct	0.022222
polarity on	0.125000
tags ,	0.333333
The AT&T	0.005208
tags .	0.333333
commonly researched	0.125000
one year	0.015385
polarity of	0.250000
removal of	1.000000
- -RRB-	0.062500
; and	0.085106
closely related	0.400000
and the	0.059249
theory Conversation	0.076923
choice of	0.250000
accuracy for	0.064516
developed RSI	0.038462
Voice Input	0.200000
into general	0.012821
Supervised text	1.000000
-RRB- involved	0.002817
supervised methods	0.125000
Automatically	0.000029
improve .	0.076923
independently	0.000029
one place	0.015385
grammar -RRB-	0.081081
visual	0.000058
adverbs ,	1.000000
did cause	0.200000
and signing	0.001445
After training	0.333333
more difficult	0.073684
a bilingual	0.001227
evaluation of	0.074074
depending on	0.750000
is closer	0.002033
vertices\/unigrams	0.000029
doing as	0.500000
, though	0.003369
<s> Intra-texual	0.000769
Words	0.000116
function of	0.125000
spoken ,	0.142857
Example-based Main	0.333333
Around the	1.000000
are ranked	0.004149
the semantics	0.001384
Canadian	0.000058
any supervised	0.032258
modeling ,	0.142857
<s> Similarly	0.000769
characters rather	0.062500
LUNAR was	0.333333
complex endeavors	0.041667
geospatial	0.000029
summarization -RRB-	0.020000
beach ,	1.000000
Manual evaluation	0.666667
types of	0.857143
speech acts	0.019737
the burden	0.000692
of Hearing	0.000891
be studied	0.004219
measured can	0.166667
- A	0.062500
current text	0.142857
in operational	0.001873
`` 12	0.010582
perform as	0.090909
commercial	0.000318
<s> Adda	0.000769
knowledge comes	0.037037
perform an	0.090909
Japanese camp	0.125000
categorical .	1.000000
the previous	0.001384
database tables	0.100000
, creating	0.001123
serving a	1.000000
, modules	0.000561
when a	0.114286
since one	0.100000
utilize an	0.500000
words are	0.091743
be done	0.021097
example Wireless	0.012346
Speech Technology	0.032258
which involves	0.007246
statistical approach	0.030303
JSF	0.000029
Confusable Words	1.000000
remains	0.000116
the answer	0.009689
after going	0.083333
analysis ''	0.015385
long-time translator	1.000000
started	0.000116
summarization systems	0.100000
and computer	0.001445
necessary .	0.100000
time on	0.030303
studies and	0.250000
crossed	0.000029
2 descriptions	0.200000
time or	0.030303
successful systems	0.111111
consistent terminology	1.000000
It essentially	0.026316
is not	0.038618
is now	0.006098
large-scale content-analysis	1.000000
in reference	0.003745
might ask	0.038462
'' which	0.005376
-LRB- -LRB-	0.002710
to unsupervised	0.002656
AI than	0.333333
also refer	0.014493
many applications	0.038462
MySpace	0.000029
usually termed	0.031250
subjective information	0.333333
Politics	0.000029
quotations	0.000029
group at	0.250000
-LRB- 3	0.005420
-LRB- ,	0.002710
on simple	0.004717
common feature	0.040000
league over	1.000000
program is	0.045455
program in	0.090909
of Michigan	0.000891
Consultant -LRB-	1.000000
-LRB- k	0.002710
hands	0.000029
-LRB- c	0.002710
-LRB- b	0.002710
-LRB- a	0.013550
showing evidence	0.500000
the presentation	0.000692
titles and	0.500000
devices for	0.250000
warnings from	1.000000
Marginal	0.000029
Speereo Software	0.500000
-LRB- P	0.002710
evaluation criteria	0.037037
Why	0.000203
intermediary representation	0.666667
IR and	0.333333
lines ,	0.333333
-LRB- F	0.002710
Lehnert ,	0.666667
front-end	0.000029
to .	0.003984
to ,	0.002656
it could	0.008547
semiotics ,	1.000000
and decorrelating	0.001445
then characterized	0.028571
various combinations	0.055556
examples are	0.041667
to :	0.001328
<s> However	0.028440
to 7	0.003984
etc. ''	0.045455
Patent 1,915,993	0.333333
facts about	1.000000
Sensory ,	1.000000
represent analog	0.111111
covers tasks	0.250000
incorrect ones	0.333333
and address	0.001445
limit to	0.250000
and noise	0.001445
recommendations	0.000029
to a	0.037185
, Bobrow	0.000561
completely	0.000029
simple and	0.076923
legends	0.000029
' language	0.052632
1981	0.000029
attaching real-valued	1.000000
derivations	0.000058
to turn	0.001328
the large	0.000692
camp ''	0.250000
unsupervised keyphrase	0.125000
<s> Perspectives	0.000769
and extrinsic	0.001445
and determining	0.001445
Some attempts	0.047619
spelled `	1.000000
compiled newswire	1.000000
such formal	0.008130
, voice-activation	0.000561
and 1970s	0.001445
was attempted	0.012987
precisely	0.000029
using random	0.016949
management	0.000203
to English	0.001328
perfectly	0.000029
prone	0.000058
and example	0.001445
to explore	0.002656
conveniently as	1.000000
neural approaches	0.066667
the algorithm	0.000692
deals with	1.000000
on hand-crafted	0.004717
-RRB- languages	0.002817
a news	0.002454
its application	0.028571
e.g. echoes	0.017857
Recognition -LRB-	0.125000
Guzman	0.000029
parsed efficiently	0.250000
translating speech	0.250000
manual annotation	0.500000
POST -RRB-	1.000000
statistically-based	0.000029
depth ''	0.333333
is difficult	0.008130
broken English	0.200000
Jaworski	0.000029
query-biased summaries	1.000000
has meant	0.011905
harder 75	0.142857
though other	0.100000
non-textual	0.000029
lectures	0.000029
deploy	0.000029
this context	0.021978
-RRB- is	0.030986
-RRB- it	0.002817
- keyphrases	0.062500
-RRB- in	0.011268
Processor	0.000029
utterance ``	0.333333
derived meaning	0.166667
acoustics -RRB-	1.000000
precision because	0.200000
databases	0.000232
Christmas fall	1.000000
Medical Records	0.500000
tagging system	0.040000
accommodate various	0.200000
employs a	0.500000
editing	0.000058
based	0.001563
Turing test	0.500000
cultural factors	1.000000
bases	0.000029
data-to-text	0.000029
the boundaries	0.002076
l'assignation	0.000029
acoustic modeling	0.333333
testing for	0.200000
and Re-encoding	0.001445
early AI	0.200000
Popular	0.000029
internal organization	0.200000
Narrow	0.000029
procedures	0.000116
processes	0.000145
low-resolution ,	1.000000
topic or	0.125000
processed	0.000174
under construction	0.200000
topic of	0.125000
<s> Statistical	0.002306
Question	0.000203
considerable interest	0.200000
to measure	0.005312
statistically	0.000058
screen of	1.000000
models can	0.038462
; these	0.042553
to customize	0.002656
conjunction with	0.666667
be challenged	0.004219
rescoring	0.000029
comparable	0.000029
context have	0.030303
difference between	0.250000
this centroid	0.010989
minimal complexity	1.000000
transformed into	1.000000
vs. ``	0.166667
dedicated OCR	0.333333
Woods	0.000029
as could	0.003484
statistical natural	0.030303
The program	0.005208
that may	0.007092
-LRB- DA	0.005420
pasted ,	1.000000
space character	0.200000
slowly	0.000058
`` political	0.005291
those surrounding	0.045455
be approached	0.004219
with fixed	0.005464
corresponding	0.000174
of corpus	0.000891
seem completely	0.500000
article deal	0.034483
legal and	0.333333
cache language	1.000000
of interaction	0.000891
earlier term	0.250000
magazine 's	1.000000
on post-processing	0.004717
Ann	0.000029
recent developments	0.125000
air is	0.200000
can learn	0.005525
of retail	0.000891
was done	0.012987
phenomenon may	0.200000
descriptive and	0.333333
included analyses	0.125000
World ,	0.142857
capture	0.000058
been encouraging	0.014706
segments at	0.200000
generic	0.000087
and more	0.007225
Summarizers	0.000029
strength score	0.200000
, NLG	0.000561
with recognition	0.005464
APEXC	0.000029
user interfaces	0.142857
domains and	0.250000
transformational	0.000058
frequently	0.000058
way as	0.041667
well	0.000811
<s> That	0.002306
human would	0.021739
that alone	0.003546
more successful	0.031579
of optical	0.000891
verify the	1.000000
vertices .	0.222222
vertices ,	0.111111
SpeechTEK and	0.500000
barmaid	0.000174
uttered before	0.333333
vertices ?	0.111111
evaluation systems	0.018519
male-female	0.000029
software -LRB-	0.037037
Despite	0.000029
and bought	0.001445
NNS	0.000029
human-language	0.000029
formulaic	0.000029
immediately	0.000029
immunology	0.000029
these represent	0.023810
dictionaries	0.000029
initial sounds	0.333333
overt morphological	1.000000
'' implicate	0.005376
Svenka	0.000029
page	0.000203
, showing	0.000561
such features	0.008130
largest speech	1.000000
to humans	0.001328
less standardised	0.083333
Extract subjective	1.000000
them with	0.052632
a relaxed	0.001227
ends a	0.500000
received considerable	0.500000
are highly	0.004149
?	0.000695
inaccurate	0.000029
journal	0.000087
Other areas	0.142857
movie review	0.333333
stationary distribution	0.285714
multi-way	0.000029
OCR vendors	0.020408
their chosen	0.029412
a sensible	0.001227
qualities of	0.500000
<s> LL	0.001537
Many machine	0.083333
<s> LR	0.000769
represented using	0.166667
been data-to-text	0.014706
synthesizer	0.000029
A feature	0.020000
in picture	0.001873
Jelinek F.	0.500000
expected to	0.285714
Workshop Hirschman	1.000000
i.e. requiring	0.052632
nodes for	0.142857
late 70s	0.111111
neutral	0.000058
goals	0.000029
eat	0.000029
spaces used	0.200000
it must	0.008547
Increasingly	0.000058
on pattern	0.004717
phrase ``	0.100000
decisions probabilistically	0.100000
The problems	0.005208
main ''	0.125000
Sentiment analysis	0.833333
stories	0.000029
converted them	0.333333
shallow-transfer machine	1.000000
to aid	0.001328
probability is	0.142857
transcription of	0.500000
'' systems	0.016129
by Kurzweil	0.005714
Norval ,	1.000000
Santorini gives	1.000000
tagging or	0.080000
Besides	0.000029
The FAA	0.005208
of candidates	0.000891
IBM and	0.333333
alternative courses	0.333333
of databases	0.000891
% -LRB-	0.076923
a co-occurrence	0.001227
voice recognition	0.076923
Due to	1.000000
evaluators .	1.000000
form words	0.050000
on speech	0.004717
is technology	0.002033
cross-discipline of	1.000000
ensure verifiability	1.000000
from Latin	0.009615
Spanish	0.000058
1,000,000 words	1.000000
the second	0.001384
techniques similar	0.043478
is then	0.010163
whose	0.000087
show the	1.000000
NLP system	0.085106
-LRB- at	0.002710
-LRB- as	0.018970
fine-grained	0.000029
receipts ,	1.000000
to analyze	0.001328
derivation -LRB-	0.500000
abbreviations ,	0.400000
abbreviations .	0.200000
1976 the	0.500000
Generation Challenges	0.500000
do we	0.038462
be his	0.004219
discourse analysis	0.222222
and length	0.001445
an in-depth	0.007576
wreck	0.000029
text as	0.006289
huge handmade	1.000000
Last level	1.000000
grammar -LRB-	0.027027
images .	0.166667
telephony is	0.333333
images ,	0.333333
desired answers	0.200000
Greene	0.000029
adjective 40	0.142857
of planning	0.000891
had mentioned	0.071429
determining whether	0.166667
dry	0.000029
high level	0.166667
ranging from	1.000000
has been	0.333333
He received	0.125000
same in	0.040000
credit	0.000087
the Puma	0.000692
Each level	0.166667
suitable	0.000116
-- between	0.040000
special fonts	0.200000
G. Lehnart	0.500000
human thought	0.021739
investigation performed	1.000000
Also	0.000087
describing a	0.250000
parts of	1.000000
, separate	0.001123
with each	0.005464
capture the	0.500000
logic oriented	0.250000
of mouse	0.000891
Gismo ''	0.500000
input -LRB-	0.048780
extracted summaries	1.000000
Algorithms which	0.500000
V	0.000029
present in	0.833333
Naomi Sager	1.000000
paste relevant	1.000000
is probably	0.002033
goals of	1.000000
it that	0.008547
processing Objectives	0.018519
, June	0.000561
ontology requires	0.500000
operations .	1.000000
, relative	0.000561
only into	0.026316
depended on	1.000000
are harder	0.004149
commonplace and	1.000000
transform -LRB-	0.200000
blogs and	0.500000
might not	0.076923
75 %	1.000000
president	0.000058
most sentiment	0.017241
attempt	0.000174
domains ASR	0.125000
various aspects	0.055556
Monroe	0.000029
term voice	0.055556
An automated	0.062500
formalisms are	0.500000
some training	0.012048
it would	0.034188
results may	0.047619
annotated -LRB-	0.500000
set ''	0.051282
' is	0.052632
Recall this	0.333333
maximal	0.000029
is digital	0.002033
light -RRB-	0.333333
the assistance	0.000692
products '	0.250000
therapy	0.000029
products .	0.250000
products ,	0.250000
to travel	0.001328
hearings -RRB-	1.000000
, Facebook	0.000561
quantities .	0.333333
their device	0.029412
side	0.000029
mean	0.000058
probability to	0.142857
help prevent	0.111111
a bill	0.001227
typology	0.000029
Poncini	0.000029
have a	0.125000
interim year	1.000000
crucial	0.000029
of words	0.013369
reader	0.000290
democratizing	0.000058
software and	0.037037
; a	0.021277
, D.	0.000561
who maintains	0.100000
ATC training	0.400000
overlap metrics	0.250000
which focused	0.007246
sentence structure	0.020833
; A	0.021277
100000	0.000029
which focuses	0.007246
to treat	0.001328
-RRB- have	0.005634
article ``	0.034483
likely following	0.062500
`` angry	0.005291
effectiveness of	0.333333
thereof	0.000029
very hard	0.024390
hand-produced	0.000029
sentiment .	0.040000
annotated	0.000058
conditions ;	0.200000
more common	0.010526
example text	0.012346
Press	0.000029
outputting	0.000058
HMM-based part	0.333333
and retrieving	0.001445
the initial	0.000692
many different	0.076923
Language Processing	0.250000
distance	0.000087
Consider	0.000058
structures	0.000145
provided by	0.400000
all where	0.023256
preparation	0.000029
enables	0.000029
extracting	0.000145
even lower	0.037037
discourse analysts	0.055556
papers on	0.666667
perhaps surprisingly	0.166667
modern	0.000145
mine	0.000029
Designing	0.000029
seen	0.000290
seem	0.000058
seek	0.000029
that performance	0.010638
virtually any	0.500000
read not	0.142857
automatically focus	0.047619
synopsis	0.000029
up to	0.227273
SpeechTEK Europe	0.500000
when the	0.114286
delayed until	1.000000
shared-task	0.000029
graph .	0.153846
US Veterans	0.142857
a novel	0.001227
translator	0.000203
regular	0.000029
Some of	0.190476
the concept	0.001384
categories -LRB-	0.111111
goal .	0.142857
must produce	0.071429
of Canada	0.001783
dog	0.000087
or dimensions	0.004505
we are	0.044444
pick the	1.000000
Unlike PageRank	1.000000
principle	0.000029
` hitcha	0.062500
to return	0.002656
consumer	0.000029
History The	0.500000
to medical	0.001328
modules ,	0.500000
syntax	0.000318
post-process	0.000029
, vehicle	0.000561
QA is	0.047619
or what	0.009009
exploits	0.000029
Shift-Reduce parsing	1.000000
you want	0.076923
see Tablet	0.050000
separate parts	0.100000
Searches	0.000029
States Air	0.142857
and replicated	0.001445
documents might	0.026316
guided by	1.000000
Dogged	0.000029
in parametric	0.001873
Overview	0.000058
architecture	0.000058
us with	0.500000
nautical term	0.500000
in e-communities	0.001873
other fields	0.014286
edges between	0.142857
decided	0.000087
assignment .	0.500000
last year	0.200000
distances represented	0.500000
subject	0.000232
`` hub	0.005291
issues relating	0.200000
classification for	0.117647
methods require	0.022727
Vocabulary is	0.333333
simplest	0.000029
glossary or	0.500000
another -RRB-	0.076923
triples	0.000087
An intrinsic	0.125000
resulted in	1.000000
on top	0.004717
the shift-reduce	0.000692
greater accuracy	0.333333
candidacies and	1.000000
compared phrase-structure	0.142857
disseminate	0.000029
against	0.000145
fairly non-trivial	0.250000
potential to	0.285714
very much	0.024390
Cognitive psychology	0.333333
built that	0.333333
parsing aims	0.035714
users sent	0.111111
21 taggers	1.000000
PDF to	1.000000
Robert Wilensky	0.250000
by different	0.005714
by multiplying	0.005714
mainly from	0.166667
the results	0.002768
Giro ,	1.000000
persuasion ,	1.000000
from Turney	0.009615
e.g. containing	0.017857
Gismo	0.000058
software vendors	0.037037
Language Input	0.083333
integrated part	0.333333
feasibility study	0.500000
`` President	0.005291
Martin ,	0.500000
, Perceptron	0.000561
duplicate or	0.500000
the types	0.001384
state -LRB-	0.071429
after Fourier	0.083333
Sacks ,	1.000000
Context-free	0.000029
, an	0.005615
power ,	0.250000
, at	0.001684
found in	0.214286
mouse	0.000029
often requires	0.022727
Georgetown	0.000087
Journal -RRB-	0.333333
others can	0.083333
make	0.000579
confusability Speaker	1.000000
filtered	0.000087
enterprise customers	1.000000
vibrates	0.000029
vocabulary of	0.125000
MMR -RRB-	1.000000
1970s ,	0.333333
differing	0.000058
kit	0.000058
Englund	0.000029
how the	0.034483
Results have	1.000000
as paraphrase	0.003484
questions under	0.038462
pulled directly	1.000000
not before	0.008929
complex matter	0.041667
importance .	0.166667
human	0.001332
-LRB- HLDA	0.002710
's tagger	0.019608
Rates Increase	1.000000
and similar	0.001445
P. ,	1.000000
character	0.000637
why he	0.285714
not Afghanistan	0.008929
the tagging	0.001384
reuse	0.000029
structure rules	0.083333
split into	0.500000
had an	0.071429
opportunity to	0.500000
were the	0.024390
Based on	1.000000
computer ,	0.022727
now called	0.076923
, probabilistic	0.001684
NC ''	1.000000
pragmatics of	0.333333
prisoners or	0.500000
In a	0.019048
in differing	0.001873
a situation	0.001227
the meaning	0.006920
learn such	0.076923
<s> Profile	0.000769
extensive research	0.333333
-RRB- represents	0.002817
7 across	0.428571
making more	0.142857
separate lexical	0.100000
meanings	0.000116
accumulation of	1.000000
known labeled	0.038462
encode in	1.000000
The Associated	0.005208
critics claim	1.000000
at MIT	0.029412
to read	0.001328
be evaluated	0.008439
terminology	0.000029
fran√ßais	0.000029
general use	0.045455
to accomplish	0.001328
technology that	0.045455
lectures ,	1.000000
correct .	0.200000
do .	0.038462
tokens like	0.142857
possibilities must	0.200000
any safety	0.032258
any condition	0.032258
task-based -LRB-	0.250000
of communication	0.001783
teletype	0.000029
of FoG	0.000891
automatically ,	0.047619
Keyphrases have	1.000000
step -RRB-	0.066667
increased and	0.200000
the meantime	0.000692
Interactive	0.000058
disassembling	0.000029
: TextRank	0.019608
based representation	0.018519
include contractions	0.037037
of surrounding	0.000891
span several	1.000000
apply statistical	0.200000
In 1629	0.009524
Lauriault\/Loriot	0.000058
between an	0.025641
more forms	0.010526
Bayes risk	0.333333
finite state	0.800000
the Turney	0.000692
are content	0.004149
Bolivar ,	1.000000
hoping to	1.000000
Gustav Tauschek	1.000000
retrieval and	0.285714
discriminate	0.000087
application requirements	0.071429
authoritative	0.000029
it enumerated	0.008547
given approach	0.083333
is presented	0.004065
first occurrence	0.030303
but such	0.014706
probabilistic division	0.142857
Sager ,	0.500000
automation Interactive	1.000000
to develop	0.006640
text illustrates	0.006289
standards require	0.200000
help speakers	0.111111
be ''	0.008439
school-age children	1.000000
<s> Tokens	0.000769
in massive	0.001873
with it	0.010929
a problem	0.003681
interest Topics	0.090909
involves several	0.100000
of January	0.000891
sounds ''	0.066667
segments -LRB-	0.200000
Sensory	0.000029
for voice	0.003610
depend	0.000087
continues to	1.000000
of charge	0.000891
, closed-domain	0.000561
a vocabulary	0.001227
High-order n-gram	1.000000
Japanese .	0.125000
further commercializing	0.125000
photographing data	1.000000
therefore to	0.200000
Japanese ,	0.125000
processing and	0.018519
by one	0.005714
its context	0.028571
a final	0.001227
programs ,	0.181818
programs .	0.272727
93-95 %	1.000000
item	0.000029
minimal	0.000029
to bootstrap	0.001328
patterns rather	0.200000
is sometimes	0.006098
Scotland with	0.200000
their framework	0.029412
and context	0.004335
only on	0.052632
Heritage	0.000029
an Australian	0.007576
the can	0.000692
Wilson ,	1.000000
during machine	0.100000
of rules	0.002674
a program	0.004908
or she	0.004505
unsupervised	0.000232
features ''	0.038462
a substantial	0.001227
passages to	0.500000
slow	0.000058
and atmosphere	0.001445
reader to	0.100000
Perceptron ,	1.000000
shift	0.000029
named entities	0.428571
step	0.000434
many NLP	0.019231
of similarity	0.000891
results of	0.047619
and Nelson	0.001445
best that	0.111111
conveniently	0.000029
Technology	0.000087
emotional communication	0.250000
in principle	0.001873
and encouraged	0.001445
action is	0.200000
understanding also	0.030303
` global	0.062500
with Japanese	0.005464
associated with	0.250000
-RRB- one	0.002817
finding non-existent	0.200000
compactly	0.000029
Critical Genre	0.500000
lessened	0.000029
previously prepared	0.500000
: Produce	0.009804
Giv√≥n	0.000029
On a	0.166667
purposes -LRB-	0.250000
seen an	0.200000
document\/text summarization	0.500000
reviews	0.000174
of Engineers	0.001783
seen as	0.300000
Lehrberger	0.000029
course ,	0.333333
confused	0.000058
in performance	0.001873
William Labov	0.500000
be obtained	0.004219
is obtained	0.002033
not require	0.008929
learn to	0.076923
various algorithms	0.055556
an extractive	0.007576
social psychology	0.071429
evaluating the	0.200000
significant semiotic	0.111111
combination and	0.200000
map	0.000058
subset of	1.000000
hand printing	0.071429
may	0.001505
Swales	0.000058
sentence such	0.020833
Yale	0.000058
script will	0.250000
, special	0.000561
man	0.000029
display format	0.500000
follows that	0.500000
silence	0.000029
-RRB- measure	0.002817
talk	0.000029
to NLP	0.001328
Cook ,	1.000000
pitch	0.000029
of disambiguation	0.000891
con sentiment	1.000000
Savic	0.000029
system operators	0.010753
relationships in	0.166667
one can	0.015385
creates new	0.500000
See machine	0.166667
Nearest-neighbor	0.000029
World	0.000203
Arbor ,	1.000000
related words	0.066667
`` corpora	0.005291
identifying the	0.666667
Substantial test	0.500000
machine-aided	0.000029
<s> With	0.003843
the final	0.002768
mainly the	0.166667
My head	1.000000
SWER -RRB-	1.000000
vectors ,	0.333333
Interactional	0.000029
is produced	0.004065
recognizer ,	1.000000
in various	0.005618
automatic analysis	0.043478
were ambiguous	0.024390
funding of	0.125000
centroid sentence	0.500000
through a	0.250000
2500	0.000029
3rd	0.000029
number of	0.837209
the one	0.000692
emerged	0.000029
metamodel	0.000029
sentence there	0.020833
than procedural	0.022222
thus beyond	0.100000
small local	0.111111
subject -RRB-	0.125000
recursion in	1.000000
derivation	0.000116
organizations such	1.000000
models for	0.230769
For keyphrase	0.016393
supervised machine	0.062500
writing systems	0.222222
is concerned	0.004065
be represented	0.008439
think	0.000087
painstakingly ``	1.000000
semantics without	0.071429
Referring	0.000029
Before a	0.500000
-LRB- Wilensky	0.002710
is exactly	0.002033
sounds	0.000434
little	0.000087
approximation was	0.166667
common term	0.040000
prize .	1.000000
his students	0.166667
typically include	0.055556
especially because	0.066667
systems do	0.008929
Tagging	0.000029
also been	0.057971
speech-recognition engine	0.666667
direct comparison	0.166667
position of	0.250000
broadcast	0.000029
Unsupervised tagging	0.166667
coefficients	0.000116
; nor	0.021277
11	0.000029
Are there	1.000000
13	0.000058
12	0.000145
17	0.000029
gives examples	0.500000
document -LRB-	0.055556
though we	0.100000
LexRank uses	0.083333
example the	0.012346
noise but	0.125000
an evaluation	0.007576
topics	0.000203
exceeded	0.000029
where POS	0.028571
future developments	0.333333
the subjectivity	0.000692
having considerable	0.200000
knowledge base	0.148148
speakers	0.000116
efficient	0.000087
or people	0.009009
potential	0.000203
by Frost	0.005714
cases are	0.055556
appears that	0.200000
can ''	0.011050
multiple parts	0.076923
learn tag	0.076923
Features might	1.000000
To mine	0.111111
and laughter	0.001445
ask him	0.250000
currency for	1.000000
attractive recognition	0.333333
an OCR	0.007576
leads ,	1.000000
shop	0.000029
previously-written	0.000029
show	0.000029
the Wall	0.001384
after removing	0.083333
, some	0.005053
wide range	0.500000
section titles	0.166667
be reached	0.004219
who is	0.200000
Translation	0.000087
complicating the	1.000000
human judge	0.021739
nearly	0.000058
2008 -RRB-	1.000000
original sound	0.076923
answering	0.000347
discourses and	0.500000
method -LRB-	0.062500
1979 -RRB-	1.000000
years development	0.095238
are numerous	0.004149
relative	0.000087
promise to	1.000000
`` universal	0.010582
been displaced	0.014706
1996 ,	1.000000
best guesses	0.055556
Bayes ,	0.333333
mild repetitive	1.000000
-LRB- Asia	0.002710
development cost	0.083333
<s> Finally	0.000769
documents as	0.026316
MT companies	0.200000
F =	1.000000
and techniques	0.001445
prepared ,	1.000000
uses several	0.071429
processing plain	0.018519
developed CLAWS	0.038462
sensible	0.000029
For sentiment	0.016393
a robot	0.001227
culminating in	1.000000
word to	0.016667
call ''	0.333333
translation paradigms	0.013514
top-down parsers	0.250000
is hard	0.002033
Fairclough	0.000029
RCA Drum	0.200000
'' non-linearly	0.005376
<s> Large-scale	0.000769
through the	0.500000
Psycholinguists	0.000029
photocells	0.000029
Edward	0.000029
ongoing	0.000058
-RRB- vs.	0.002817
transducers with	1.000000
weighted finite	0.333333
conferences	0.000029
summaries is	0.069767
-RRB- recognize	0.002817
forms of	0.333333
devised to	0.500000
known key	0.038462
paper used	0.090909
based engine	0.018519
approaches differ	0.035714
the British	0.000692
others were	0.083333
speech	0.004401
Mention must	1.000000
sentences '	0.013158
FAA document	0.500000
sentences ,	0.105263
to eliminate	0.002656
-RRB- task-based	0.005634
largely	0.000145
works It	0.500000
roughly	0.000087
solve	0.000116
LMF -RRB-	1.000000
Initial results	1.000000
Digest ,	0.333333
Google .	0.500000
degrees depending	0.500000
Booth and	1.000000
Hirschman 1998	0.500000
bi-directional	0.000029
be presented	0.004219
: syntax	0.009804
or con	0.004505
right kind	0.100000
meaning of	0.304348
interactive translation	0.250000
broad ,	0.250000
grid	0.000029
materials to	0.500000
and large	0.001445
sentence and	0.020833
LexRank deals	0.083333
-- to	0.040000
from section	0.009615
ATIS .	1.000000
suitability for	0.500000
facing	0.000029
either	0.000290
those which	0.045455
words emerge	0.009174
into battle	0.012821
British General	0.333333
its main	0.028571
Dr.	0.000029
Statistics guided	0.333333
matching	0.000145
, sets	0.000561
devoted in	0.200000
'' a	0.016129
pilots flying	0.500000
extensively	0.000029
-LRB- Journal	0.002710
to resort	0.001328
Environmental noise	1.000000
with deep	0.005464
T.	0.000029
sound blocks	0.050000
'' .	0.069892
'' ,	0.161290
'' -	0.010753
over hand-produced	0.083333
or phrases	0.009009
and Lifeline	0.001445
human user	0.043478
referenced	0.000029
moon missions	1.000000
or to	0.009009
references	0.000116
, Margaret	0.000561
produces Grass	0.250000
is capitalized	0.002033
http:\/\/arxiv.org\/abs\/1104.2086 -RRB-	1.000000
typically grouped	0.055556
methods did	0.022727
possible forms	0.041667
, large	0.000561
those meanings	0.045455
to analyzing	0.001328
: how	0.009804
; or	0.021277
formalisms	0.000058
name must	0.200000
represent natural	0.111111
<s> LUNAR	0.000769
following words	0.066667
extraction process	0.032258
Warren Weaver	1.000000
Society	0.000029
a necessary	0.001227
was Pollen	0.012987
Leo Spitzer	1.000000
risk -LRB-	0.500000
USA	0.000029
sentiment -LRB-	0.040000
world 's	0.066667
citation	0.000376
deep	0.000203
general	0.000637
unigrams	0.000347
, adjective	0.000561
1-July-2005	0.000029
genres	0.000029
As this	0.055556
and when	0.001445
personnel	0.000029
to +5	0.001328
like supervised	0.035714
98.5	0.000029
vibrates per	1.000000
SBD -RRB-	1.000000
enumerated all	1.000000
was connected	0.012987
computer-generated	0.000029
was of	0.012987
that determines	0.007092
<s> This	0.039969
important	0.000463
world ''	0.066667
these environments	0.023810
a number	0.024540
Speaking ''	1.000000
observe	0.000029
Piron ,	0.333333
possible word	0.041667
pollen count	0.076923
oral	0.000029
Was he	1.000000
how people	0.034483
aids	0.000029
speech feature	0.006579
Marcus M.	1.000000
most popular	0.051724
Greene and	1.000000
determine both	0.043478
looking wave	0.200000
aids for	1.000000
that appear	0.014184
trainer .	1.000000
news documents	0.076923
referring expression	0.500000
returning	0.000058
environment where	0.166667
domain-specific	0.000058
characters to	0.062500
difference	0.000116
are names	0.004149
human-generated summaries	0.500000
cohesion ''	1.000000
, adjectives	0.000561
minimize the	1.000000
of theories	0.000891
terms ,	0.076923
ideas in	0.500000
to progress	0.001328
same in-depth	0.040000
, domotic	0.000561
the founder	0.000692
to these	0.002656
public	0.000029
<s> Starting	0.000769
component	0.000145
of analyzing	0.000891
approached keyphrase	0.500000
harder it	0.142857
rich information	0.200000
segments each	0.200000
any speaker	0.032258
Naomi	0.000058
million books	0.333333
was all	0.012987
<s> To	0.006149
expression generation	0.100000
at varying	0.014706
their own	0.029412
readily	0.000087
Europe	0.000145
an input-stream	0.007576
, instead	0.000561
representation -LRB-	0.105263
two	0.000840
comparing	0.000058
90 %	1.000000
, negative	0.000561
all written	0.069767
might expect	0.038462
like writing	0.035714
, dimensionality	0.000561
assign positive	0.200000
first customers	0.030303
enormous amount	1.000000
unit ,	0.333333
LR parsers	1.000000
<s> Its	0.001537
‚Üí	0.000087
paragraph	0.000087
Zacharov -RRB-	1.000000
pioneered	0.000087
Web 2.0	0.111111
or sentiments	0.004505
issue .	0.250000
issue ,	0.125000
Relationship extraction	1.000000
in domains	0.001873
about 1965	0.025000
priorities	0.000029
!	0.000029
smoothly or	0.500000
conversation with	0.500000
computer database	0.022727
which even	0.007246
of modern	0.000891
This way	0.015873
attitude of	0.500000
difficult tasks	0.071429
amenable to	1.000000
This was	0.015873
walk to	0.200000
Standard Annex	0.500000
submit their	0.500000
Ideally ,	1.000000
Produce a	1.000000
grounded in	1.000000
technique chosen	0.142857
the start	0.002768
among others	0.125000
to computer	0.001328
sound really	0.050000
`` STT	0.005291
playing	0.000029
if a	0.035714
, ''	0.001684
formal representations	0.222222
smaller dictionary	0.142857
connected directly	0.200000
summary might	0.023810
25	0.000029
26	0.000029
20	0.000029
21	0.000029
this constraint	0.010989
23	0.000029
years in	0.047619
sponsored by	0.500000
database ,	0.100000
for billing	0.003610
and Development	0.001445
decade in	0.333333
LUNAR	0.000087
accelerations and	1.000000
between discourse	0.128205
linguistics is	0.150000
output nodes	0.076923
which describe	0.007246
for programming	0.003610
unit block	0.333333
deteriorated	0.000029
computer interaction	0.022727
eliminate the	0.500000
is where	0.004065
text is	0.025157
and natural	0.005780
chose different	1.000000
is performed	0.004065
feature dependencies	0.076923
hard	0.000174
logical assertions	0.166667
isolated speech	0.400000
text in	0.050314
and Vietnamese	0.001445
other levels	0.014286
algorithm known	0.035714
print	0.000029
was extensively	0.012987
categories themselves	0.111111
same as	0.080000
modeling has	0.142857
pattern has	0.166667
machine -RRB-	0.012658
the Levenshtein	0.000692
prior work	0.333333
technique which	0.142857
increasing the	0.333333
component .	0.200000
previous training	0.333333
computers	0.000261
generators .	0.500000
read musical	0.142857
Brenton	0.000029
sentence-level syntax	1.000000
language constraints	0.006757
accordance with	1.000000
Kurzweil started	0.142857
devoted exclusively	0.200000
, outputting	0.000561
Precision	0.000029
least	0.000145
Clancy	0.000029
assumption	0.000058
of User	0.000891
combination hidden	0.200000
popularity as	1.000000
learning ,	0.093023
learning .	0.093023
related questions	0.066667
then we	0.057143
to clean	0.001328
part	0.000782
pars	0.000029
doctors	0.000087
This is	0.269841
Rogerian psychotherapist	1.000000
`` On	0.005291
speech recognizers	0.006579
recording	0.000029
Ohio Bell	1.000000
accent ,	1.000000
was tested	0.012987
trillion-word	0.000029
SPHINX	0.000029
on it	0.004717
proved far	0.333333
majority	0.000029
not pre	0.008929
the subsequent	0.000692
likely related	0.062500
individuals that	1.000000
example ,	0.666667
state-of-the-art	0.000058
example :	0.024691
correct answer	0.066667
extremely	0.000116
<s> Individuals	0.000769
unigrams ,	0.250000
unigrams .	0.166667
can simplify	0.005525
Patent	0.000087
podcast where	1.000000
propositions ,	1.000000
weapons release	1.000000
UK RAF	0.250000
networks	0.000405
photos against	1.000000
, similarities	0.000561
' at	0.052632
sentence-level	0.000029
a purpose	0.001227
community ,	1.000000
8	0.000029
constraints ;	0.250000
to five	0.001328
is considerable	0.002033
constraints .	0.250000
<s> Behind	0.000769
token ,	0.250000
be an	0.004219
clues in	0.333333
common	0.000724
be as	0.012658
senses .	0.500000
semitied	0.000029
be found	0.012658
part-of-speech markers	0.066667
segments and	0.200000
discover these	1.000000
Canadian Hansard	0.500000
right-hand-sides	0.000029
in most	0.007491
'' corpora	0.005376
Senseval	0.000029
Unix	0.000058
ELIZA might	0.111111
's methodology	0.019608
`` Speaker	0.010582
Postal	0.000029
agreement about	0.333333
is ``	0.004065
<s> Bottom-up	0.000769
that funding	0.003546
, our	0.000561
semantics ,	0.285714
semantics .	0.071429
generated -LRB-	0.066667
models were	0.038462
representing successive	0.500000
also classify	0.014493
reverse	0.000058
For a	0.032787
introduction of	1.000000
say ,	0.285714
manage their	1.000000
simply	0.000347
opens ,	1.000000
are then	0.004149
45 %	1.000000
together in	0.125000
, \*	0.000561
of building	0.000891
gap	0.000029
estate advertisements	1.000000
say `	0.285714
sentence to	0.020833
There is	0.272727
some set	0.012048
Shepard went	0.333333
a user	0.002454
It was	0.052632
Performing grammatical	1.000000
a recent	0.001227
College	0.000058
length normalization	0.125000
search .	0.090909
text to	0.044025
Fairclough ,	1.000000
real-valued	0.000087
tagging work	0.040000
of fusion	0.000891
, usually	0.002807
signals are	1.000000
structures ,	0.200000
-LRB- extrinsic	0.002710
coherence and	0.666667
discourse	0.001042
difficult to	0.392857
Symantec changed	0.500000
Weizenbaum at	0.333333
notion of	0.750000
also be	0.101449
A number	0.060000
, DeRose	0.000561
purpose	0.000145
Activity	0.000029
specific summarization	0.047619
pattern recognition	0.666667
vectors would	0.333333
, semantics	0.001684
be moderate	0.004219
hand -RRB-	0.071429
metrics like	0.111111
-	0.000463
the ROUGE	0.000692
usually the	0.031250
less accurate	0.083333
sponsored evaluations	0.500000
ICR .	0.333333
approach in	0.028571
deliberately	0.000029
what they	0.031250
was considered	0.012987
next word	0.285714
judgement	0.000087
Future research	0.500000
parser is	0.187500
smoothing to	1.000000
semi	0.000029
moderate with	0.200000
<s> Furthermore	0.004612
data sources	0.025974
-RRB- Hands-free	0.002817
CyberEmotions	0.000029
accelerations	0.000029
the sentiment	0.001384
, cursive	0.000561
1971 -LRB-	0.333333
ending at	1.000000
although there	0.166667
Commissioned by	1.000000
Some text	0.047619
more data	0.021053
T ,	0.166667
So an	0.333333
very common	0.048780
301	0.000029
synthesis techniques	1.000000
addressed in	0.500000
, interlingual	0.001123
vol-2	0.000029
air -LRB-	0.200000
readability	0.000029
in artificial	0.001873
constraint	0.000029
processing tasks	0.018519
because NLP	0.033333
or movies	0.004505
networks allow	0.071429
robust when	0.500000
segment the	0.111111
of segmentation	0.000891
getting into	0.250000
be referenced	0.004219
extracting answers	0.200000
for developing	0.007220
top-down expansion	0.250000
on developing	0.004717
LDA-based	0.000029
contrastive analysis	1.000000
method used	0.062500
seconds ,	1.000000
theory to	0.076923
simplify the	1.000000
Ruth Wodak	1.000000
much slower	0.090909
decided that	0.333333
kind appears	0.090909
acoustic and	0.166667
input which	0.024390
achieves its	0.500000
, ASR	0.000561
-- indeed	0.040000
Books	0.000029
exploration	0.000029
milliseconds	0.000058
using algorithms	0.016949
words coming	0.009174
decided without	0.333333
textual representation	0.200000
Perhaps	0.000029
single	0.000405
big a	0.500000
<s> Due	0.000769
May	0.000058
H. Shepard	0.500000
evaluation is	0.074074
within Tipster	0.055556
Man	0.000058
Case	0.000029
works These	0.500000
prepared	0.000029
much harder	0.045455
most other	0.017241
to encourage	0.001328
-RRB- into	0.005634
recognition is	0.074380
the desktop	0.000692
2,000 or	0.500000
express sentiment	0.200000
Asian	0.000029
articulated theory	1.000000
take advantage	0.400000
a task	0.003681
historically -RRB-	0.500000
general approaches	0.045455
'' ``	0.005376
and Grass	0.001445
the dBase	0.000692
-LRB- parsed	0.002710
mid-1960s .	1.000000
1914 ,	1.000000
entry has	0.250000
University by	0.111111
helps	0.000058
, Vito	0.000561
automotive	0.000029
in full	0.001873
DTW .	0.333333
be decided	0.004219
helped improve	0.333333
help to	0.111111
EMR -LRB-	0.333333
judgments .	1.000000
gather information	1.000000
on programer	0.004717
such rules	0.008130
with equivalent	0.010929
paper-to-computer text	1.000000
the norm	0.000692
<s> Commanders	0.000769
exchange	0.000029
Evaluation -LRB-	0.111111
objects	0.000145
for acquiring	0.003610
implicit	0.000029
Chinese	0.000203
32	0.000029
, Nikolas	0.000561
30	0.000087
programs often	0.090909
their input	0.029412
Acoustical distortions	0.500000
stochastic semantic	0.125000
authors found	0.200000
such input	0.008130
Subsequently a	1.000000
improvements .	0.500000
our alphabetic	0.200000
basic and	0.076923
phrase `	0.100000
large probabilities	0.043478
unsupervised ''	0.125000
, Ruth	0.000561
similar ideas	0.037037
determining sentiment	0.166667
NLP that	0.021277
network approaches	0.333333
keyphrases available	0.028571
direct translation	0.166667
Recent research	0.666667
Recognition or	0.125000
other native	0.014286
year later	0.166667
have focused	0.019231
phrase ,	0.100000
normalized	0.000029
Yet ELIZA	1.000000
speech from	0.006579
on discourse	0.004717
focus is	0.142857
Recognition of	0.250000
is semantic	0.002033
basis for	0.333333
to arrive	0.001328
contained in	1.000000
obvious	0.000029
number on	0.023256
1980s ,	0.555556
on machine-learning	0.004717
want not	0.166667
differ in	0.333333
ATNs	0.000087
Teun	0.000029
the editor	0.000692
Phonemes	0.000029
the personal	0.000692
democracy	0.000029
Sometimes it	1.000000
modeling of	0.142857
detail .	0.500000
nouns -LRB-	0.111111
out from	0.071429
Journal corpus	0.333333
useful NLG	0.071429
ambiguous	0.000347
this step	0.010989
WER	0.000029
Approaches which	0.333333
of Quechua	0.000891
The umbrella	0.005208
, widely	0.000561
perhaps the	0.166667
error -LRB-	0.166667
has plateaued	0.011905
leverages the	1.000000
Chilton ,	1.000000
looks ,	0.250000
to post-process	0.001328
such corpora	0.016260
technology Sensory	0.045455
high levels	0.166667
linguistics .	0.050000
linguistics ,	0.400000
views as	1.000000
Web pages	0.222222
greater	0.000087
graphic user	1.000000
a potentially	0.001227
entries ,	0.500000
is written	0.002033
levels for	0.136364
proven useful	1.000000
Knowing this	1.000000
a growing	0.001227
fulfill the	0.500000
IBM Research	0.333333
tones that	1.000000
Michael Stubbs	0.250000
the disfluences	0.000692
-RRB- output	0.002817
versions of	0.333333
multi-document extractive	0.250000
In 1935	0.009524
conducted the	0.200000
to specify	0.001328
stub	0.000029
These standards	0.058824
is specifically	0.002033
Speaker Independent	0.166667
translation :	0.027027
of hand-written	0.002674
-RRB- Bhatia	0.002817
Unix Consultant	0.500000
and knowledge	0.001445
translation ,	0.108108
translation .	0.054054
possible task	0.041667
with an	0.027322
interaction	0.000232
conversations .	0.333333
with keyphrases	0.005464
conversations ,	0.333333
taken up	0.333333
words relate	0.009174
judges can	0.500000
Hence -LRB-	0.500000
stage of	0.400000
speech tools	0.006579
2,000	0.000058
Modern	0.000087
performed through	0.100000
single verbal	0.071429
Annotate the	1.000000
have unambiguous	0.009615
was a	0.038961
's job	0.039216
were question	0.024390
results are	0.190476
command interpreters	0.500000
seen in	0.100000
been trained	0.014706
they refer	0.050000
AVRADA tests	0.500000
at conclusions	0.014706
are broader	0.004149
, automatic	0.001684
content -LRB-	0.083333
system developed	0.010753
visited	0.000029
leading to	1.000000
was .	0.012987
consideration of	0.333333
controller would	0.250000
papers by	0.333333
Machine	0.000261
unlikely	0.000029
close	0.000029
Oil	0.000029
mid	0.000029
as models	0.003484
explicit word	0.200000
Carston	0.000029
every combination	0.333333
constraints Read	0.250000
Some	0.000608
graphs	0.000029
and create	0.002890
normally	0.000058
this ostensibly	0.010989
`` defective	0.005291
Bhatia	0.000029
is unusual	0.002033
, multi-document	0.000561
has not	0.023810
use text	0.013889
has now	0.011905
, especially	0.005053
accommodate direct	0.200000
each template	0.022222
complicated backgrounds	0.333333
documents and	0.026316
speech-recognition machine	0.333333
inferior	0.000029
, possessive	0.000561
that minimizes	0.007092
in 1989	0.001873
, anthropology	0.000561
<s> Described	0.000769
in 1982	0.001873
in 1987	0.003745
in 1984	0.001873
True\/False	0.000029
expressed by	0.166667
currently focus	0.142857
4 star	0.200000
Their algorithm	0.500000
using precision	0.016949
step --	0.133333
of 200	0.000891
the gradual	0.000692
The results	0.005208
no matter	0.076923
been seen	0.044118
informal exchange	0.500000
of existing	0.001783
pattern	0.000174
, need	0.000561
Example-based machine	0.666667
segmentation will	0.030303
NLP systems	0.063830
of intermediary	0.000891
generalized ATNs	1.000000
anomalies .	1.000000
a system	0.012270
POS tagging	0.384615
taking	0.000145
set that	0.025641
time series	0.030303
Alessandro	0.000029
Design	0.000087
place in	0.500000
detailed	0.000058
relevant	0.000203
by searching	0.005714
validity and	1.000000
Products began	0.500000
any case	0.096774
resolved :	1.000000
usually separated	0.031250
inference algorithms	0.250000
January 13	0.250000
proposal	0.000029
during verbalization	0.100000
machines by	0.250000
these actions	0.023810
finished	0.000058
doctors ,	0.333333
an abstract	0.007576
by precision	0.005714
on understanding	0.004717
it belongs	0.008547
Topics of	1.000000
summarization system	0.060000
many sentences	0.019231
this task	0.043956
work has	0.083333
sometimes had	0.076923
inseparable part	1.000000
manually	0.000116
almost	0.000029
walks	0.000058
proper noun	0.142857
The vertices	0.005208
consideration neural	0.333333
the latter	0.000692
requires a	0.062500
The reader	0.005208
and recording	0.001445
to book	0.001328
any arbitrary	0.064516
the difficulty	0.000692
infer	0.000029
e.g. Noise	0.017857
a clarification	0.001227
language or	0.013514
reporting	0.000087
approaches :	0.142857
abruptly at	1.000000
modern parsers	0.200000
approaches ,	0.035714
approaches .	0.107143
PAM -LRB-	1.000000
language of	0.006757
<s> Little	0.000769
as SVM	0.003484
The relations	0.026042
, UMLS	0.000561
some labeled	0.012048
soft ,	0.500000
languages are	0.020000
constraints are	0.250000
made by	0.062500
patent on	0.750000
nodes based	0.142857
speaking speeds	0.125000
DOE -RRB-	1.000000
been explored	0.014706
a date	0.001227
add	0.000029
a data	0.001227
propositions	0.000058
confusions	0.000029
match	0.000174
with machine	0.005464
tourism information	1.000000
part -LRB-	0.037037
we learn	0.022222
unsupervised summarization	0.250000
Ethnomethodology	0.000029
perceptions are	1.000000
from which	0.028846
Noise in	1.000000
test documents	0.200000
likely another	0.062500
proper	0.000203
are already	0.004149
in taxonomies	0.001873
feature\/aspect-based sentiment	1.000000
the Viterbi	0.002768
commercially available	1.000000
1935 Tauschek	1.000000
layer of	1.000000
is brought	0.002033
and negative	0.002890
, several	0.000561
used OCR	0.008850
British English	0.333333
although	0.000174
controversy is	1.000000
about	0.001158
actual	0.000145
boards	0.000029
Generation	0.000058
certainty	0.000029
of approaches	0.000891
basically a	1.000000
or paragraph	0.004505
of international	0.000891
the outside	0.000692
functional	0.000058
Computing +	0.500000
, task-based	0.000561
blind ,	0.250000
are under	0.004149
of phonetic	0.000891
researchers wrote	0.100000
segmentation may	0.030303
phases .	1.000000
second aim	0.100000
other pieces	0.014286
26 letters	1.000000
repeated	0.000058
disambiguate sentence	0.333333
Significant advances	1.000000
a difficult	0.001227
vastly less	1.000000
theoretical perspectives	0.333333
discussions in	0.333333
objective sentences	0.200000
some form	0.048193
proceeds	0.000029
automatically and	0.095238
47	0.000029
ambiguity by	0.125000
45	0.000029
that identify	0.003546
impossibility	0.000029
40	0.000058
Context and	1.000000
occurrence of	0.500000
of accent	0.000891
requires six	0.062500
no. .	1.000000
highly structured	0.111111
5 consecutive	0.500000
coding of	1.000000
of answer	0.000891
definitional questions	1.000000
GALE	0.000058
questions asking	0.038462
Moreover ,	1.000000
limited	0.000290
of physics	0.000891
Described	0.000029
Extractive methods	1.000000
a universal	0.001227
well be	0.035714
the last	0.002076
is getting	0.004065
Naive	0.000029
containing	0.000232
font at	0.333333
under	0.000145
Air controller	0.333333
<s> Artificial	0.000769
proposed as	0.111111
level is	0.050000
people ,	0.062500
people .	0.125000
<s> English	0.000769
an input	0.022727
Henry	0.000058
with initial	0.005464
learned from	0.200000
levels will	0.090909
dynamically create	0.500000
unified mathematical	1.000000
graph-based	0.000058
look-up	0.000029
simply based	0.083333
Management command	1.000000
An explicit	0.062500
consistent	0.000029
English POS-taggers	0.027027
the keyboard	0.000692
words commonly	0.009174
effectively learning	0.333333
of spoken	0.001783
whole workday	0.111111
Huang	0.000029
reader was	0.200000
we produce	0.044444
Harold Garfinkel	1.000000
learning model	0.023256
represented	0.000174
70s	0.000029
Savic Naomi	1.000000
features are	0.115385
metrics in	0.111111
the search	0.000692
Subsumption	0.000029
Part-of-speech	0.000058
unigram matching	0.200000
target-language-independent	0.000029
language are	0.006757
translation of	0.148649
June	0.000029
HMM-based approach	0.666667
people from	0.062500
noting	0.000029
see appraisal	0.050000
assessment	0.000029
translation or	0.013514
task -LRB-	0.023810
in garden	0.001873
this are	0.021978
extensively used	1.000000
including images	0.071429
<s> Examples	0.002306
will not	0.114286
the judge	0.000692
distinguish reliably	0.200000
possible semantics	0.041667
being able	0.055556
, Stephen	0.000561
, Why	0.000561
similarity to	0.100000
segmentation depends	0.030303
many as	0.019231
CSIS	0.000058
by these	0.005714
of elementary	0.000891
appears to	0.200000
express all	0.200000
warping -LRB-	0.250000
walk ,	0.200000
Most modern	0.500000
there 's	0.025000
methods Some	0.022727
generated out	0.066667
Page\/Lex\/TextRank that	1.000000
simply verbs	0.083333
German taggers	0.250000
have to	0.019231
linguistic formalism	0.062500
Essentially ,	1.000000
the effectiveness	0.000692
challenges -RRB-	0.500000
Hendrix formed	1.000000
processing -LRB-	0.074074
bore similarities	1.000000
the prolific	0.000692
complexity	0.000347
than T	0.022222
recognize equivalent	0.111111
trivial ,	0.250000
aloud	0.000029
Web-based	0.000087
<s> Realisation	0.000769
-- often	0.040000
currently used	0.142857
routing -LRB-	0.333333
Ford Sync	1.000000
for up-to-date	0.003610
automating	0.000029
principled way	1.000000
test document	0.100000
Pang who	0.333333
1971 Terry	0.333333
, who	0.000561
U.S. program	0.142857
into its	0.012821
defines the	0.500000
Act of	1.000000
, why	0.001123
tourism	0.000029
especially if	0.066667
Some current	0.095238
Granada Pallet	0.500000
best one	0.055556
selecting examples	0.200000
distribution that	0.500000
each	0.001303
a real	0.002454
modern statistically-based	0.200000
Objectives	0.000029
the models	0.000692
and multitude	0.001445
<s> Warren	0.000769
<s> Aggregation	0.000769
time-consuming and	0.333333
-RRB- by	0.002817
collaborated	0.000029
'' from	0.005376
were accelerations	0.024390
relatively simple	1.000000
while logic	0.050000
extraction system	0.064516
Studies	0.000029
vol-2 Black	1.000000
The performance	0.005208
messages into	0.500000
and informativeness	0.001445
of phrases	0.000891
onto	0.000029
, words	0.001123
, document	0.000561
Stanford University	0.500000
rank	0.000174
in systems	0.003745
20th-century	0.000029
toy	0.000058
Nielsen	0.000029
must take	0.071429
top	0.000145
too	0.000174
popular is	0.111111
Creating referring	0.500000
clues not	0.333333
concurrently with	1.000000
artificial languages	0.090909
subsequent application	0.500000
stopwords .	1.000000
maximal probability	1.000000
ends up	0.500000
appliance control	1.000000
speech tagging	0.013158
approach ,	0.057143
summaries formed	0.023256
in pattern	0.001873
in use	0.003745
commercializing	0.000029
overriding issue	1.000000
converse on	1.000000
report -LRB-	0.250000
1969	0.000058
1964	0.000029
has 4	0.011905
1966	0.000087
has 2	0.011905
that was	0.010638
hard if-then	0.333333
Gina Poncini	1.000000
to separate	0.001328
at lower	0.014706
capitalization	0.000087
though	0.000290
`` central	0.010582
to place	0.002656
punched cards	1.000000
of individual	0.001783
items in	0.500000
an LDA-based	0.007576
to make	0.005312
has a	0.047619
grammatical relationships	0.090909
machine and	0.012658
the future	0.001384
solutions	0.000058
High-performance fighter	1.000000
can function	0.005525
should predict	0.052632
tools usually	0.166667
Records	0.000029
decoding is	1.000000
Cognitive	0.000087
include versions	0.037037
algorithm exploits	0.035714
report	0.000116
Web -RRB-	0.111111
scale ,	0.333333
recognized or	0.166667
scale .	0.166667
effective .	0.333333
are complicated	0.004149
that adaptation	0.003546
which led	0.007246
combination with	0.400000
2,026,329 -RRB-	1.000000
Spanish do	0.500000
automatic	0.000666
of question	0.002674
appears in	0.200000
roadmap	0.000029
detection	0.000058
each other	0.133333
the comprehension	0.000692
cost of	0.500000
M-346	0.000029
discriminate because	0.333333
recognizing entire	0.200000
approach	0.001013
these apply	0.023810
number -RRB-	0.046512
alone usually	0.250000
weak	0.000029
-LRB- QA	0.002710
taken place	0.333333
have developed	0.009615
wear	0.000029
relationships can	0.166667
find left-most	0.076923
for word	0.003610
corpus and	0.032258
Computed	0.000029
For the	0.016393
Bobrow	0.000029
as EAGLi	0.003484
after testing	0.083333
games	0.000029
verb or	0.230769
simpler questions	0.333333
president of	1.000000
variance	0.000029
a specialised	0.001227
word can	0.033333
convinced many	1.000000
custom software	0.500000
successes occurred	1.000000
requires significant	0.062500
for generating	0.003610
each ambiguity	0.022222
and then	0.010116
the differences	0.000692
<s> Part-of-speech	0.000769
of computerized	0.001783
part-of-speech tagging	0.466667
the features	0.003460
simplification	0.000029
quickly	0.000029
one detail	0.015385
speech choice	0.006579
expected	0.000203
hence reducing	0.500000
1 %	0.500000
Pennsylvania	0.000029
a communicative	0.001227
sources or	0.166667
pitch ,	1.000000
non-Western	0.000029
; otherwise	0.021277
procedure	0.000087
, TextRank	0.001123
pyramid	0.000029
on an	0.014151
value ,	0.333333
undercarriage	0.000029
value .	0.333333
resolve some	0.250000
experts	0.000029
suggest	0.000087
much about	0.045455
n't end	0.250000
advances	0.000029
Part-of-Speech	0.000029
was applied	0.012987
minimum phone	0.500000
are consumed	0.004149
contain enough	0.083333
pick	0.000029
hard task	0.166667
token generation	0.250000
positives	0.000029
normalization	0.000174
the culture	0.000692
some nice	0.012048
SHRDLU could	0.166667
Internet and	0.500000
broad tags	0.250000
between closely	0.025641
another linguistic	0.076923
MAHS =	1.000000
NLG researchers	0.047619
<s> Attribute	0.000769
F35	0.000029
Nunan	0.000029
summaries -LRB-	0.046512
official languages	1.000000
paper documents	0.090909
exceptions -RRB-	1.000000
, reliability	0.000561
linguistic cues	0.062500
advent of	1.000000
learning applications	0.023256
the Baum-Welch	0.000692
vibration	0.000029
should figure	0.052632
the south	0.001384
transcription .	0.500000
and syntactic	0.002890
<s> Given	0.002306
cultural	0.000029
at Brown	0.029412
judge	0.000116
this aim	0.010989
's 1990	0.019608
MLLT -RRB-	1.000000
translation Transfer-based	0.013514
Word splitting	0.285714
a scaling	0.001227
50	0.000087
arbitrary	0.000087
<s> Tags	0.000769
errors or	0.200000
a smaller	0.001227
successfully	0.000087
tackles each	1.000000
Much	0.000087
interact with	1.000000
tagging by	0.040000
extended in	1.000000
germane to	1.000000
areas ,	0.166667
answer 90	0.033333
a major	0.006135
control when	0.200000
the state-of-the-art	0.000692
again statistically	1.000000
mechanized	0.000029
chapter	0.000029
be based	0.004219
grammars can	0.071429
forward-backward algorithm	1.000000
naturally occurring	0.500000
plus	0.000029
cursive handwriting	0.200000
human review	0.021739
calling for	1.000000
, Cleave	0.000561
need is	0.047619
transform	0.000145
= Noun	0.111111
the Brown	0.005536
<s> Sentence	0.002306
attempted	0.000029
performance is	0.111111
portions	0.000029
in spoken	0.003745
Microphone on	1.000000
Nuance Voice	0.333333
Granada	0.000058
the inherent	0.000692
in each	0.001873
human -LRB-	0.043478
, ICASSP	0.000561
constrained ,	1.000000
discontinuous ,	0.333333
diagramming of	1.000000
systems based	0.017857
naive semantics	0.500000
applied ,	0.066667
= no.	0.111111
been devised	0.014706
to enable	0.001328
whereas	0.000087
Archaeology of	1.000000
this paper	0.010989
There are	0.545455
Effective	0.000029
Design choices	1.000000
lies the	0.500000
measures how	0.333333
return a	0.500000
using either	0.016949
recognition because	0.008264
an opportunity	0.007576
the questioner	0.002768
focus	0.000203
adjective	0.000203
suggest a	0.333333
US Navy	0.142857
recognized normal	0.166667
`` patient	0.005291
data be	0.012987
analysis which	0.015385
environment	0.000174
charge	0.000029
promoting	0.000029
techniques merely	0.043478
so it	0.066667
Tagger ,	1.000000
management system	0.142857
individual morphemes	0.083333
UPV -RRB-	1.000000
environments .	1.000000
ca n't	1.000000
improve results	0.076923
up-to-date research	1.000000
, Wayne	0.000561
vulnerable to	1.000000
They simply	0.333333
producing the	0.333333
only one	0.026316
dried	0.000029
size N	0.166667
improve robustness	0.076923
Known word	1.000000
since they	0.100000
is challenging	0.002033
with low	0.005464
favor a	0.500000
developments in	0.666667
'' exceeded	0.005376
mention how	0.333333
Aermacchi M-346	1.000000
dissertation -LRB-	0.333333
size ,	0.166667
emerge	0.000029
successively more	1.000000
in Scotland	0.001873
Collection of	1.000000
Telematics -LRB-	1.000000
covariance transform	0.500000
formalisms\/languages	0.000029
<s> Accuracy	0.003843
a fluent	0.001227
handles	0.000029
the implied	0.000692
inference within	0.250000
major algorithms	0.083333
enhance accessibility	1.000000
It 's	0.052632
speech that	0.006579
nearly anything	0.500000
new application	0.041667
that converts	0.003546
lexical similarity	0.076923
recognition within	0.008264
Please improve	0.333333
repeatedly reviewed	1.000000
converted the	0.333333
differences It	0.333333
and computationally	0.001445
are analytical	0.004149
extracting sentences	0.200000
Edmund	0.000029
counting	0.000029
sentences weighted	0.013158
1	0.000116
DeRose and	0.200000
online expression	0.125000
combine various	0.666667
evaluate summaries	0.250000
used in	0.203540
of subjectivity	0.000891
for air	0.003610
to texts	0.001328
emails -RRB-	0.500000
used is	0.008850
as an	0.045296
be unrealistically	0.004219
<s> Typically	0.000769
context-free ,	0.090909
in reverse	0.001873
-RRB- while	0.002817
human intervention	0.021739
of Speaker	0.000891
advertisements .	1.000000
'' text	0.005376
Machines	0.000029
disease ,	1.000000
extractor	0.000058
led by	0.333333
far is	0.125000
and placed	0.001445
representative of	1.000000
text more	0.006289
levels even	0.045455
depth understanding	0.333333
sources are	0.166667
to TextRank	0.001328
usefulness of	1.000000
, sufficiently	0.000561
continue	0.000029
between posts	0.025641
Using	0.000058
ongoing issue	0.500000
anthropology ,	1.000000
the narrowest	0.000692
describe informal	0.166667
out a	0.071429
the domain	0.001384
Nearest-neighbor have	1.000000
term	0.000521
name	0.000145
acquiring coarse-grained	1.000000
is how	0.004065
paradigm includes	0.333333
pyramid showing	1.000000
Knowledge of	0.500000
uttered one	0.333333
closed-captioning	0.000029
Knowledge on	0.500000
up or	0.045455
rank ,	0.166667
rank .	0.166667
a stream	0.001227
coherence .	0.333333
up of	0.045455
<s> Leading	0.000769
parsing for	0.035714
systems indicate	0.008929
and Weizenbaum	0.001445
a conversation	0.001227
mapping	0.000058
Record	0.000029
Security	0.000029
Transfer-based machine	1.000000
library are	0.500000
abstraction Broadly	0.250000
place	0.000116
the years	0.000692
be recognized	0.008439
-RRB- securely	0.002817
PC +	0.250000
those patterns	0.045455
structures that	0.400000
often the	0.045455
our everyday	0.200000
array	0.000029
might refer	0.038462
given	0.000695
necessarily	0.000058
returns	0.000029
is used	0.026423
gives	0.000058
examples .	0.166667
we could	0.022222
humans	0.000347
mental representations	0.333333
examples ?	0.041667
released	0.000058
implicitly determines	1.000000
specify	0.000029
RSI	0.000029
fade away	1.000000
unfortunately	0.000029
synopsis like	1.000000
explore critical	0.250000
very distant	0.024390
verbalization	0.000029
from other	0.009615
they helped	0.025000
themselves sometimes	0.250000
of more	0.003565
English grammars	0.027027
some statistical	0.012048
selling a	1.000000
ideas	0.000116
ideal	0.000029
List of	1.000000
Ethnography	0.000029
one summary	0.015385
tasks include	0.031250
Turney and	0.222222
and may	0.002890
humans in	0.083333
a superset	0.001227
, phrases	0.000561
<s> Reading	0.000769
automatically tuned	0.047619
erroneous input	1.000000
document can	0.027778
workshops	0.000058
missions .	1.000000
the blind	0.000692
the CoNLL	0.000692
occur on	0.200000
bridging relationship	1.000000
`` do	0.005291
sentence -LRB-	0.020833
evidence for	0.500000
Spitzer 's	1.000000
machine-generated summaries	1.000000
rocks returned	1.000000
All the	1.000000
ways .	0.125000
ways ,	0.250000
paragraphs in	0.250000
review .	0.333333
evident that	0.500000
ways :	0.250000
define	0.000058
on summarization	0.004717
to remain	0.001328
Apollo moon	1.000000
formats like	1.000000
closed world	1.000000
reveal	0.000029
hierarchically in	1.000000
the phrase	0.002768
it 's	0.008547
by selecting	0.011429
did Christmas	0.200000
Ge'ez	0.000029
discussing	0.000058
same objects	0.040000
vertices\/unigrams are	1.000000
as nouns	0.003484
that difference	0.003546
following years	0.066667
May 2009	0.500000
: Extract	0.009804
, culminating	0.000561
subsequent	0.000058
field is	0.037037
-RRB- ;	0.022535
instances of	0.666667
outside	0.000058
task-based	0.000116
-RRB- -	0.002817
-RRB- ,	0.219718
-RRB- .	0.284507
represent only	0.111111
Natural	0.000376
turns -RRB-	0.333333
from false	0.009615
the publication	0.001384
densely	0.000058
be also	0.004219
Apple Newton	1.000000
a row	0.001227
recognized with	0.166667
in following	0.001873
corpus has	0.032258
-RRB- a	0.005634
adjective -LRB-	0.142857
Also ,	1.000000
Treebank -RRB-	0.166667
also lead	0.014493
for most	0.007220
different profile	0.020408
sold to	0.333333
`` centroid	0.005291
This work	0.031746
are used	0.033195
entirely and	0.500000
which the	0.057971
helicopter	0.000116
500	0.000058
engine	0.000174
<s> -LRB-	0.014604
under a	0.200000
, probabilities	0.000561
centrality .	0.500000
disparate fields	1.000000
abstractive method	0.166667
summarization hopes	0.020000
, no	0.001684
lexicons	0.000058
Thus the	0.083333
In Europe	0.019048
simple substitution	0.038462
Lemke	0.000029
the higher	0.000692
now the	0.076923
's Digest	0.058824
parse	0.000261
which recognized	0.007246
tagged as	0.333333
& OnlineOCR	0.250000
operational settings	1.000000
The difficulty	0.015625
basic task	0.076923
determine what	0.043478
ten-year-long research	1.000000
to require	0.001328
D. ,	0.400000
improving output	1.000000
vowel	0.000058
cartoon	0.000029
-LRB- SBD	0.002710
but robustness	0.014706
it runs	0.008547
reasoning mechanisms	0.142857
accuracy substantially	0.032258
<s> Hybrid	0.000769
presented in	0.500000
-LRB- now	0.008130
-LRB- not	0.002710
domain is	0.050000
of descriptive	0.000891
actions	0.000058
reason why	0.250000
point scale	0.333333
<s> Since	0.003075
seems	0.000058
and creation	0.001445
for Computational	0.003610
more general	0.031579
cause much	0.500000
name of	0.200000
at revealing	0.014706
include automatic	0.037037
in the	0.260300
accepted	0.000029
be for	0.004219
With IT	0.142857
of such	0.004456
... About	0.500000
all of	0.093023
G-loads .	1.000000
reduced	0.000116
Bobrow 's	1.000000
has more	0.011905
three or	0.333333
bi-directional inference	1.000000
DARPA -LRB-	0.250000
Much of	0.333333
underpinnings discouraged	1.000000
algorithms .	0.114286
algorithms ,	0.142857
2001 -RRB-	0.500000
Hansard	0.000029
would still	0.018868
a speech	0.002454
systems use	0.053571
first solid	0.030303
not necessarily	0.017857
Web or	0.111111
on this	0.014151
when discussing	0.057143
HTK	0.000058
A post	0.020000
it to	0.042735
the person	0.002768
media has	0.166667
cases where	0.166667
Control -RRB-	1.000000
reading machine	0.125000
, meaning	0.000561
play in	1.000000
English speaking	0.027027
to improve	0.011952
cosine values	0.333333
, medicine	0.000561
rescore	0.000029
short-time stationary	0.500000
corrected by	1.000000
nodes should	0.142857
Slembrouck ,	1.000000
predict what	0.166667
within computer	0.055556
regard	0.000145
up pronouns	0.045455
amongst	0.000029
Error	0.000058
program and	0.045455
security process	1.000000
part because	0.037037
decide to	0.250000
native speaker	1.000000
vocal tract	1.000000
change focus	1.000000
The user	0.005208
before it	0.166667
, complicating	0.000561
objective or	0.200000
assumptions .	0.200000
a speaker-dependent	0.001227
representation ,	0.157895
the provider	0.001384
a parser	0.003681
automatic is	0.043478
Sacks	0.000029
Parsers may	0.500000
Project ,	1.000000
slower ,	1.000000
words will	0.018349
current commercial	0.142857
backward	0.000029
was due	0.012987
systems to	0.008929
is made	0.004065
and 1980s	0.002890
unsupervised ,	0.125000
all	0.001245
humor -RRB-	1.000000
The following	0.020833
unweighted	0.000029
of syntax	0.001783
spacecraft	0.000029
meets two	0.500000
So far	0.333333
who utilize	0.100000
Das ,	1.000000
generate polynomial-size	0.055556
ARCHILES	0.000029
CANDIDE from	1.000000
other punctuation	0.014286
reference summary	0.375000
features ,	0.038462
statistical translation	0.030303
stochastic	0.000232
for Larry	0.003610
al.	0.000029
mentioned the	0.166667
combining those	0.250000
Fowler	0.000029
Afghanistan or	1.000000
then ,	0.085714
hand ,	0.500000
the history	0.000692
hand .	0.071429
translation would	0.027027
or content	0.004505
a nautical	0.001227
an extrinsic	0.007576
Force and	0.500000
learn it	0.076923
these ,	0.047619
what	0.000926
available to	0.058824
overload	0.000029
but a	0.014706
model and	0.033333
simple conditions	0.038462
-RRB- Marc	0.002817
multitude	0.000029
express this	0.200000
1965 based	0.250000
tags	0.000174
steps of	0.500000
spontaneous speech	1.000000
a more	0.004908
the emotional	0.001384
Another reason	0.076923
complexity .	0.083333
1984 .	1.000000
these T	0.023810
digital texts	0.142857
Speech segmentation	0.096774
the derived	0.000692
fair gold-standard	1.000000
, means	0.000561
extremes	0.000029
may pick	0.019231
POS-taggers	0.000029
learning automatically	0.023256
the characters	0.000692
classification :	0.058824
, text	0.001684
Tom	0.000029
of restaurant	0.000891
Human-machine interaction	1.000000
cost related	0.500000
Overall	0.000029
as multiple	0.003484
the Artificial	0.000692
is for	0.002033
, Sept.	0.000561
superset of	1.000000
separate words	0.300000
Das	0.000029
semantics which	0.142857
basically	0.000029
The recently	0.005208
Dyer	0.000029
<s> Machine	0.002306
Yale which	0.500000
printed in	0.083333
Systems with	0.083333
discussions .	0.333333
clip of	1.000000
the graph	0.004152
highest level	0.333333
Snyder performed	0.500000
ambiguous words	0.166667
been created	0.029412
uses spontaneous	0.071429
, speeches	0.000561
, simulated	0.000561
closest the	0.500000
, contain	0.000561
automatically answering	0.047619
of coherent	0.000891
replace the	1.000000
how phrases	0.034483
influenced	0.000087
Parliament	0.000058
goal	0.000203
recognition applications	0.008264
each with	0.022222
that statistical	0.003546
commercial interest	0.090909
multiple times	0.076923
judgement or	0.333333
campaigns within	0.500000
much smaller	0.045455
and Dale	0.001445
without having	0.076923
weaknesses	0.000029
and right	0.002890
difficult and	0.035714
as sentence	0.006969
scripts ,	0.333333
are commonly	0.004149
to millions	0.001328
then applied	0.057143
Hearing ,	1.000000
Machine Learning	0.111111
text databases	0.006289
binary classifier	0.250000
then applies	0.028571
essence	0.000058
natural-language	0.000029
journal abstracts	0.333333
metric such	0.333333
be understood	0.004219
style	0.000058
Full	0.000029
misspelled	0.000029
affine	0.000029
machine-learning paradigm	0.250000
resort	0.000029
several years	0.090909
of valuable	0.000891
are ``	0.004149
sometimes be	0.076923
machine digitized	0.012658
elements ,	0.250000
characterizes	0.000029
characterized	0.000116
computer-aided language	0.333333
, 1975	0.000561
, 1977	0.000561
, 1976	0.001123
, 1979	0.000561
, 1978	0.001123
techniques use	0.043478
experimented	0.000029
expect	0.000087
organised	0.000029
degree to	0.166667
Reading	0.000058
More	0.000261
the HMM	0.000692
Such inflection	0.125000
and generate	0.001445
be performed	0.008439
shipment	0.000029
simplification Text-to-speech	1.000000
Penpoint	0.000029
often make	0.022727
other places	0.014286
one language	0.030769
's many	0.019608
Malcolm Coulthard	1.000000
meet Wikipedia	0.250000
as named	0.003484
new approaches	0.041667
NLP is	0.021277
the sizes	0.000692
well-known	0.000029
sailor	0.000145
says	0.000029
allow a	0.200000
, Ford	0.000561
analysis Applied	0.015385
Models	0.000087
right-to-left ,	1.000000
2000 -RRB-	0.333333
expensive to	0.142857
involved the	0.166667
the KEA	0.000692
photographing	0.000029
understand that	0.142857
optical	0.000058
are put	0.004149
break hyphenated	0.500000
a canonical	0.001227
aims	0.000087
to judge	0.002656
New Orleans	1.000000
an urgent	0.007576
in context	0.007491
characters that	0.062500
of inflected	0.000891
as people	0.003484
a large	0.009816
ratings for	0.111111
to sort	0.001328
check	0.000058
common -LRB-	0.040000
Germany	0.000058
for document	0.003610
computer programming	0.022727
he proposed	0.142857
raters typically	1.000000
shown in	0.400000
, Robert	0.001684
75	0.000029
classifier so	0.142857
70	0.000116
for people	0.007220
prestige	0.000029
from knowledge	0.009615
to 150	0.001328
largely because	0.200000
paper ,	0.090909
paper .	0.090909
Facebook -RRB-	1.000000
more human-generated	0.010526
induction .	1.000000
chapter ,	1.000000
the art	0.001384
that builds	0.003546
inflection	0.000029
understanding to	0.060606
, Verbyx	0.000561
Ann Arbor	1.000000
, analyze	0.000561
right ,	0.100000
right .	0.300000
compiled	0.000029
to protect	0.001328
distortions -LRB-	1.000000
sentiment of	0.040000
BASEBALL and	0.500000
compiler	0.000087
English in	0.027027
English is	0.027027
discourse -RRB-	0.027778
approaches assume	0.035714
many in	0.019231
Case =	1.000000
probabilistic modeling	0.142857
signal or	0.166667
achieved	0.000290
'' that	0.021505
comparison of	0.333333
2.0 was	0.500000
candidates can	0.200000
University researchers	0.111111
unigrams placed	0.083333
numerous	0.000029
positive sentiment	0.142857
profiling	0.000029
Document summarization	0.250000
creating	0.000203
the occurrence	0.000692
requires the	0.187500
instance some	0.071429
's quality	0.019608
relying	0.000029
Keyphrase	0.000116
of major	0.000891
1971 and	0.333333
context	0.000955
the machine-learning	0.000692
in Northern	0.001873
: Neural	0.009804
as the	0.094077
political	0.000087
text fragments	0.006289
misspelled words	1.000000
assertions in	0.500000
Pragmatics	0.000029
displays .	1.000000
SVOX .	1.000000
LexRank paper	0.083333
a linear	0.002454
quite expensive	0.125000
various natural	0.055556
references -RRB-	0.500000
concentrates	0.000029
5000 or	1.000000
simple sentence	0.038462
recogniton	0.000058
evaluated	0.000203
depends on	0.875000
gained surprising	0.500000
which words	0.014493
devoted to	0.600000
Communication .	1.000000
test and	0.200000
orthography	0.000058
and geospatial	0.001445
impersonate	0.000029
and\/or aural	0.333333
grammar :	0.027027
non-linear transformations	1.000000
analysis --	0.015385
grammar .	0.108108
grammar ,	0.108108
Interlingual	0.000087
About	0.000058
literature	0.000029
recognition ''	0.016529
boundary identification	0.166667
big green	0.500000
Leeuwen ,	1.000000
the answers	0.000692
<s> Alternatively	0.001537
tonal language	1.000000
is described	0.002033
specific domains	0.047619
inference algorithm	0.250000
Dogged ''	1.000000
methods build	0.022727
stating	0.000029
pollen	0.000376
computer -LRB-	0.022727
D. Booth	0.200000
make the	0.050000
with n	0.005464
Since then	0.200000
programmed with	0.500000
however empirical	0.076923
with a	0.109290
tables	0.000087
In many	0.019048
KEA -LRB-	1.000000
the majority	0.000692
English text	0.027027
governmental	0.000029
two senses	0.034483
claimed that	1.000000
customers	0.000058
Last	0.000029
writing -RRB-	0.111111
with -LRB-	0.005464
Air	0.000087
with .	0.005464
with ,	0.005464
groups submit	0.200000
and SVOX	0.001445
are instructed	0.004149
regular expressions	1.000000
scanner and	0.333333
digitalized	0.000029
-RRB- words	0.002817
an excellent	0.007576
shapes	0.000087
of abbreviations	0.001783
essential	0.000029
recognition .	0.057851
to compare	0.005312
we use	0.022222
Recall-Oriented Understudy	1.000000
<s> Langues	0.000769
sub-committee	0.000058
recall-based to	0.500000
the EHR	0.000692
been built	0.014706
the partial	0.000692
extracting and	0.200000
-LRB- IR	0.002710
patterns ,	0.200000
because analyzing	0.033333
researched tasks	1.000000
Command	0.000058
informatics	0.000029
sizes of	0.666667
However some	0.027027
there are	0.375000
that integrated	0.003546
Evaluation The	0.111111
<s> Effective	0.000769
Statistical techniques	0.111111
that generate	0.003546
This rubric	0.015873
dialog	0.000058
ELIZA .	0.111111
relief is	1.000000
classifier for	0.142857
The objects	0.005208
process include	0.027778
degrees of	0.500000
form letters	0.050000
right information	0.100000
noun 40	0.071429
that simultaneously	0.003546
The European	0.005208
about which	0.025000
sections	0.000058
DA -RRB-	0.666667
humans possess	0.083333
criteria	0.000116
Friday have	1.000000
Google	0.000116
field which	0.037037
delta	0.000058
consist	0.000029
Bell	0.000029
A typical	0.040000
coverage of	0.333333
Yale University	0.500000
very large	0.024390
controller tasks	0.250000
discrete characters	0.333333
-RRB- hours	0.002817
specialist textbook	1.000000
-LRB- Harris	0.005420
core database	0.500000
similarity .	0.100000
The task	0.020833
phonemes .	0.166667
generates	0.000087
punctuation and	0.285714
helping	0.000029
word with	0.016667
generated	0.000434
grow without	1.000000
Cullingford ,	1.000000
both in	0.032258
into computer-understandable	0.012821
vice	0.000029
Malcolm	0.000029
-RRB- Around	0.002817
demonstrates	0.000029
once	0.000029
and lexical	0.001445
features -LRB-	0.038462
N in	0.333333
N is	0.333333
English-like command	0.333333
its lexicon	0.028571
focuses on	1.000000
it is	0.205128
dramatically	0.000029
sentiment about	0.040000
have different	0.019231
context of	0.151515
Read vs.	1.000000
work from	0.041667
context or	0.030303
This term	0.015873
systems ''	0.008929
be distinguished	0.004219
as HMM	0.003484
in speech	0.013109
documents more	0.026316
facemask	0.000029
various optimization	0.055556
given unfamiliar	0.083333
smaller	0.000203
<s> Rules	0.000769
ambiguous there	0.083333
query these	0.333333
modified	0.000029
have corpus	0.009615
appear consecutively	0.062500
work of	0.083333
DTW	0.000087
made up	0.062500
and inspired	0.001445
understand simple	0.285714
voice file	0.076923
EUROPARL ,	1.000000
capital	0.000087
in four	0.003745
OCR ''	0.040816
of accuracy	0.001783
hypothesis	0.000029
produce models	0.045455
at Birkbeck	0.029412
arguably function	0.500000
human-written texts	0.500000
: Automatically	0.009804
of estimating	0.000891
The technique	0.005208
hardly any	1.000000
not use	0.017857
<s> Of	0.000769
<s> On	0.003843
the LexRank	0.000692
other cases	0.028571
, Screenshot	0.000561
people for	0.062500
Statistical Main	0.111111
most summarization	0.017241
amount of	1.000000
performance improvements	0.055556
need as	0.047619
need at	0.047619
derivation or	0.250000
of discrete	0.000891
succeeding on	1.000000
Input	0.000058
of Lichtenstein	0.000891
computational humor	0.100000
summarise conditions	0.333333
consumption	0.000029
the conversations	0.000692
extractive	0.000203
the right	0.002076
Prolog	0.000029
trade offs	0.500000
periods or	0.333333
adjacent and	0.166667
filtered by	0.333333
on recognition	0.004717
journals -LRB-	0.500000
Disambiguation Main	1.000000
by relying	0.005714
little any	0.333333
impressive .	0.500000
mentioned above	0.166667
comprehensive survey	0.200000
anywhere	0.000029
identify .	0.083333
publish a	1.000000
all natural	0.023256
input .	0.048780
use a	0.055556
, recognizing	0.000561
stress and	0.500000
and English	0.001445
nice '	0.250000
so the	0.233333
parser for	0.062500
first major	0.060606
certain region	0.142857
typical machine-learning-based	0.111111
Caldas-Coulthard	0.000029
handover	0.000029
six	0.000058
meaning ;	0.043478
instead	0.000203
meaning .	0.086957
target -LRB-	0.090909
appraisal theory	1.000000
pursued after	1.000000
of rule-based	0.000891
Document reader	0.250000
famous early	0.333333
also known	0.086957
made more	0.125000
the specification	0.001384
would somehow	0.018868
traditionally written	0.500000
dividing speech	0.333333
multiply .	1.000000
revealing socio-psychological	1.000000
sufficient iteration	0.200000
light	0.000087
quantity .	0.333333
the ''	0.000692
only cares	0.026316
But also	0.166667
unique and	1.000000
mine the	1.000000
ways to	0.125000
a user-provided	0.001227
not represent	0.008929
, training	0.000561
of handwritten	0.000891
can occur	0.005525
Janet Kolodner	0.500000
have become	0.009615
it led	0.008547
then be	0.028571
contains a	0.100000
documents where	0.026316
To decode	0.111111
<s> Vocabulary	0.000769
clusters	0.000029
and relevant	0.001445
tasks from	0.031250
articles rarely	0.125000
organized notations	1.000000
Applications include	0.500000
material	0.000058
input characters	0.024390
they observe	0.025000
use only	0.027778
punctuation ,	0.285714
Graph This	1.000000
transformational grammar	1.000000
breathing was	1.000000
, syllables	0.000561
sense and	0.125000
bills	0.000029
substantially .	1.000000
the 2011	0.000692
, see	0.001123
related	0.000434
tasks defined	0.031250
Wendy	0.000029
80	0.000029
a global	0.001227
other aspects	0.014286
human-readable	0.000029
the following	0.004844
above --	0.076923
autopilot	0.000029
simple morphology	0.038462
plural	0.000145
real time	0.111111
maintains	0.000029
post-processing by	0.333333
additional	0.000174
fields .	0.166667
fields ,	0.333333
of 19th	0.000891
character -RRB-	0.045455
or evaluation	0.004505
search -LRB-	0.090909
, after	0.000561
five pages	0.200000
3 ,	0.200000
co-founded	0.000029
corpora ,	0.090909
3 %	0.200000
parse tree	0.111111
highly .	0.111111
a slide	0.001227
of named	0.000891
publication	0.000087
<s> Importance	0.000769
their	0.000984
word -LRB-	0.016667
Success	0.000029
be to	0.008439
Engineers	0.000058
, Thai	0.000561
of sentence-level	0.000891
peak ,	1.000000
taught the	0.666667
Ethnomethodology .	1.000000
logical representation	0.166667
its definition	0.028571
method in	0.062500
stock market	0.333333
rarity	0.000029
of pragmatics	0.000891
method is	0.062500
known cases	0.038462
the Blind	0.001384
their solutions	0.029412
two illustrates	0.034483
caused problems	1.000000
forecasts to	0.200000
as in	0.027875
certain assumptions	0.142857
features involve	0.038462
angle	0.000029
together into	0.125000
as if	0.003484
After	0.000087
; Compute	0.021277
i.e. so	0.052632
which	0.003995
for NLP	0.003610
part-of-speech ,	0.066667
Lichtenstein	0.000029
as is	0.013937
Kintsch	0.000029
principles which	1.000000
accessibility ,	1.000000
informativeness of	0.666667
corpus is	0.032258
encouraged researchers	1.000000
used as	0.044248
is clear	0.002033
the social	0.002076
used an	0.008850
spoken words	0.142857
and methodologies	0.001445
corpus in	0.064516
class	0.000116
RCA engineers	0.200000
that make	0.010638
Before getting	0.500000
, spoken	0.000561
at TWA	0.014706
co-occur at	0.500000
first and	0.030303
state computers	0.071429
the words	0.004152
wrote a	0.166667
for customisation	0.003610
affect OCR	0.333333
sentence or	0.041667
and Latin	0.001445
primary output	0.500000
from the	0.211538
simple terms	0.038462
sentence of	0.020833
US patent	0.285714
'' for	0.005376
to understand	0.003984
titled Natural	1.000000
Ken Church	1.000000
main difficulty	0.250000
of training	0.003565
The grammar	0.010417
, search	0.001123
, ID	0.000561
queries	0.000087
this procedure	0.010989
the original	0.006920
limited applications	0.100000
The difference	0.005208
module	0.000087
has dried	0.011905
on increasingly	0.004717
levels is	0.045455
levels in	0.045455
variability	0.000029
recognize speech	0.111111
studied more	1.000000
crucial to	1.000000
and align	0.001445
Server	0.000029
in Norman	0.001873
Important journals	1.000000
discourses ,	0.500000
discourse begin	0.027778
-LRB- EBMT	0.002710
immediately to	1.000000
increasing number	0.333333
databases into	0.125000
walk	0.000145
-LRB- Loriot	0.002710
Finally	0.000029
sequences	0.000261
Pang and	0.333333
table lookup	0.142857
automotive maintenance	1.000000
i.e.	0.000550
From these	1.000000
image consisting	0.333333
recommending ''	1.000000
quite distinct	0.125000
small integer	0.111111
the information	0.003460
different speaking	0.020408
negative emotions	0.125000
selecting a	0.400000
analysis has	0.015385
systems applications	0.008929
processing problems	0.018519
present	0.000174
to train	0.001328
and delta-delta	0.002890
unlike	0.000029
parse reranking	0.111111
English into	0.027027
plateaued	0.000058
tag-sets	0.000029
Organization ,	1.000000
as those	0.017422
the average	0.000692
MPE -RRB-	1.000000
benefits to	0.500000
was proposed	0.025974
semantic or	0.047619
presume a	1.000000
2002 a	0.500000
visual and\/or	0.500000
are maximum	0.004149
assigns large	1.000000
humans as	0.083333
The ideal	0.005208
gained by	0.500000
units	0.000203
to densely	0.001328
gets	0.000058
reconfiguring	0.000029
an easier	0.007576
which should	0.007246
Translations are	1.000000
automation	0.000029
by Zellig	0.005714
seminal paper	1.000000
they rephrase	0.025000
applying PageRank	0.500000
and\/or	0.000087
rules generated	0.023256
Speaker independent	0.166667
information theory	0.021739
greatly reduced	0.142857
more complex	0.084211
Using the	0.500000
are probably	0.004149
interlingua	0.000029
and reasoning	0.002890
ranking sentences	0.142857
, part-of-speech	0.001123
other academic	0.014286
rapidly growing	0.500000
`` un-supervised	0.005291
answer questions	0.033333
good search	0.076923
information that	0.021739
Brenton D.	1.000000
attractive	0.000087
words from	0.018349
grammar parsing	0.027027
, Liberman	0.000561
in multiple	0.001873
larger summarization	0.062500
, domain	0.000561
States ,	0.142857
Scope and	1.000000
trillion-word corpus	1.000000
States ?	0.142857
as easily	0.006969
summarization technology	0.020000
<s> Recently	0.000769
entertaining can	0.500000
lot of	0.333333
<s> WebOCR	0.001537
introduced the	1.000000
be expressed	0.012658
the record	0.000692
arbitrarily long	1.000000
statistical language	0.030303
but evaluation	0.014706
, distinct	0.000561
different problem	0.020408
FAA as	0.500000
usually faster	0.031250
only a	0.052632
-LRB- with	0.008130
methods already	0.022727
answering The	0.083333
word being	0.033333
difficulty in	0.285714
OCR Since	0.020408
difficulty is	0.142857
and abstraction	0.002890
For some	0.016393
van	0.000058
artifacts	0.000029
8000	0.000029
more commonly	0.021053
and Snyder	0.001445
whose theoretical	0.333333
approximates	0.000058
the web	0.001384
found no	0.071429
follows a	0.500000
IE additionally	0.333333
PCFGs -LRB-	1.000000
made	0.000463
whether	0.000376
where particular	0.028571
important topics	0.062500
accuracy above	0.032258
, room	0.000561
, coreference	0.000561
suggest valuable	0.333333
`` ASR	0.005291
valid summary	1.000000
approximated	0.000029
mutual	0.000029
is less	0.002033
documents per	0.026316
fire	0.000058
segment .	0.111111
segment ,	0.222222
task-effectiveness well	0.500000
prisoners ?	0.500000
the opposite	0.001384
NAACL ,	1.000000
ranks	0.000058
or turns-at-talk	0.004505
programs that	0.090909
may or	0.019231
but sometimes	0.014706
But then	0.166667
goal of	0.285714
pairs ,	1.000000
thought-to-paper	0.000029
a phrase	0.002454
users after	0.111111
builds up	0.500000
the president	0.001384
paper Shipibo	0.090909
, Computer	0.000561
so meaningless	0.033333
the recognized	0.001384
implicate ``	1.000000
with images	0.005464
ParaEval	0.000029
SourceForge	0.000029
`` Speech	0.005291
dictionary can	0.142857
are at	0.008299
or EHR	0.004505
-LRB- and	0.013550
morphological analysis	0.333333
Word-sense disambiguation	1.000000
second	0.000290
good results	0.076923
sentence boundary	0.062500
not been	0.017857
exactly how	0.333333
online databases	0.125000
Chafe	0.000029
specialist	0.000029
, location	0.000561
reporter	0.000029
here	0.000058
reported	0.000145
read 23	0.142857
chosen .	0.200000
conversational	0.000029
the geological	0.000692
became one	0.200000
Japanese prisoners	0.125000
intrinsic evaluation	0.500000
HLT	0.000029
reports	0.000145
capabilities were	0.200000
task often	0.023810
Recovery and	1.000000
to other	0.001328
in similar	0.001873
classification	0.000492
processes of	0.200000
brought	0.000029
each lexical	0.022222
member of	1.000000
Basic	0.000029
experience ,	0.500000
and ask	0.001445
unit	0.000087
; total	0.021277
extractive -LRB-	0.142857
like Chinese	0.071429
of whether	0.000891
carried out	0.500000
taxonomies .	1.000000
until	0.000058
usable output	1.000000
the mean	0.000692
sub-categories .	1.000000
above 95	0.076923
using shallow	0.016949
processors or	1.000000
99	0.000029
98	0.000087
Language Workshop	0.083333
90	0.000116
95	0.000116
detection of	0.500000
achieved translating	0.100000
capabilities by	0.200000
Text	0.000174
often not	0.045455
concepts	0.000145
natural-language processing	1.000000
Perspectives	0.000029
all nouns	0.023256
classification-related	0.000029
-RRB- break	0.002817
to start	0.002656
theory ,	0.307692
analysis of	0.184615
syntactic	0.000376
TextRank uses	0.142857
word use	0.016667
all alternative	0.023256
analysis on	0.015385
how	0.000840
analysis or	0.046154
MorphoChallenge	0.000029
been applied	0.088235
classify	0.000058
Formal	0.000029
A	0.001448
, stochastic	0.000561
specifically concerned	0.500000
Each article	0.166667
Schober	0.000029
`` computer	0.005291
usually operate	0.031250
which accommodate	0.007246
Brown University	0.142857
feedback	0.000058
test how	0.100000
providing a	0.500000
findings were	1.000000
the evaluators	0.000692
voice dialing	0.076923
James Paul	0.250000
matching -RRB-	0.200000
fidelity	0.000029
systems now	0.008929
The shapes	0.005208
text corpora	0.006289
most of	0.086207
programer	0.000029
Red is	1.000000
orthography .	0.500000
understanding machine	0.030303
, clean	0.000561
a lot	0.003681
quite weak	0.125000
as vertices	0.003484
fonts ,	0.333333
Plot	0.000029
caps -RRB-	1.000000
resources and	0.166667
12 \*	0.400000
<s> Telephony	0.000769
: Example-based	0.009804
Gustav	0.000029
expression and	0.200000
detection and	0.500000
disfluences -LRB-	1.000000
complex setting	0.041667
Functional grammar	1.000000
a dialogue	0.002454
sometimes preferred	0.076923
heavy-noise ,	1.000000
years -LRB-	0.047619
and makes	0.001445
being followed	0.055556
capitalize names	1.000000
has published	0.011905
's OCR	0.019608
see that	0.050000
Sonic	0.000029
such an	0.016260
similarly	0.000029
will tend	0.028571
quantity -LRB-	0.333333
such as	0.731707
a known	0.002454
ranging	0.000058
<s> While	0.002306
be NP-complete	0.004219
random walk	0.571429
language characters	0.006757
a -5	0.001227
Code	0.000029
and many	0.001445
also many	0.014493
tractability .	1.000000
by finding	0.005714
to structured	0.001328
approach involves	0.028571
\/ F-16	0.333333
-RRB- leverages	0.002817
the picture	0.001384
distinction of	0.200000
solved in	0.200000
billion words	1.000000
A corpus	0.020000
easier part	0.125000
use\/mention distinction	1.000000
implemented	0.000145
hub	0.000029
Current difficulties	0.200000
might want	0.038462
an untagged	0.007576
of morphologically	0.000891
using ,	0.016949
in 1933	0.001873
above to	0.076923
metric -LRB-	0.333333
object	0.000058
recommend ''	1.000000
systems are	0.116071
acoustic noise	0.333333
funding to	0.125000
resource such	0.200000
four different	0.285714
using a	0.169492
though much	0.100000
incomplete	0.000029
to databases	0.001328
Union	0.000029
Agency	0.000058
early as	0.100000
SIGGEN portion	1.000000
is required	0.004065
example type	0.012346
design of	0.250000
of count	0.000891
Translator	0.000029
, sentences	0.001123
that speech	0.003546
6 to	0.750000
Automatic segmentation	0.333333
adviser for	1.000000
newspaper articles	0.333333
, headlines	0.000561
started trying	0.250000
<s> Other	0.005380
decisions only	0.100000
in-principle	0.000029
is able	0.002033
release	0.000087
, GRASSHOPPER	0.000561
adjectives .	0.333333
context --	0.030303
require	0.000637
scripts -LRB-	0.666667
issue of	0.125000
issue on	0.125000
naturalness	0.000029
result	0.000318
, Michael	0.002246
to both	0.003984
Other systems	0.142857
John	0.000232
This phenomenon	0.031746
between adjacent	0.051282
, any	0.000561
controllers -LRB-	0.333333
and decelerations	0.001445
and writing	0.001445
A more	0.020000
include an	0.074074
, and	0.106120
language data	0.006757
this point	0.010989
data .	0.220779
these systems	0.119048
patented	0.000029
Text-proofing	0.000029
contribute to	1.000000
asked	0.000087
with regard	0.021858
and	0.020034
, Constraint	0.000561
the mental	0.000692
stochastic purposes	0.125000
Method	0.000029
billing	0.000029
meaning but	0.043478
Dependent	0.000029
subject of	0.250000
extractive approach	0.142857
-LRB- digital	0.002710
risk of	0.500000
do something	0.038462
already placed	0.200000
year despite	0.166667
algorithm -LRB-	0.035714
processing systems	0.055556
SRI	0.000029
This covers	0.031746
Holmes	0.000029
, Jelinek	0.000561
user about	0.071429
distinct from	0.428571
can perform	0.005525
e.g. SCU	0.017857
remembering	0.000029
weaknesses .	1.000000
employs rule-based	0.500000
characterize	0.000058
co-occur with	0.500000
importantly ,	1.000000
's first	0.019608
things	0.000087
translated as	0.250000
and smaller	0.001445
decorrelating the	1.000000
templates	0.000029
may result	0.019231
Contrary	0.000058
vary with	0.166667
that ROUGE	0.003546
tune	0.000029
usability .	1.000000
Structure ,	1.000000
, meanings	0.000561
focus to	0.142857
echoes	0.000058
a multileveled	0.001227
defined ,	0.166667
think of	0.333333
morphological distinctions	0.333333
rushing	0.000029
succeeding	0.000029
of 80	0.000891
ease	0.000029
For individuals	0.016393
successful HMM-based	0.111111
easy	0.000087
should soon	0.052632
east	0.000058
answer -LRB-	0.033333
reader .	0.200000
of keywords	0.000891
speaker dependent	0.055556
corpus -LRB-	0.032258
Pallet 1998	0.500000
seen -RRB-	0.100000
occurring	0.000029
paraphrase	0.000029
in classifying	0.001873
to pre-process	0.001328
<s> Just	0.000769
languages with	0.020000
the 93-95	0.000692
, archiving	0.000561
Warren	0.000029
appears multiple	0.200000
right	0.000290
publicly available	1.000000
System	0.000029
Frederick Jelinek	1.000000
multiple	0.000376
<s> Canada	0.000769
are different	0.004149
LILOG	0.000058
on text	0.004717
Bayes	0.000087
Pollen counts	1.000000
forward than	1.000000
on tasks	0.009434
the notion	0.001384
decide when	0.250000
de Beaugrande	0.500000
Many words	0.166667
First	0.000029
challenges .	0.500000
word delimiter	0.016667
trend to	1.000000
the notable	0.000692
Scotland	0.000145
scholars -LRB-	0.500000
limit the	0.500000
but not	0.058824
returning a	1.000000
the fidelity	0.000692
though it	0.200000
offer	0.000029
Furthermore ,	1.000000
extraction Task	0.032258
project compared	0.153846
the part-of-speech	0.000692
summaries and	0.046512
Liberman M.	1.000000
location ,	1.000000
and interjection	0.001445
considered	0.000261
UK dealing	0.250000
coherent discourse	0.200000
steer-point coordinates	1.000000
new data	0.041667
and treat	0.001445
-- are	0.080000
inclusion in	1.000000
verifiability	0.000029
contain rules	0.083333
grammatical	0.000318
Intelligence ''	0.333333
large text	0.043478
levels ,	0.045455
levels .	0.045455
a similar	0.001227
, research	0.001123
articles or	0.250000
the set	0.001384
human-readable address	1.000000
articles on	0.125000
or Continuous	0.004505
100000 may	1.000000
steps ,	0.500000
present special	0.166667
time	0.000955
patient ''	1.000000
the major	0.001384
Inc. in	0.500000
Lee Pike	1.000000
pars -LRB-	1.000000
see what	0.050000
interlingual ,	0.250000
Desktop	0.000029
It approaches	0.026316
machine-learning algorithms	0.250000
processing in	0.037037
analysts not	0.500000
've just	0.500000
task because	0.023810
1960s and	0.333333
tools starts	0.166667
processing is	0.037037
Stanford ,	0.500000
Discursive	0.000029
mainly evaluation	0.166667
to Recognize	0.001328
data was	0.012987
of NLG	0.000891
base of	0.250000
various fine	0.055556
find that	0.076923
base or	0.250000
word-forms are	1.000000
of NLP	0.004456
a full-text	0.001227
and end	0.001445
issues are	0.200000
findings	0.000029
what class	0.031250
meteorologist -RRB-	1.000000
in ``	0.005618
was by	0.025974
commercial efforts	0.181818
1965 it	0.250000
have in	0.019231
harmonic mean	1.000000
learning is	0.023256
processes implemented	0.200000
source software	0.041667
basic knowledge	0.076923
deterministic problem	0.250000
-LRB- An	0.005420
was higher	0.012987
alone	0.000116
along	0.000058
Computational	0.000087
Associated	0.000029
corpora of	0.090909
flight ''	0.500000
'' -RRB-	0.096774
vectors	0.000087
corpora on	0.090909
life ?	0.250000
they disagree	0.025000
Finally ,	1.000000
life .	0.250000
the entity	0.000692
prefer	0.000058
a set	0.017178
resolution remains	0.250000
processing group	0.018519
<s> Types	0.001537
be detected	0.004219
not functioning	0.008929
training on	0.035714
on SourceForge	0.004717
'' tagging	0.005376
by creating	0.005714
answer candidate	0.033333
less -RRB-	0.083333
, Abney	0.000561
validity	0.000029
Constraints	0.000087
passage web	1.000000
tends to	1.000000
end abruptly	0.125000
printing	0.000029
Text grammar	0.166667
domotic	0.000029
the Sparkle	0.000692
effort should	0.250000
Single Word	1.000000
or the	0.040541
The goal	0.005208
divided	0.000087
High-order	0.000029
lines segments	0.333333
also possible	0.043478
divider	0.000029
results for	0.047619
qualitatively The	1.000000
making decisions	0.142857
essay scoring	1.000000
explored	0.000058
and thus	0.004335
such	0.003561
stress	0.000058
and weaknesses	0.001445
truck	0.000029
you say	0.076923
translation software	0.040541
Typhoon currently	1.000000
course	0.000087
the highest	0.000692
, sociology	0.000561
assume no	0.500000
produce both	0.045455
Natural language	0.692308
derive	0.000058
Telephony and	1.000000
it proved	0.008547
additional features	0.166667
sentence-ending	0.000029
include papers	0.037037
errata ,	1.000000
means Category	0.166667
from multimedia	0.009615
linguists can	0.333333
Overview of	1.000000
context -LRB-	0.060606
many keyphrases	0.019231
copy the	1.000000
web site	0.250000
can both	0.005525
those using	0.045455
predefined	0.000029
sentences of	0.026316
-RRB- provides	0.002817
1,000 words	0.500000
example through	0.012346
sentences or	0.013158
written for	0.038462
by Joseph	0.005714
quite	0.000232
besides	0.000029
words --	0.009174
's annual	0.019608
training	0.000811
programming	0.000145
routed	0.000058
The essential	0.005208
massive	0.000029
to high	0.003984
<s> We	0.005380
ATC	0.000145
ATN	0.000029
thus require	0.100000
accuracy rate	0.064516
Isolated	0.000058
textual	0.000145
in other	0.009363
called evaluation	0.111111
heuristics with	0.500000
structured	0.000174
to provide	0.005312
and development	0.002890
draft	0.000058
of newspaper	0.000891
surrounding words	0.400000
might also	0.038462
EAGLi	0.000029
is becoming	0.002033
simulators	0.000029
two categories	0.034483
This device	0.015873
inventor	0.000029
some linguistic	0.012048
standardised	0.000029
with human-made	0.005464
segments besides	0.200000
often required	0.022727
sad	0.000029
say	0.000203
records is	0.250000
testing is	0.200000
called grammatical	0.055556
Pointwise Mutual	1.000000
saw	0.000029
12 ,	0.200000
in Italy	0.001873
may depend	0.019231
note	0.000029
Important	0.000029
spending limit	1.000000
Writing	0.000029
, called	0.000561
a different	0.003681
and phonemes	0.001445
-LRB- AFTI	0.002710
be processed	0.004219
multilingual corpus	0.333333
in more	0.001873
pages	0.000203
known summaries	0.038462
or by	0.004505
features making	0.038462
before -RRB-	0.333333
help understand	0.111111
words or	0.064220
thirty years	1.000000
coverage ,	0.333333
coverage .	0.333333
tract length	1.000000
for database	0.003610
describe a	0.166667
within documents	0.055556
latent semantic	1.000000
A popular	0.020000
slot	0.000029
weapons	0.000029
Other tasks	0.142857
intrinsic and	0.250000
Weaver wrote	1.000000
, although	0.002246
going	0.000116
Yes\/No vs.	1.000000
<s> Multilingual	0.000769
digitize	0.000029
computers to	0.111111
-- discourse	0.040000
score if	0.166667
settings	0.000029
have taken	0.009615
system would	0.021505
syntactic features	0.076923
when inter-annotator	0.028571
where	0.001013
for without	0.003610
their translation	0.029412
from Fully	0.009615
relevance theory	0.333333
expended to	1.000000
consecutive years	0.500000
new wave	0.041667
example The	0.012346
is an	0.020325
programming languages	0.600000
smaller lexical	0.142857
rule-based and	0.142857
QA It	0.047619
Bush 's	0.500000
evaluation can	0.037037
created rules	0.142857
segmentation that	0.030303
<s> Schools	0.000769
be selected	0.004219
gets about	0.500000
Pang showed	0.333333
One approach	0.076923
personal digital	0.250000
Bush ''	0.500000
specialised document	0.500000
The management	0.005208
the actual	0.002076
a toy	0.002454
large amount	0.043478
credit card	1.000000
the proposed	0.001384
process Main	0.027778
working in	0.285714
measure than	0.090909
world with	0.066667
-LRB- how	0.008130
generation techniques	0.111111
Comparing	0.000029
measure that	0.090909
transformations .	0.500000
NLP comprises	0.021277
graph using	0.076923
cosine	0.000087
still ''	0.066667
observe patterns	1.000000
limited amounts	0.100000
evaluation might	0.018519
meeting summarization	1.000000
G-loads	0.000029
, LexRank	0.000561
context-free approximation	0.090909
coughing	0.000029
Additional aspects	1.000000
Coreference resolution	1.000000
lexicon reached	0.111111
approach has	0.028571
on to	0.009434
called ISO\/TC37\/SC4	0.055556
relic	0.000029
highest ROUGE-1	0.333333
hurts ''	0.500000
.5 decision	1.000000
quantities of	0.666667
learn from	0.076923
by looking	0.005714
formalism	0.000029
corpus as	0.032258
considered .	0.111111
, Adam	0.000561
approach -RRB-	0.057143
is seen	0.002033
Although it	0.125000
Naive Bayes	1.000000
has many	0.023810
stage using	0.200000
naval resource	0.666667
`` random	0.005291
of Generation	0.000891
identities of	1.000000
the distinctive	0.000692
considered a	0.111111
recognizers have	0.500000
milliseconds .	0.500000
new ,	0.041667
the special	0.000692
option .	1.000000
distinct vowels	0.142857
Pennsylvania in	1.000000
geological	0.000029
the summaries	0.002768
particularly difficult	0.200000
as one	0.006969
publications .	1.000000
1977 -RRB-	1.000000
the broken	0.000692
to direct	0.001328
a lexicon	0.002454
by which	0.005714
equal to	1.000000
marker vs.	1.000000
transcended	0.000029
sampling	0.000029
from 10,000	0.009615
occur together	0.200000
parsing accuracy	0.035714
and simulation	0.001445
CSR -RRB-	0.666667
stationary	0.000203
size and	0.333333
primarily by	0.500000
levels as	0.045455
speaking computer	0.125000
so forth	0.033333
is copied	0.002033
entered the	0.500000
such accuracy	0.008130
objectives of	0.500000
Ratliff	0.000029
hand-written	0.000203
scientific	0.000058
power	0.000116
each dictionary	0.022222
Rajman M.	1.000000
read aloud	0.142857
yet been	0.500000
<s> Last	0.000769
This includes	0.015873
gradually reduced	1.000000
`` features	0.005291
<s> Instead	0.001537
sub-field of	1.000000
-RRB- are	0.008451
been undertaken	0.014706
Message	0.000029
patterns would	0.200000
reflect a	1.000000
off-line	0.000029
not lead	0.008929
have shown	0.009615
ways in	0.125000
Collection	0.000029
the area	0.001384
tagset	0.000029
a classifier	0.001227
for Speech	0.003610
case-based	0.000029
for further	0.010830
complete	0.000029
SHRDLU ,	0.166667
Full of	1.000000
Research Institute	0.125000
technologies	0.000116
capitalization may	0.333333
-LRB- e.g.	0.102981
reasoned	0.000029
phrases that	0.062500
<s> Overview	0.001537
rules by	0.023256
expansion of	0.333333
also an	0.014493
eigenvector	0.000058
an abstractive	0.015152
linear-time	0.000029
word recognition	0.016667
certain	0.000203
in itself	0.001873
How	0.000203
algorithm like	0.035714
noting that	1.000000
Howarth	0.000029
method and	0.062500
unigrams appear	0.083333
Systems corp.	0.083333
noun -LRB-	0.071429
Nunan ,	1.000000
that match	0.003546
Wide	0.000116
graphs and	1.000000
or Auto	0.004505
document\/text	0.000058
to existing	0.001328
Once examples	0.200000
a team	0.001227
Street	0.000087
cases and	0.055556
intervention :	1.000000
splicing	0.000029
consider	0.000116
- not	0.062500
expensive task	0.142857
`` to	0.010582
postal code	1.000000
by paying	0.005714
edges after	0.142857
Wodak	0.000029
the EARS	0.000692
undercarriage ,	1.000000
different from	0.122449
characters which	0.125000
subjectivity\/objectivity	0.000029
commercial system	0.090909
1,500	0.000029
a Computer	0.001227
and composing	0.001445
computationally feasible	0.500000
attempts to	0.500000
unigram	0.000145
the Sociologist	0.000692
book -LRB-	0.250000
points out	0.500000
Shallow parsing	0.500000
in supervised	0.001873
growing interest	0.500000
approach ;	0.028571
psychologist .	1.000000
approach .	0.057143
dictionary-based machine	1.000000
`` entities	0.005291
developments of	0.333333
counselling -RRB-	1.000000
text map	0.006289
used to	0.194690
text may	0.006289
heteroscedastic linear	1.000000
German and	0.250000
method	0.000463
revealing	0.000029
sound should	0.100000
complexity while	0.083333
the purpose	0.001384
be labeled	0.004219
`` Fundamentals	0.010582
results demonstrate	0.047619
, Ingria	0.000561
annual Document	0.500000
significant complexity	0.111111
first layer	0.030303
social	0.000405
concerned	0.000145
via	0.000029
obtained by	0.571429
5 %	0.500000
select	0.000174
one that	0.015385
that attempt	0.003546
objectives	0.000058
engines to	0.333333
Russian	0.000058
English has	0.054054
containing several	0.125000
the peak	0.000692
: Natural	0.009804
if in	0.071429
if it	0.071429
quality of	0.500000
that characterize	0.003546
adjust\/correct	0.000029
Content	0.000029
telephony	0.000087
by standard	0.005714
be resolved	0.004219
late Claude	0.111111
and methods	0.001445
available and	0.058824
sent	0.000029
converts	0.000029
sailor !	0.200000
Machine translation	0.555556
ACL Anthology	0.500000
vendors began	0.250000
from non	0.009615
generating too	0.200000
way --	0.041667
approach applies	0.028571
text used	0.006289
page count	0.142857
than has	0.022222
transducer ,	0.500000
, opens	0.000561
plant	0.000029
, science	0.000561
an action	0.007576
Teun A.	1.000000
glass-box	0.000058
12 categories	0.200000
checked each	0.500000
shop or	1.000000
out .	0.071429
regardless of	1.000000
is parsing	0.002033
passages	0.000058
trade	0.000058
attitude	0.000058
its	0.001013
features	0.000753
includes mainly	0.142857
rapidly	0.000058
Application-Oriented	0.000058
one according	0.015385
toolkit -RRB-	0.500000
-LRB- HMMs	0.005420
are in	0.012448
, reading	0.000561
repetitive .	0.500000
currently require	0.142857
aimed at	1.000000
momentum for	1.000000
One might	0.076923
broad agreement	0.250000
database look-up	0.100000
helicopters is	0.500000
but those	0.014706
camp with	0.500000
letter shapes	0.333333
limiting the	1.000000
warped	0.000029
dynamic motion	0.200000
Convert chunks	0.500000
further speaker	0.125000
not consistently	0.017857
use lexical	0.027778
of these	0.009804
assumptions ,	0.200000
computer forecasts	0.022727
eigenvalue 1	1.000000
really	0.000029
features ?	0.038462
Ernesto Laclau	1.000000
to change	0.001328
the surrounding	0.001384
features .	0.076923
accidentally omitted	1.000000
worked ,	0.200000
first approximation	0.030303
IR	0.000087
, engaging	0.000561
semiotic	0.000029
cockpit	0.000058
Some speech	0.047619
simple data	0.038462
represent as	0.111111
with boundary	0.005464
using unweighted	0.016949
a corporation	0.001227
Latin-script ,	1.000000
Charniak	0.000029
with having	0.005464
exhibited	0.000029
major	0.000347
states that	0.250000
for those	0.007220
differ	0.000087
<s> Later	0.000769
should indicate	0.052632
human kind	0.021739
syllables	0.000058
physicians who	1.000000
James A.	0.500000
of summaries	0.003565
-LRB- Some	0.002710
approach described	0.028571
Street .	0.333333
College at	0.500000
by adding	0.011429
natural -RRB-	0.013333
vocal	0.000029
hence need	0.500000
`` processing	0.010582
be put	0.004219
from those	0.019231
uses a	0.285714
previous questions	0.333333
the bi-directional	0.000692
and dictionary-based	0.001445
with no	0.010929
is processed	0.002033
tasks implemented	0.031250
approaches to	0.178571
in several	0.003745
W. Handel	0.500000
mechanized sorting	1.000000
keyphrases will	0.028571
user has	0.071429
understood only	1.000000
In 1965	0.009524
selected as	0.500000
uses .	0.071429
JAS-39 Gripen	1.000000
into more	0.025641
In 1969	0.019048
speaker normalization	0.055556
if-then rules	1.000000
in English	0.009363
Wikipedia 's	0.500000
out other	0.071429
Audio ,	0.500000
Jef Verschueren	1.000000
slow speech	0.500000
formalization of	0.500000
United	0.000261
system needs	0.043011
soon .	0.333333
total accuracy	0.500000
mentioned by	0.166667
creating systems	0.142857
lexical exigencies	0.076923
LexRank differences	0.083333
captures	0.000029
further condensation	0.125000
the definition	0.002076
dependent	0.000087
relations between	0.416667
of ambitious	0.000891
a domain-specific	0.001227
many systems	0.019231
<s> Approaches	0.002306
words to	0.009174
that deals	0.003546
makes intuitive	0.125000
systems existing	0.008929
-LRB- Nuance	0.002710
masculine ,	1.000000
the book	0.001384
Inter-rater	0.000029
`` open	0.005291
Liberman	0.000029
Examples include	0.333333
word sequences	0.016667
implemented ,	0.200000
Amplitude -LRB-	1.000000
underlie the	1.000000
movie	0.000087
currently	0.000203
rejecting	0.000087
verbs	0.000145
Jan Blommaert	1.000000
basic level	0.076923
times in	0.200000
collections of	0.250000
`` training	0.005291
open-access	0.000029
superimpose	0.000029
linguistic competence	0.062500
termed ``	0.500000
interface	0.000116
<s> Scope	0.000769
These range	0.058824
are language-specific	0.004149
improved	0.000116
proved similarly	0.333333
in linguistic	0.003745
, key	0.000561
useful review	0.071429
analyzing the	0.200000
for computer	0.010830
as short	0.003484
Each word	0.166667
written without	0.038462
for using	0.003610
below -RRB-	0.400000
an automated	0.007576
publishing	0.000029
time warping	0.121212
find an	0.153846
Edges are	1.000000
or electronic	0.004505
between successive	0.025641
are available	0.008299
an error	0.007576
great	0.000087
you 've	0.153846
it accepts	0.008547
Starting	0.000029
rescore lattices	1.000000
handling	0.000058
free as	0.250000
socio-psychological characteristics	1.000000
`` Dog	0.005291
the gold	0.002076
optimization	0.000029
Brill 's	0.333333
evaluating	0.000145
forecasts from	0.200000
very difficult	0.048780
styles	0.000029
hoping	0.000029
producing more	0.333333
calculator	0.000058
just as	0.222222
alphabetic heritage	1.000000
connected text	0.200000
triple	0.000029
Category :	0.500000
not context-free	0.008929
Category =	0.500000
place to	0.250000
while Carnegie	0.050000
Turney paper	0.222222
computers for	0.111111
system using	0.010753
Hands-free	0.000029
shorter	0.000058
virtually	0.000058
has little	0.011905
types ,	0.071429
reporting -RRB-	0.333333
common ground	0.040000
unlabeled	0.000029
routing bar	0.333333
scientists ,	1.000000
Navigation Systems	1.000000
summers of	1.000000
Consider the	1.000000
randomly chosen	1.000000
choice between	0.125000
serve other	0.200000
engines such	0.333333
planning an	0.500000
Processes may	1.000000
somehow internalize	1.000000
to words	0.001328
garden path	1.000000
discriminative training	1.000000
massive collections	1.000000
human ratings	0.086957
communicative	0.000087
prune away	1.000000
extractor follows	0.500000
source .	0.041667
source -	0.041667
source ,	0.041667
real-world data	0.333333
constituents ,	0.500000
signals	0.000058
phenomenon of	0.600000
Coulthard	0.000029
input	0.001187
linguistic research	0.062500
database available	0.100000
1933 -LRB-	1.000000
action applied	0.200000
WYSIWYM framework	1.000000
projects	0.000058
either positive	0.100000
either as	0.300000
trained on	0.333333
getting published	0.250000
, reasoning	0.000561
and Ken	0.001445
either an	0.100000
pertaining	0.000029
as Penn	0.003484
documents have	0.026316
Bar-Hillel	0.000029
volume and	0.250000
has gone	0.011905
broadband	0.000029
lexer would	1.000000
contrast to	0.250000
complex sounds	0.041667
Deirdre Wilson	1.000000
systems in	0.008929
performance only	0.055556
dictates	0.000058
pages .	0.285714
pages ,	0.428571
Brown Corpus	0.857143
systems is	0.026786
details the	0.500000
segmentation In	0.030303
2010 and	0.333333
technology also	0.045455
pre-process	0.000029
assertive -LRB-	1.000000
repeated as	0.500000
their similarity	0.029412
handheld scanner	1.000000
the grammar	0.006228
Programming languages	0.666667
requires expansion	0.062500
appropriate	0.000116
called a	0.055556
evaluation :	0.037037
spending	0.000029
-- in	0.040000
submit	0.000058
custom	0.000058
-RRB- work	0.002817
by question	0.005714
:	0.002953
words of	0.027523
<s> Goldberg	0.000769
improved their	0.250000
temporal and	0.500000
Royal Aerospace	0.500000
Potentially ,	1.000000
pattern .	0.166667
model for	0.066667
the American	0.001384
that scans	0.003546
1960s were	0.333333
Office	0.000029
got about	1.000000
word of	0.016667
verification	0.000029
continuously	0.000029
Adda 1999	0.500000
Conference Evaluation	0.500000
frequently formalized	0.500000
translated in	0.250000
dependency theory	0.200000
its domain	0.057143
QA system	0.238095
translated it	0.250000
makes tagging	0.125000
relative probability	0.333333
These are	0.117647
, length	0.000561
invalid	0.000029
is essentially	0.006098
becomes easier	0.500000
division of	0.500000
of translating	0.000891
elements	0.000116
Querying	0.000029
, each	0.003369
languages have	0.040000
<s> Running	0.000769
select individual	0.166667
fighter	0.000174
semantically constrained	1.000000
or text	0.009009
, Judith	0.000561
examples of	0.208333
II -LRB-	0.500000
partial	0.000029
illustrates	0.000058
potentially unlimited	0.333333
most suitable	0.017241
existing	0.000145
now rely	0.076923
also Machine	0.014493
centers	0.000029
a startlingly	0.001227
Michael Schober	0.250000
reasonable chance	0.500000
reCAPTCHA	0.000029
checking that	1.000000
In the	0.133333
idea that	0.285714
provides	0.000058
utterance and	0.333333
continues	0.000029
printed by	0.083333
, tag	0.000561
continued	0.000261
voice than	0.076923
negligibly rare	1.000000
two extremes	0.034483
Post has	0.500000
language with	0.006757
program with	0.045455
odd	0.000058
observation .	1.000000
be digitalized	0.004219
in simple	0.001873
look ''	0.200000
databases .	0.500000
by Henry	0.005714
significant task	0.111111
ATC -RRB-	0.200000
such a	0.048780
proliferation	0.000029
any markup	0.032258
respectively	0.000029
for American	0.003610
adaptation .	0.666667
, turns	0.000561
consideration	0.000087
, explanation	0.000561
of 1928	0.000891
IR -RRB-	0.333333
<s> Imagine	0.000769
involved	0.000174
numbers which	0.142857
opinion	0.000145
rate of	0.272727
involves	0.000290
proposed by	0.111111
1999 L'action	0.500000
or desired	0.004505
topic by	0.125000
weaker	0.000029
candidates so	0.200000
tools	0.000174
to bridge	0.001328
practically available	1.000000
evaluation .	0.055556
evaluation ,	0.055556
best path	0.055556
Lakoff	0.000029
-- is	0.040000
outputting language	0.500000
duplicate	0.000058
were printed	0.024390
svg This	1.000000
-- if	0.080000
experiment in	0.200000
then use	0.028571
Wallace Chafe	1.000000
successive words	0.500000
Iraq in	0.500000
or Spanish	0.004505
recognition-related	0.000029
Therein	0.000029
this	0.002635
prefer the	0.500000
pour	0.000029
entries for	0.500000
fulfill	0.000058
knowledge frequently	0.037037
you must	0.076923
with known	0.010929
can often	0.005525
purposes	0.000116
pieces	0.000029
as semantic	0.003484
Christmas	0.000029
a character	0.001227
the resulting	0.001384
Extraction techniques	0.333333
the Canadian	0.001384
art for	0.500000
characterised by	1.000000
singular	0.000116
tied	0.000029
separators -RRB-	1.000000
left ,	0.166667
processed documents	0.166667
on personal	0.004717
Apple	0.000029
approach which	0.057143
<s> Beatrice	0.000769
earliest-used machine	0.500000
redundant	0.000029
or	0.006427
substantial financial	0.200000
produces	0.000116
male-female normalization	1.000000
and linguistics	0.002890
produced	0.000261
comprehension .	0.428571
comprehension ,	0.142857
democracy .	1.000000
something similar	1.000000
, styles	0.000561
high as	0.055556
high at	0.055556
example-generation strategy	1.000000
phrases and	0.187500
a readable	0.001227
are unable	0.004149
In information	0.009524
<s> Was	0.000769
Speech When	0.032258
see references	0.050000
separators	0.000029
must appear	0.071429
parsing refers	0.035714
function words	0.125000
contrast -RRB-	0.125000
translating .	0.250000
parser attempts	0.062500
are focused	0.004149
achieving high	0.500000
doing	0.000058
Processing -RRB-	0.250000
static	0.000029
-LRB- Meehan	0.002710
consideration the	0.333333
problem was	0.022727
output -RRB-	0.038462
start of	0.285714
comprising context	0.500000
if and	0.035714
the accompanying	0.000692
and Callaghan	0.001445
an instance	0.007576
statistical ;	0.030303
East Asian	1.000000
lexer	0.000029
Jump	0.000029
for this	0.018051
is always	0.004065
phrase begin	0.100000
basis of	0.666667
apparent	0.000029
has never	0.023810
even articles	0.037037
AI-complete ''	0.666667
'' might	0.010753
extrinsic	0.000174
with his	0.005464
ATC situation	0.200000
testing	0.000145
a time	0.002454
digital camera	0.142857
final keyphrases	0.222222
<s> Recognition	0.001537
bites man	0.333333
stems in	0.500000
2 ''	0.200000
phrases supported	0.062500
Use of	0.500000
the name	0.001384
famous article	0.333333
: Separate	0.019608
Workshop	0.000029
machine translation	0.493671
radiology	0.000029
Voice2Go	0.000029
capital letters	0.333333
with respect	0.038251
viewed	0.000116
with thought-to-paper	0.005464
obtained a	0.285714
language comprehension	0.006757
the impossibility	0.000692
Hulth	0.000087
showed how	0.250000
allow	0.000145
large amounts	0.043478
also called	0.043478
device	0.000058
sentences instead	0.013158
more principled	0.010526
Penpoint OS	1.000000
Descartes	0.000029
more than	0.042105
Homayoon Beigi	1.000000
obtained .	0.142857
texts from	0.058824
fairly simple	0.250000
it in	0.008547
atmosphere	0.000029
this example	0.010989
terminate	0.000029
to clarify	0.001328
gaming and	1.000000
restrictions .	1.000000
The CyberEmotions	0.005208
trivial	0.000116
difficult ,	0.035714
difficult .	0.071429
`` shallow	0.005291
domains where	0.125000
Terry Winograd	1.000000
e.g. stating	0.017857
express the	0.400000
the extraction	0.002768
emigre Leo	1.000000
transmitting by	1.000000
<s> Performing	0.000769
polynomial time	1.000000
to digitize	0.001328
the form	0.000692
Polar Lander	1.000000
characters can	0.187500
currently .	0.142857
intervening	0.000029
of complexity	0.000891
normalization .	0.333333
The algorithm	0.005208
individual words	0.083333
glass-box evaluation	1.000000
ATN -RRB-	1.000000
untrained on	1.000000
standard method	0.071429
we can	0.066667
where phrases	0.028571
other modifying	0.014286
UK .	0.500000
`` Translation	0.005291
<s> Work	0.001537
closed-domain	0.000029
named Interspeech	0.142857
<s> Word	0.003843
for part-of-speech	0.007220
e.g. yes-no	0.017857
found by	0.071429
same person	0.040000
their underlying	0.029412
original source	0.076923
he talking	0.142857
equivalent ideas	0.200000
<s> Among	0.000769
edge between	0.333333
<s> Example-based	0.000769
and obtained	0.001445
and Semantic	0.001445
not 100	0.008929
: David	0.009804
causes a	1.000000
of phrase	0.000891
preliminary approach	0.333333
accuracy in	0.032258
Example-based	0.000087
offering WebOCR	1.000000
an adjective	0.037879
question classifier	0.023810
, propositions	0.001123
Verschueren ,	1.000000
modeling and	0.142857
's opinions	0.019608
start to	0.142857
article such	0.034483
cope	0.000029
by Xuedong	0.005714
and syntax	0.001445
phrases to	0.062500
conflicting	0.000029
a series	0.007362
the intended	0.001384
Medical	0.000058
upon	0.000029
formalized in	1.000000
Eurospeech\/ICSLP	0.000029
points of	0.500000
expand	0.000029
which he	0.007246
mark the	0.333333
Command Success	0.500000
Challenges	0.000029
costs -LRB-	1.000000
b -RRB-	1.000000
this book	0.010989
parsers were	0.076923
negligence	0.000029
less	0.000347
a complex	0.006135
it about	0.008547
separate field	0.100000
Callaghan	0.000029
lattice	0.000029
There has	0.181818
the 70	0.000692
coordinates and	1.000000
or quantities	0.004505
programs have	0.090909
increased	0.000145
human geography	0.021739
pioneered at	0.333333
increases	0.000058
five	0.000145
a result	0.003681
supervised extractive	0.062500
Systems released	0.166667
a linguistic	0.002454
began to	0.571429
the possibility	0.002768
his visit	0.083333
an era	0.007576
<s> Important	0.000769
quality and	0.100000
included as	0.125000
helps doctors	0.500000
only rely	0.026316
sufficiently	0.000029
and corrected	0.001445
does	0.000290
democratizing data	0.500000
Harrison P.	1.000000
Cognitive Systems	0.333333
resources it	0.166667
of cepstral	0.000891
noun than	0.071429
and compare	0.002890
metrics used	0.111111
and typical	0.001445
garden-path sentences	1.000000
easier than	0.250000
often used	0.022727
recognition tasks	0.016529
articles ,	0.125000
insufficient	0.000058
often uses	0.022727
computerized language	0.500000
waves are	0.142857
from systems	0.009615
BLEU	0.000087
contractions	0.000058
NLP and	0.021277
Extrinsic	0.000058
included	0.000232
about 30	0.025000
Network	0.000029
speech commands	0.006579
paper -RRB-	0.090909
networks can	0.071429
The Army	0.005208
positive or	0.285714
emails and	0.500000
potentially exponential	0.333333
roughness ,	1.000000
components .	0.200000
systems which	0.017857
this level	0.010989
the food	0.000692
informational	0.000058
together ?	0.125000
would run	0.037736
together ,	0.125000
together .	0.125000
disagree that	0.333333
incorrect letters	0.333333
unstructured text	1.000000
is leading	0.002033
due both	0.400000
several quality	0.045455
very preliminary	0.024390
global '	0.333333
be either	0.004219
scholars have	0.500000
<s> Using	0.001537
chance	0.000029
requires one	0.062500
this problem	0.076923
Context	0.000029
automatically generated	0.142857
<s> By	0.000769
above are	0.076923
shallow methods	0.166667
main ideas	0.125000
rule	0.000087
As the	0.055556
what original	0.031250
then compute	0.028571
global `	0.333333
Subsumption -LRB-	1.000000
star scale	0.500000
relationships	0.000174
votes	0.000029
much less	0.045455
Automatic	0.000261
Independent ''	1.000000
relic of	1.000000
wave as	0.111111
enough for	0.200000
eliminate redundancy	0.500000
have human-made	0.009615
method based	0.125000
as its	0.010453
phones	0.000058
<s> Early	0.001537
Isles and	1.000000
retrieval -LRB-	0.142857
noun ,	0.428571
used varies	0.008850
mentioned earlier	0.333333
when annotating	0.028571
turned into	1.000000
time question	0.030303
a rules	0.001227
consisting	0.000058
and is	0.008671
and it	0.007225
-LRB- so	0.005420
In France	0.019048
and if	0.001445
designed to	0.714286
and in	0.010116
Technology -LRB-	0.333333
very similar	0.097561
often continues	0.022727
at hand	0.014706
Home	0.000029
Digitize the	1.000000
discontinuous	0.000087
a degree	0.001227
NIST 's	0.500000
Health	0.000058
that aid	0.003546
PARRY	0.000029
review as	0.333333
then it	0.057143
garden-path	0.000029
as WordNet	0.003484
Star	0.000029
information to	0.086957
substitutions	0.000029
example is	0.012346
Meaningful Use	1.000000
training organizations	0.035714
`` words	0.005291
LexRank score	0.083333
Smartphones	0.000029
supported by	1.000000
confused with	1.000000
of smoothing	0.000891
<s> Sound	0.001537
look -LRB-	0.200000
been developed	0.014706
, as	0.012914
of pollen	0.001783
word	0.001737
input with	0.024390
1629	0.000029
work	0.000695
style and	0.500000
copied despite	0.500000
an abbreviation	0.007576
neat ,	1.000000
LILOG ,	0.500000
also used	0.028986
a kind	0.001227
cited	0.000029
the generation	0.000692
groups at	0.200000
hyphenated	0.000029
simple demonstrations	0.038462
Digital	0.000029
Deese	0.000029
known word	0.038462
to keep	0.002656
Journal	0.000087
exponential number	0.500000
into readable	0.012821
disappear	0.000029
machine reading	0.012658
just robustness	0.111111
The most	0.026042
can start	0.005525
user-specified fraction	0.500000
Frost ,	1.000000
difficulties in	0.500000
meaningful	0.000232
1928 the	1.000000
data of	0.012987
Software -LRB-	0.500000
and both	0.001445
data on	0.012987
address of	0.250000
According to	1.000000
being developed	0.055556
order	0.000405
accurately -LRB-	0.500000
parameter estimation	1.000000
linguistic typology	0.062500
theory of	0.076923
special image	0.200000
or speech	0.004505
an EMR	0.007576
terms in	0.076923
Xerox	0.000058
As access	0.055556
cursive text	0.200000
talking about	1.000000
An important	0.125000
mid-90s .	1.000000
eventually	0.000029
languages contain	0.020000
break	0.000058
President	0.000116
, generally	0.000561
chance of	1.000000
Control	0.000029
recognition but	0.008264
particularly speech	0.200000
The poor	0.005208
search corpus	0.090909
what is	0.093750
science convention	0.100000
structuring :	1.000000
prior attempts	0.333333
integrating speech	1.000000
items .	0.500000
when describing	0.057143
for any	0.003610
are often	0.016598
network	0.000174
static shape	1.000000
published his	0.142857
which accepts	0.007246
on lexicon	0.004717
evaluation approach	0.018519
Inuit virtually	1.000000
Naturally	0.000029
grammar can	0.027027
Loriot &	1.000000
could be	0.250000
Art Graesser	1.000000
<s> Beginning	0.000769
particular words	0.076923
commercially	0.000058
parsing have	0.035714
businesses look	0.500000
done both	0.090909
following :	0.133333
National	0.000087
the 1980s	0.001384
following .	0.133333
date -LRB-	0.666667
a subsystem	0.001227
is because	0.002033
within their	0.055556
dimensionality reduction	1.000000
discriminant analysis	1.000000
rated	0.000029
developing text	0.250000
opportunity	0.000058
and Nearest-neighbor	0.001445
rates	0.000232
predicted value	0.500000
the media	0.000692
version of	0.666667
sequences ,	0.111111
sequences .	0.222222
grammar that	0.027027
into methods	0.012821
target	0.000318
the goal	0.002768
tackles	0.000029
that underlies	0.003546
; Computed	0.021277
rewrite	0.000029
, plural	0.000561
Like the	0.500000
A speaker	0.040000
network to	0.166667
`` main	0.005291
Instead	0.000087
Garfinkel	0.000029
to low	0.001328
Kittredge &	0.500000
both research	0.032258
concerns finding	0.500000
like ``	0.107143
the system	0.013841
recognized essentially	0.166667
materials	0.000058
and some	0.002890
some summarization	0.012048
Error Rate	0.500000
, Winograd	0.000561
-LRB- semi	0.002710
effective and	0.166667
Statistical natural-language	0.111111
' could	0.052632
though this	0.100000
optimizes	0.000029
poorly defined	1.000000
William A.	0.500000
structured speech	0.166667
optimized	0.000029
phase	0.000029
stating that	1.000000
his wingmen	0.083333
than in	0.022222
<s> On-line	0.002306
evaluation process	0.018519
had to	0.071429
or generated	0.004505
automatizing the	1.000000
Helicopters	0.000029
Automatic translation	0.111111
Main article	1.000000
two conflicting	0.034483
ParaEval -RRB-	1.000000
effectively launched	0.333333
CKY	0.000029
called Cross-Sentence	0.055556
and right-most	0.001445
universal ''	0.333333
preferred	0.000029
1993 there	0.333333
been parse	0.014706
the proliferation	0.000692
, highly-specialized	0.000561
classifier ,	0.142857
analytical	0.000058
into a	0.217949
Trek .	1.000000
erroneous	0.000029
, Jay	0.000561
Apparatus	0.000029
technique used	0.142857
observed	0.000029
analytics	0.000029
, Jan	0.000561
technique uses	0.142857
repeated relations	0.500000
Auto	0.000029
includes a	0.142857
Technologies	0.000029
A precise	0.020000
-- makes	0.040000
clues	0.000087
manually created	0.250000
Segmentation ,	1.000000
received	0.000058
charge services	1.000000
databases as	0.125000
produced like	0.111111
Handwriting recognition	1.000000
Maximal Marginal	1.000000
driving social	1.000000
topic -RRB-	0.125000
to cope	0.001328
Maximal	0.000029
But the	0.166667
engines	0.000087
markers ,	0.333333
markers .	0.333333
relations among	0.166667
attempts at	0.333333
representation framework	0.052632
applying a	0.250000
concerning	0.000029
candidacies	0.000029
He then	0.125000
application where	0.071429
or negative	0.009009
by periods	0.005714
2007 .	0.400000
Communication	0.000029
said with	1.000000
ambiguity ''	0.125000
eigenvector corresponding	0.500000
the jet	0.000692
interjection .	1.000000
successful for	0.111111
lacks pre-existing	1.000000
evaluating automatically	0.200000
Around	0.000029
, nasality	0.000561
avoids	0.000029
taxonomies	0.000029
independent	0.000058
person 's	0.210526
therefore it	0.600000
well enough	0.035714
's polarity	0.019608
field within	0.037037
resource -LRB-	0.200000
and Romanseval	0.001445
`` an	0.005291
interaction ,	0.125000
interaction .	0.250000
linguistically meaningful	1.000000
its component	0.028571
centres	0.000029
are words	0.004149
pronouns with	0.500000
quoted	0.000029
NLP The	0.042553
the rules	0.003460
generated is	0.066667
probabilities not	0.090909
a stochastic	0.001227
apply to	0.400000
rules should	0.023256
recogniton by	0.500000
capturing data	1.000000
using machine	0.016949
is contrast	0.002033
approach was	0.028571
makes sense	0.125000
study language	0.250000
fusion	0.000029
accuracies in	1.000000
command centres	0.500000
sounds :	0.066667
Part-of-Speech Tagset	1.000000
a skilled	0.001227
sounds .	0.066667
Reader	0.000087
consumed from	1.000000
He pointed	0.125000
frequency -LRB-	0.500000
Head-driven	0.000029
`` language	0.010582
of written	0.003565
applications Aerospace	0.040000
humor	0.000029
`` blocks	0.010582
the ambiguous	0.001384
rule-based methods	0.142857
a learner	0.001227
may be	0.403846
Imagine you	1.000000
, largely	0.000561
marketing	0.000029
computer .	0.068182
customize OCR	0.500000
backup methods	1.000000
properties	0.000116
National Corpus	0.333333
: Stemming	0.009804
to apply	0.001328
them but	0.052632
a better	0.002454
prisoners	0.000058
<s> vs.	0.001537
with Optical	0.005464
of rocks	0.000891
POS -RRB-	0.076923
basic OCR	0.076923
theorists	0.000029
uses -LRB-	0.071429
Matches	0.000029
as possible	0.017422
authors claimed	0.400000
and language	0.004335
algorithms have	0.085714
deaf	0.000029
wave which	0.111111
searching -LRB-	0.333333
contains only	0.100000
and hearings	0.001445
components operating	0.200000
easily as	0.111111
list ,	0.090909
boundaries of	0.090909
, organization	0.001123
; By	0.021277
emotional	0.000116
multileveled	0.000029
TWA	0.000029
to Australia	0.001328
be keyphrases	0.004219
abstract	0.000029
more effectively	0.010526
of how	0.000891
training systems	0.035714
general software	0.045455
A simplified	0.020000
Although the	0.375000
research focus	0.023810
can discriminate	0.005525
very rare	0.024390
Windows	0.000029
Later	0.000029
usually done	0.062500
The sentences	0.005208
into words	0.038462
an inseparable	0.007576
scores	0.000145
advantage of	0.800000
Examples are	0.666667
on absorbing	0.004717
will never	0.028571
steer-point	0.000029
parser can	0.062500
switched	0.000029
To avoid	0.111111
recognition from	0.016529
rise to	0.500000
shallow approach	0.333333
can express	0.022099
a pre-existing	0.001227
requirements of	0.500000
and `	0.001445
This makes	0.015873
devoted	0.000145
<s> NLG	0.001537
an isolated	0.007576
redundancy .	0.333333
<s> NLP	0.000769
select keyphrases	0.166667
algorithms for	0.114286
involved in	0.166667
and 2	0.001445
different issue	0.020408
and ,	0.004335
pre -	1.000000
Conversation analysis	1.000000
is still	0.008130
two levels	0.034483
CoNLL	0.000029
the Northern	0.001384
his PhD	0.083333
to market	0.001328
Current research	0.200000
Corporation and	0.250000
other terms	0.014286
George	0.000029
undertaken to	0.500000
upper	0.000058
S. ,	1.000000
SVM ,	1.000000
discover	0.000029
Given an	0.071429
also general	0.014493
be filtered	0.012658
only Wikipedia	0.026316
to define	0.002656
assistance	0.000029
debated	0.000029
corpus denote	0.032258
coarse-grained relations	1.000000
any feedback	0.032258
subdivided	0.000029
of sounds	0.000891
ROUGE	0.000145
in its	0.003745
even allows	0.037037
to capture	0.001328
or phones	0.004505
machines or	0.250000
IMR during	0.500000
Deaf	0.000029
basic categories	0.076923
especially statistical	0.066667
easier to	0.250000
process ``	0.027778
used together	0.008850
The Apple	0.005208
state automata	0.071429
Q&A systems	1.000000
marked	0.000087
text -LRB-	0.037736
Holmes ,	1.000000
according to	1.000000
were found	0.048780
marker	0.000029
market	0.000087
assistance of	1.000000
and Intelligent	0.001445
be electronically	0.004219
or using	0.009009
from left	0.009615
usually are	0.031250
typically undirected	0.055556
ratings :	0.111111
travel .	1.000000
envelope	0.000029
data annotation	0.012987
ratings .	0.111111
ratings ,	0.111111
probable answer	1.000000
methods are	0.045455
a plural	0.001227
area is	0.181818
software was	0.037037
, German	0.001123
, linear-time	0.000561
without much	0.076923
manipulate the	0.333333
SBD	0.000029
extractors are	1.000000
pauses	0.000116
Walter	0.000029
voice-activation	0.000029
write	0.000029
modeling approach	0.142857
` kick	0.062500
, except	0.000561
a simple	0.001227
<s> CLAWS	0.001537
annotation	0.000116
as well	0.048780
Health Record	0.500000
are parsed	0.004149
<s> Please	0.002306
typical	0.000261
recognition problems	0.008264
phonetic segmentation	0.500000
, grounded	0.000561
into intrinsic	0.012821
: List	0.009804
individual trained	0.083333
training are	0.071429
process automatic	0.027778
was most	0.012987
ELIZA worked	0.111111
choice in	0.125000
breaks are	0.500000
choice is	0.250000
way sentiment	0.041667
<s> For	0.043812
be produced	0.004219
retrieving information	1.000000
as researchers	0.003484
translation Machine	0.013514
disparate	0.000029
and practical	0.001445
scaling	0.000029
example for	0.024691
superset	0.000029
discuss	0.000029
movie together	0.333333
the attitude	0.000692
into several	0.012821
; Given	0.021277
four words	0.142857
tries to	1.000000
context ,	0.121212
context .	0.212121
convention in	1.000000
than extraction	0.022222
: objective	0.009804
accomplish	0.000029
disabilities People	0.250000
rates .	0.125000
Vulcan	0.000058
function is	0.125000
assistant providing	1.000000
work progressed	0.041667
Asia Online	1.000000
and ELIZA	0.002890
future .	0.333333
Blind	0.000058
end of	0.250000
and graphics	0.001445
emotional state	0.250000
Laclau ,	1.000000
-LRB- 1954	0.002710
mean word	0.500000
apply increasingly	0.200000
flying	0.000029
Languages like	0.333333
variables	0.000029
There	0.000318
writing ,	0.222222
for health	0.003610
were able	0.024390
-LRB- Carbonell	0.002710
not absolutely	0.008929
Walter Kintsch	1.000000
, rule-based	0.000561
trigram found	0.333333
<s> ELIZA	0.002306
Noun	0.000029
Standardization	0.000029
that	0.008164
some writing	0.012048
1,500 documents	1.000000
the sense	0.000692
Viterbi algorithm	1.000000
manual evaluation	0.500000
reputations .	1.000000
switched to	1.000000
semantics	0.000405
categorical	0.000029
allow for	0.200000
characterize keyphrases	0.500000
Conferences	0.000058
accordance	0.000029
template ,	0.250000
a professor	0.001227
template .	0.250000
semantics is	0.071429
corpora specifically	0.090909
other work	0.014286
of adaptive	0.000891
that NLG	0.007092
Handbook	0.000029
other word	0.014286
Kittredge	0.000058
Tauschek	0.000058
programming algorithms	0.200000
societal problem	1.000000
restricted ``	0.250000
computationally	0.000058
join different	1.000000
which undertook	0.007246
distinguishes these	0.500000
the opinion	0.000692
nuances	0.000029
online	0.000232
country into	0.250000
case of	0.352941
begin	0.000087
be possible	0.008439
mostly work	0.500000
Deese ,	1.000000
dried up	1.000000
uses stochastic	0.071429
doing extensive	0.500000
to foster	0.001328
the late	0.005536
within different	0.055556
was also	0.025974
k -RRB-	1.000000
professional	0.000029
high .	0.055556
high ,	0.055556
subject to	0.125000
typical features	0.111111
was LILOG	0.012987
disambiguation often	0.100000
is distorted	0.004065
about pronouns	0.025000
Political	0.000087
way and	0.041667
notations	0.000058
been much	0.014706
primary topics	0.500000
title	0.000029
Janet Holmes	0.500000
1981 -RRB-	1.000000
Vulcan program	0.500000
phrase structure	0.200000
the simulation	0.000692
moved across	1.000000
with such	0.005464
EVALITA web	0.500000
% to	0.051282
the program	0.002076
active research	0.500000
better QA	0.111111
<s> During	0.003075
the potentially	0.000692
Aerospace Establishment	0.500000
not predict	0.008929
, pitch	0.000561
without it	0.076923
studying the	1.000000
the microphone	0.000692
However the	0.027027
or insufficient	0.004505
assigning the	1.000000
purpose at	0.200000
labeled keyphrases	0.333333
are provided	0.004149
highlighting candidate	1.000000
the natural	0.001384
Markov Models	0.166667
lexicon and	0.111111
summarization works	0.020000
3	0.000145
computers ,	0.222222
and Subjectivity	0.001445
computers .	0.222222
, biographical	0.000561
OCR Software	0.020408
highly by	0.111111
available .	0.176471
available ,	0.235294
analyzed	0.000145
in political	0.001873
translation by	0.013514
gone into	1.000000
returns text	1.000000
databases and	0.125000
knowledge bases	0.037037
<s> Future	0.000769
over 95	0.083333
be learned	0.004219
pruned	0.000029
learning	0.001245
Few assumptions	1.000000
low precision	0.333333
cares	0.000029
skew	0.000029
-RRB- automatically	0.002817
VITO Voice2Go	1.000000
especially to	0.066667
done using	0.090909
phonetically different	1.000000
of sublanguage	0.001783
musical notations	1.000000
when deployed	0.028571
Kenneth	0.000029
to ensure	0.001328
recognition rates	0.016529
would look	0.037736
or her	0.009009
analyzed using	0.200000
POS-taggers ,	1.000000
overload has	1.000000
sometimes provided	0.076923
's house	0.039216
rank individual	0.166667
by programs	0.005714
Edges	0.000058
<s> increases	0.000769
adding citations	0.500000
ones ,	0.300000
ones .	0.200000
English verbs	0.027027
investigates	0.000029
keyphrases your	0.028571
in processing	0.001873
abstraction can	0.250000
people or	0.062500
SATZ	0.000029
deal with	0.500000
level we	0.050000
or millions	0.004505
varied from	1.000000
Parsers are	0.500000
competence ,	1.000000
latter as	1.000000
popular media	0.111111
level 7	0.050000
level 6	0.050000
level ;	0.100000
improvement	0.000116
level ,	0.200000
level .	0.050000
each time	0.022222
this prior	0.010989
early	0.000290
a coherent	0.002454
, Phrases	0.000561
ICR software	0.333333
David R.	0.250000
there would	0.025000
which draws	0.007246
benefit	0.000087
statistical inference	0.060606
documents .	0.131579
Web-based OCR	0.666667
those proved	0.045455
the tagset	0.000692
<s> Typical	0.001537
Vocalizations	0.000029
positive -RRB-	0.142857
teams to	0.500000
, business	0.000561
any topic	0.064516
to many	0.005312
This has	0.015873
sound input	0.050000
The acoustic	0.005208
upper-case	0.000029
domain ontologies	0.100000
symbolic representation	1.000000
achieves 98.5	0.500000
but rather	0.029412
Cross-Sentence	0.000029
access to	1.000000
still the	0.066667
be combined	0.004219
business	0.000116
heuristics to	0.500000
1933	0.000029
1935	0.000029
final stage	0.111111
comparison	0.000087
most parts	0.051724
this area	0.032967
difficult process	0.035714
represent varies	0.111111
, V.J.	0.000561
questions are	0.076923
constructs -LRB-	0.333333
processor	0.000029
content that	0.083333
harder tasks	0.142857
systems trade	0.008929
Brill Tagger	0.333333
larger source	0.062500
elementary	0.000029
your	0.000058
the translation	0.004152
-RRB- evaluation	0.002817
processed with	0.333333
periods can	0.333333
an image	0.007576
area	0.000318
assumed	0.000029
verbal unit	1.000000
challenge in	1.000000
or component	0.004505
faster computers	0.333333
the author	0.002076
for evaluating	0.010830
, proper	0.000561
grammatical information	0.090909
to Iraq	0.001328
to build	0.001328
appliance	0.000029
a graph	0.003681
and Rubin	0.001445
were conducted	0.024390
tones	0.000029
also marked	0.014493
found Intelligent	0.071429
A promising	0.020000
Bottom-up	0.000029
scanner	0.000087
make soft	0.200000
above text	0.076923
Training for	0.500000
the parse	0.000692
scanned	0.000087
advanced -LRB-	0.200000
Coreference	0.000029
having the	0.200000
in our	0.001873
Lao	0.000029
from floods	0.009615
<s> Essentially	0.000769
delimited -LRB-	0.250000
about any	0.025000
documents containing	0.026316
valid	0.000029
you	0.000376
Law	0.000029
software Current	0.037037
including morphemes	0.071429
, Harvey	0.000561
PangeaMT	0.000029
task should	0.023810
building	0.000029
condensation	0.000029
Sublanguage	0.000029
Spanish ,	0.500000
our learned	0.200000
many neighbors	0.019231
's intrinsic	0.019608
text categorization	0.006289
of freely	0.000891
workshops dedicated	0.500000
imprints for	1.000000
= common	0.111111
for triples	0.003610
actions .	1.000000
training ;	0.035714
text based	0.006289
equivalence	0.000058
difficulties discussed	0.500000
and actioning	0.001445
can find	0.005525
ability to	0.750000
Eight	0.000029
world applications	0.066667
objects -LRB-	0.200000
<s> Basic	0.000769
systems become	0.008929
grid &	1.000000
Amount	0.000029
-LRB- VITO	0.002710
securely	0.000029
integration with	1.000000
application of	0.285714
: Convert	0.019608
in of	0.001873
a heuristic	0.002454
emotions in	1.000000
Norman ,	0.500000
, machine	0.001684
is facing	0.002033
genre and	0.500000
in texts	0.001873
discourse Political	0.027778
placed in	1.000000
units as	0.142857
Corpus was	0.125000
processor speeds	1.000000
casual	0.000029
the pilot	0.000692
emotions	0.000029
ostensibly simple	1.000000
simple rules	0.038462
collaborated to	1.000000
analyzed for	0.200000
A similar	0.020000
problem can	0.022727
with implicit	0.005464
edited	0.000029
by Frederick	0.005714
1949 RCA	0.500000
questions -LRB-	0.038462
best ,	0.055556
a useful	0.001227
a gold	0.002454
Chinese and	0.142857
engine .	0.666667
amount	0.000145
been operated	0.014706
trainer	0.000029
important parts	0.062500
installed defective	0.333333
analyzing	0.000145
trained	0.000087
trainee	0.000029
and possibly	0.001445
intent .	1.000000
discriminative	0.000058
which arise	0.007246
and labor	0.001445
get this	0.142857
consumption -RRB-	1.000000
-LRB- subject	0.002710
Association for	1.000000
language output	0.006757
, opened	0.000561
A problem	0.020000
included in	0.125000
optimistic	0.000029
the harmonic	0.000692
with highest	0.010929
Press ''	1.000000
computerized text	0.500000
program may	0.045455
Acoustical signals	0.500000
the behavior	0.000692
communication studies	0.200000
SpeechTEK	0.000058
left-most derivations	0.500000
of yesterday	0.002674
the standard	0.001384
is likely	0.006098
are presented	0.004149
, merging	0.000561
tried	0.000087
the linguistic	0.000692
derived	0.000174
tries	0.000029
syntax effectively	0.090909
a	0.023595
compare the	0.285714
the overriding	0.000692
voice-activation ,	1.000000
language system	0.006757
, annotation	0.000561
it -RRB-	0.008547
committed	0.000029
of man-hours	0.000891
pollen levels	0.692308
simple tasks	0.038462
MIT	0.000058
documents generally	0.026316
solving	0.000029
actually	0.000087
of reviews	0.000891
Putting	0.000029
learning problem	0.023256
Why does	0.285714
ELIZA	0.000261
tagging is	0.080000
that these	0.010638
-- thus	0.040000
work by	0.083333
subtask	0.000058
since the	0.100000
4-gram matching	1.000000
to finding	0.001328
decimal	0.000029
Activity -LRB-	1.000000
relating to	1.000000
a learning	0.002454
Master lead-in	1.000000
optimal match	1.000000
and Janet	0.001445
beyond	0.000174
can deal	0.005525
event	0.000087
steered	0.000029
and an	0.004335
counterparts in	1.000000
languages See	0.020000
deep ''	0.142857
classification indicates	0.058824
the suffix	0.000692
human assessments	0.021739
According	0.000029
represents a	0.750000
notably successful	0.333333
language parsing	0.013514
; the	0.085106
; later	0.021277
earliest	0.000058
The process	0.015625
with manually	0.005464
LexRank and	0.083333
domain posed	0.050000
interact	0.000029
inter-texual and	0.500000
hypothesis ``	1.000000
Lander used	0.500000
robotic	0.000029
descriptive tags	0.333333
where only	0.028571
difficult than	0.107143
provide summaries	0.166667
Improved	0.000029
accuracy can	0.032258
criterion depends	0.500000
verb -LRB-	0.153846
started around	0.250000
translation	0.002142
ARNS	0.000029
150 examples	0.500000
shallowest	0.000029
singular proper	0.250000
translate spoken	0.166667
sentenced	0.000029
do not	0.500000
re-encode	0.000029
example where	0.012346
parsing -	0.071429
parsing ,	0.071429
parsing .	0.107143
sentences	0.002200
and Audio	0.001445
only of	0.026316
that operated	0.003546
ratings	0.000261
, ratings	0.000561
Users	0.000029
NLP Main	0.021277
because punctuation	0.033333
proposed what	0.111111
`` understand	0.005291
With	0.000203
parsing a	0.035714
phrase How	0.100000
changed direction	0.500000
degree -LRB-	0.166667
Arabic -RRB-	0.250000
sponsored	0.000058
-RRB- --	0.002817
the overall	0.002076
dictation system	1.000000
mobile	0.000058
clear	0.000116
not necessary	0.008929
critical new	0.250000
retrieval or	0.142857
declaration of	1.000000
classifiers make	0.500000
clean	0.000058
English sentences	0.027027
Language as	0.083333
of any	0.002674
, not	0.003930
did exactly	0.200000
Discontinuous or	1.000000
parameters	0.000116
The apple	0.010417
Trained linguists	1.000000
MT -LRB-	0.200000
very deep	0.024390
takes the	0.333333
previous Section	0.333333
and answered	0.001445
into subfields	0.012821
HMM-based	0.000087
a factory	0.001227
specific to	0.047619
are starting	0.004149
not trivial	0.008929
linguistic way	0.062500
and conversations	0.001445
significant increase	0.111111
semantic from	0.047619
<s> Human-machine	0.000769
captioning ,	1.000000
rooms ,	1.000000
probable	0.000029
intelligence .	0.125000
intelligence ,	0.125000
-LRB- December	0.002710
has grown	0.011905
probably	0.000116
and sentences	0.002890
measure -LRB-	0.090909
The software	0.005208
natural summaries	0.013333
Hirschman L.	0.500000
You are	1.000000
both	0.000897
structure The	0.083333
these approaches	0.047619
resolve .	0.250000
large-scale	0.000029
approximation to	0.333333
PC history	0.250000
2010 ?	0.333333
popular being	0.111111
as Scansoft	0.003484
, NN	0.000561
, NP	0.000561
combine	0.000087
Merging of	1.000000
to which	0.006640
speech there	0.006579
dialogue	0.000058
media .	0.166667
and characterizes	0.001445
media ,	0.500000
learning ''	0.116279
others more	0.083333
and interactive	0.001445
determination	0.000029
Wilensky	0.000058
since 1971	0.100000
Su ,	1.000000
to work	0.002656
while	0.000579
popular evaluation	0.111111
because longer	0.033333
recognized words	0.166667
phoneme ,	0.500000
history of	0.500000
many artificial	0.019231
message boards	0.500000
RCA	0.000145
The attitude	0.005208
informatics .	1.000000
FAS	0.000029
tell whether	0.333333
Understanding	0.000058
, Petrov	0.000561
group developed	0.250000
<s> Paul	0.000769
FAA	0.000058
an answer	0.015152
University of	0.333333
the introduction	0.000692
analysis systems	0.015385
fact that	0.454545
the need	0.002076
learned .	0.200000
database	0.000290
language being	0.013514
remains a	0.250000
etc. -RRB-	0.409091
Quechua	0.000058
text contains	0.006289
judgments	0.000029
classifying short-time	0.200000
Bernard	0.000029
complex recognition	0.041667
corpus contains	0.032258
CCD	0.000029
between the	0.179487
language from	0.006757
using database	0.016949
two distinctive	0.034483
wrote The	0.166667
common-sense reasoning	1.000000
rule-based	0.000203
Army Corps	0.500000
undertaken ,	0.500000
Administration ,	1.000000
decode the	1.000000
ambiguous and	0.166667
Ochs ,	1.000000
M-346 Master	1.000000
translates	0.000029
Some unsupervised	0.047619
arbitrary new	0.333333
translated	0.000116
<s> Many	0.008455
machines ,	0.250000
relations to	0.083333
improved .	0.250000
some	0.002403
urgent	0.000029
evaluated ,	0.142857
evaluated .	0.142857
defined only	0.166667
warnings	0.000029
Several papers	0.333333
Apollo	0.000029
http:\/\/haydn.isi.edu\/ROUGE\/ -RRB-	1.000000
VTLN	0.000029
error analysis	0.083333
are Deaf	0.004149
and checked	0.001445
mid-1960s	0.000029
meanings ,	0.250000
in-depth	0.000087
like a	0.071429
simulation	0.000087
summarization on	0.020000
than computers	0.022222
ASR .	0.166667
block	0.000029
Mutual	0.000029
problem setting	0.022727
using logical	0.016949
visit	0.000058
Google published	0.250000
-RRB- or	0.011268
could search	0.062500
was developed	0.012987
would expect	0.018868
Speech-to-text	0.000029
while ratings	0.050000
statistics	0.000232
system such	0.010753
<s> About	0.000769
delta-delta coefficients	1.000000
presence of	1.000000
properly .	0.500000
any kind	0.032258
Aerospace	0.000058
computer process	0.022727
of whole	0.001783
texts by	0.058824
standard expression	0.071429
intended semantic	0.200000
or disease	0.004505
'' about	0.005376
research devoted	0.023810
to current	0.001328
Intelligent Character	0.333333
alternative right-hand-sides	0.333333
ME -RRB-	0.500000
, Jim	0.000561
ontologies and	0.166667
instance of	0.142857
a fast-evolving	0.001227
have keyphrases	0.019231
corpus -	0.032258
Polar	0.000029
use neural	0.013889
value is	0.333333
A.	0.000145
electrical	0.000029
word divider	0.016667
pronouns	0.000058
entities in	0.142857
pollen level	0.153846
will be	0.257143
not explicitly	0.008929
most commonly	0.017241
letters :	0.100000
Gender	0.000029
to process	0.003984
may blend	0.019231
ISRI	0.000029
discussed involve	0.142857
letters .	0.400000
structure	0.000347
Romanseval campaigns	1.000000
practically	0.000029
passages .	0.500000
An	0.000463
`` in	0.010582
As	0.000521
At	0.000087
for reasons	0.003610
avoid	0.000029
that produce	0.003546
part-of-speech tag	0.066667
NLG summaries	0.047619
more and	0.021053
neural nets	0.066667
71 %	1.000000
the humanities	0.000692
cockpit ,	0.500000
unstructured	0.000029
umbrella term	1.000000
gender	0.000029
can prove	0.005525
focus and	0.142857
Information -LRB-	0.200000
computer-type	0.000029
is lessened	0.002033
Truecasing	0.000029
incorrect assignment	0.333333
are informative	0.004149
sentiment words	0.040000
term is	0.055556
them attractive	0.052632
translation simultaneously	0.013514
cell	0.000058
science and	0.100000
be thresholded	0.004219
1965 ,	0.500000
best option	0.055556
use Machine	0.013889
an extension	0.007576
are written	0.004149
implicit assumptions	1.000000
Arabic	0.000116
word ,	0.033333
all be	0.023256
and making	0.002890
cases -RRB-	0.055556
emigre	0.000029
addressed	0.000058
boolean	0.000029
where one	0.028571
pioneered the	0.333333
: Content	0.009804
-LRB- Cullingford	0.002710
are by	0.004149
which used	0.007246
array .	1.000000
vehicle	0.000029
to ``	0.005312
desired -RRB-	0.200000
is affected	0.002033
may use	0.019231
style ,	0.500000
grammar methods	0.027027
disabilities that	0.250000
verifying certain	1.000000
sent in	1.000000
between those	0.025641
2011 campaign	0.500000
Video	0.000029
keyphrase system	0.052632
control	0.000145
expanded the	1.000000
an example	0.037879
dictation	0.000029
the vowel	0.001384
, neutral	0.000561
already published	0.200000
‚Üí barmaid	0.333333
algorithms use	0.028571
of extracting	0.000891
onto its	1.000000
been characterized	0.014706
to tag	0.001328
on speaker	0.004717
<s> Turney	0.000769
<s> Translation	0.000769
finished writing	0.500000
-LRB- that	0.010840
disfluences	0.000029
the identity	0.002768
it offered	0.008547
to evaluate	0.005312
Wilson	0.000029
and evaluation	0.004335
Phillips	0.000029
different relationships	0.020408
computer-understandable data	1.000000
mentioned	0.000174
converting	0.000058
helicopters	0.000058
Recently	0.000029
Wallace	0.000029
keep the	0.333333
optimized for	1.000000
an ''	0.007576
architecture uses	0.500000
ellipsis ,	1.000000
unseen data	1.000000
linked in	0.333333
hand-crafted rules	0.500000
front	0.000087
a credit	0.002454
solved .	0.200000
comparing the	0.500000
name and	0.200000
The combination	0.005208
more likely	0.010526
classification-related measure	1.000000
typology ,	1.000000
workload ,	1.000000
modules that	0.500000
on Reader	0.004717
absolutely necessary	1.000000
also referred	0.014493
ROUGE-1 is	0.200000
sense in	0.125000
dictator is	1.000000
J.	0.000087
strokes	0.000029
umbrella	0.000029
free speech	0.250000
linear transform	0.142857
-RRB- Speech	0.002817
and segment	0.001445
20,000	0.000029
Models are	0.333333
, question	0.001123
candidates ,	0.200000
eat ''	1.000000
solution can	1.000000
without significant	0.076923
mentioned in	0.166667
quality	0.000290
in universities	0.001873
, Marcus	0.000561
length cutoff	0.125000
journals	0.000058
level provides	0.050000
relations	0.000347
discards any	1.000000
spun it	1.000000
-RRB- ^	0.002817
intelligence	0.000232
- passage	0.062500
final	0.000261
a threshold	0.003681
integrated into	0.333333
of each	0.006239
exactly	0.000087
to computers	0.001328
with misspelled	0.005464
-LRB- essentially	0.002710
tools for	0.166667
limitation in	1.000000
be turned	0.004219
Richard	0.000029
marking up	0.500000
widely-reported news	1.000000
GPO -RRB-	1.000000
action of	0.200000
rule should	0.333333
<s> Results	0.000769
based on	0.833333
partially influenced	1.000000
need	0.000608
Development	0.000029
microphone	0.000029
solely on	1.000000
pursued	0.000029
able	0.000463
Foucault	0.000087
model avoids	0.033333
see context-free	0.050000
word problems	0.016667
-RRB- found	0.002817
different classes	0.020408
connected	0.000145
SATZ architecture	1.000000
a predefined	0.001227
government sponsored	0.333333
France installing	0.250000
spend much	1.000000
stems from	0.500000
machine that	0.012658
preceding token	1.000000
profiling for	1.000000
OnlineOCR practically	0.333333
to know	0.001328
lip-synch	0.000029
and shorter	0.001445
political negligence	0.333333
employed	0.000029
semantic parsing	0.047619
reading is	0.125000
overall	0.000174
dogs -RRB-	0.142857
same column	0.040000
Italian	0.000058
final phase	0.111111
from has	0.009615
or formulaic	0.004505
contain	0.000347
human-ratings and	1.000000
and commercial	0.001445
a rule	0.001227
computed	0.000058
be -RRB-	0.004219
computer	0.001274
- and	0.125000
to their	0.002656
The choice	0.005208
function as	0.125000
parsing can	0.071429
user-specified	0.000058
use cepstral	0.013889
One could	0.076923
include stages	0.037037
short commands	0.125000
If web	0.100000
and minimum	0.001445
most NLP	0.017241
importance	0.000174
an infinitive	0.007576
that shift	0.003546
The earliest	0.005208
and etc.	0.001445
virtual currency	1.000000
feature is	0.076923
source materials	0.041667
been especially	0.014706
While LexRank	0.200000
in 1965	0.001873
in 1966	0.001873
: Dynamic	0.009804
knowledge sources	0.037037
In fact	0.038095
studies ,	0.500000
harmonic	0.000029
the potential	0.002076
NLP with	0.021277
advantages over	1.000000
was based	0.012987
assistants such	1.000000
to produce	0.013280
translate five	0.166667
than that	0.044444
treat	0.000058
symbols or	0.333333
neutral .	0.500000
parse a	0.111111
ontologies	0.000174
senses	0.000058
applied to	0.733333
then spoke	0.028571
into one	0.025641
evaluations such	0.166667
document summarization	0.138889
the 1970s	0.000692
glossary	0.000058
This unreferenced	0.015873
harder	0.000203
improve document	0.076923
for reading	0.007220
able to	1.000000
achieved only	0.100000
in word	0.001873
began	0.000203
techniques can	0.043478
unsupervised and	0.125000
ASRU	0.000029
completion of	1.000000
effect	0.000058
any number	0.032258
algorithms fall	0.028571
discouraged	0.000029
T unigrams	0.333333
precision .	0.200000
precision -	0.200000
in fighter	0.005618
is little	0.002033
as closed	0.003484
obstacles	0.000029
require the	0.181818
trade speed	0.500000
position in	0.500000
as 50	0.003484
social contexts	0.071429
sources	0.000174
attention ,	0.500000
automated semantic	0.142857
-RRB- refer	0.002817
will mention	0.028571
speech-to-text -RRB-	0.500000
language-specific	0.000029
`` Call	0.005291
used mostly	0.008850
By	0.000087
devised	0.000058
LexRank	0.000347
burden	0.000029
, multilingual	0.000561
large quantity	0.043478
between sentences	0.051282
extracting meaningful	0.200000
B.	0.000029
the walk	0.000692
language sentences	0.006757
gold standard	0.833333
model summaries	0.066667
shed	0.000029
a table	0.003681
data which	0.012987
a language	0.007362
known keyphrases	0.153846
automated sentiment	0.142857
questioners	0.000029
taking a	0.200000
be achieved	0.021097
but triples	0.014706
SemEval	0.000029
for identifying	0.003610
tests the	0.500000
that time	0.003546
implemented using	0.200000
LexRank was	0.083333
translator must	0.142857
will likely	0.057143
camp is	0.250000
displaced by	1.000000
negative labels	0.125000
rule induction	0.333333
in ontologies	0.001873
the programs	0.000692
significant taggers	0.111111
computer user	0.022727
classifying a	0.400000
Company and	0.500000
Service has	1.000000
mental processes	0.666667
utility	0.000058
the filter	0.000692
to test	0.002656
R -RRB-	1.000000
vagueness of	1.000000
working out	0.142857
Isolated ,	1.000000
's informativeness	0.019608
to coherent	0.001328
applies both	0.285714
input to	0.073171
input are	0.024390
Latin-script	0.000029
subjective	0.000174
problem of	0.181818
own ;	0.166667
duplicate typewritten	0.500000
signed	0.000029
converted	0.000087
and enterprise	0.001445
piece	0.000087
temporal dependencies	0.500000
majority of	1.000000
of document\/text	0.000891
the conversational	0.000692
spirit to	1.000000
a cell	0.002454
Measuring	0.000029
Despite the	1.000000
heuristic post-processing	0.333333
distinguish from	0.200000
of effort	0.000891
the importance	0.001384
<s> Major	0.001537
Corpus of	0.062500
Like	0.000058
generally ,	0.090909
a pre-processing	0.001227
sharing one	1.000000
technology in	0.045455
required translation	0.142857
retrieval --	0.142857
They combine	0.333333
portion	0.000058
icon -RRB-	1.000000
developed transformational	0.038462
about 1,000,000	0.025000
attached ,	0.500000
`` polarity	0.005291
1,000 parts	0.500000
similarity	0.000290
the most	0.013149
a hybrid	0.002454
the reported	0.000692
covers the	0.500000
preferable ,	1.000000
segments	0.000145
presents	0.000029
i.e. the	0.263158
characterised	0.000029
<s> Shallow	0.001537
updated	0.000029
connects	0.000029
text-to-speech technology	0.250000
the University	0.000692
structured databases	0.166667
hand-printed	0.000116
-RRB- of	0.019718
only relief	0.026316
of telephony	0.000891
when given	0.057143
it generalizes	0.008547
a keyboard	0.001227
programs in	0.090909
with capitalization	0.005464
keyphrase to	0.052632
particular NLP	0.076923
states -RRB-	0.250000
of cursive	0.000891
discussing how	0.500000
qualitatively	0.000029
that describe	0.003546
even	0.000782
are largely	0.004149
of developing	0.000891
warping Dynamic	0.250000
the part	0.001384
simplest -LRB-	1.000000
ever	0.000029
mechanical or	1.000000
and movie	0.001445
anthropology	0.000029
appear more	0.062500
Systran	0.000029
active	0.000058
Ohio	0.000029
numeric scores	1.000000
certain patterns	0.142857
about NLP	0.025000
campaign	0.000145
an attribute	0.007576
involves both	0.100000
components can	0.200000
cost	0.000058
sets -LRB-	0.090909
humans often	0.083333
electrical characteristics	1.000000
call	0.000087
performed in	0.200000
consistently available	0.333333
directly .	0.200000
most negative	0.017241
finished product	0.500000
other domains	0.014286
input character	0.024390
speech-enabled Symbian	1.000000
has received	0.011905
pro or	1.000000
the Web	0.001384
any data	0.032258
area are	0.090909
human vocabularies	0.021739
or probabilities	0.004505
deemed the	0.500000
some detail	0.012048
a verb	0.007362
classifier is	0.142857
involve	0.000174
Liu	0.000029
to minimize	0.001328
typewritten pages	0.200000
many languages	0.019231
The Georgetown	0.015625
, Gail	0.000561
page including	0.142857
with increasing	0.005464
answer	0.000869
a diverse	0.001227
Lancaster-Oslo-Bergen	0.000029
nodes that	0.142857
`` Man	0.010582
precise set	0.333333
All	0.000029
Civil	0.000029
representation language	0.105263
surrounding consonants	0.200000
large corpora	0.043478
maintain	0.000029
single sentence	0.071429
ELIZA gained	0.111111
and after	0.004335
use the	0.013889
operations	0.000029
and common-sense	0.001445
this type	0.032967
Rules are	0.666667
Joseph Weizenbaum	1.000000
considerable attention	0.200000
The algorithms	0.010417
scoring	0.000058
may fail	0.019231
Drew ,	1.000000
differently	0.000029
commercial systems	0.090909
Fighter Technology	1.000000
-LRB- ARRA	0.002710
overcome	0.000058
have helped	0.009615
a past-tense	0.001227
we register	0.022222
a shortened	0.001227
, symbolic	0.000561
rely on	0.857143
grammar	0.001071
some other	0.084337
of traditional	0.000891
went	0.000145
inserts	0.000029
successively	0.000029
technique referred	0.142857
hyphenated words	1.000000
principles	0.000029
Performance The	1.000000
principled	0.000029
extract	0.000116
she were	1.000000
NLP	0.001361
Analysis Standardization	0.200000
restricted	0.000116
content	0.000347
by taking	0.005714
NLG	0.000608
as subtasks	0.003484
`` advanced	0.005291
linear	0.000203
starts	0.000058
real-time character	0.500000
and naturalness	0.001445
record of	1.000000
denote abbreviations	0.500000
enumerate	0.000029
printed characters	0.083333
Both methods	0.333333
commonly tagged	0.125000
bootstrap using	1.000000
more corpus	0.010526
second edition	0.100000
phonemes -LRB-	0.166667
as within	0.003484
somewhat	0.000058
summarizing	0.000029
Klavans J.	1.000000
soon developed	0.333333
unlimited range	1.000000
bigrams	0.000058
generally refers	0.090909
same string	0.040000
for keyphrase	0.003610
on democratizing	0.004717
, emoticons	0.000561
question classification	0.023810
without a	0.076923
expect that	0.333333
DARPA	0.000116
POS	0.000376
overall system	0.166667
Speech Recognition	0.096774
Paroubek P.	1.000000
and aircraft	0.001445
assign targets	0.200000
Frederick	0.000029
the TextRank	0.001384
meaning from	0.043478
useful keyphrases	0.071429
: lexical	0.009804
difference was	0.250000
came into	0.500000
of 1,000	0.000891
graphics --	1.000000
there general	0.025000
Single	0.000029
search engine	0.090909
past decade	0.333333
walking slowly	0.333333
adding sentences	0.500000
perception that	0.500000
fixed schemata	0.500000
ending	0.000029
attempts	0.000174
to examples	0.001328
a summary	0.009816
a routing	0.001227
each word	0.111111
variously defined	1.000000
conference rooms	0.500000
are ambiguous	0.004149
Wendy Lehnert	1.000000
after 30	0.083333
can say	0.005525
compounded	0.000029
10	0.000232
Nikolas Rose	1.000000
SYSTRAN	0.000029
specific letters	0.047619
and correctly-developed	0.001445
'' has	0.010753
Given	0.000405
digits ``	1.000000
the state	0.001384
Amharic	0.000029
bag	0.000029
, employs	0.000561
requires citations	0.062500
way :	0.041667
correct according	0.066667
way ,	0.041667
Sydney	0.000029
simultaneously	0.000058
identifiers .	1.000000
A series	0.020000
language model	0.006757
chain random	1.000000
further information	0.125000
C	0.000029
and morphology	0.001445
elaborate theories	1.000000
-RRB- vibration	0.002817
precise function	0.333333
human-ratings	0.000029
not map	0.008929
summarization program	0.020000
released speech	0.500000
, thanks	0.000561
the output	0.002076
The features	0.005208
<s> Unlike	0.000769
of tags	0.000891
it builds	0.008547
usually called	0.031250
C.	0.000029
Authorities in	1.000000
their answers	0.029412
find ways	0.076923
categories can	0.111111
three	0.000087
Early	0.000058
that person	0.003546
C4	0.000029
-RRB- case	0.002817
understanding ''	0.060606
although capitalization	0.166667
Meehan	0.000029
using an	0.033898
<s> Additional	0.000769
be -LRB-	0.004219
pseudo-pilot	0.000058
illustrates some	0.500000
tagger ,	0.444444
what kinds	0.031250
ultraviolet light	1.000000
R. McDonald	0.166667
computer-generated weather	1.000000
the appropriate	0.002076
, abstractive	0.000561
grown	0.000029
strategy gets	0.200000
overlap should	0.250000
McCarthy coined	1.000000
general ontologies	0.045455
fine-grained analysis	1.000000
using OCR	0.050847
that affective	0.003546
Users were	1.000000
`` Naturally	0.005291
algorithms differ	0.028571
is typically	0.006098
this document	0.010989
The Archaeology	0.005208
overt	0.000029
1969 ,	0.500000
-LRB- transcription	0.002710
qualities	0.000058
paradigm	0.000087
a roadmap	0.001227
-LRB- context-free	0.002710
parser that	0.062500
just	0.000261
sentence	0.001390
was first	0.012987
Analysis and	0.200000
in determining	0.001873
turn a	0.166667
is non-trivial	0.002033
candidate	0.000087
A different	0.040000
, does	0.001123
Fully Automated	1.000000
rules that	0.093023
not contain	0.008929
turn .	0.166667
background	0.000087
turn ,	0.166667
while parsing	0.050000
What you	0.090909
human might	0.021739
, due	0.000561
manual	0.000058
Levenshtein	0.000029
perform a	0.272727
Text Retrieval	0.166667
Corpus contains	0.062500
draws on	1.000000
Psycholinguists prefer	1.000000
changing information	1.000000
consult information	1.000000
integer ,	1.000000
multileveled pattern	1.000000
paragraphs	0.000116
social sciences	0.142857
match between	0.166667
question-answering engines	0.500000
cognitive psychology	0.500000
Human-machine	0.000029
they superimpose	0.025000
also experimented	0.014493
complex expressions	0.041667
systems must	0.008929
, Ann	0.000561
qualitative automatic	0.500000
Shallow approaches	0.500000
Levinsohn	0.000029
also being	0.014493
2,000 words	0.500000
Hearing	0.000029
newspaper .	0.333333
reported there	0.200000
it may	0.017094
entities ,	0.285714
actual text	0.200000
indeed that	0.333333
speaker independent	0.055556
e.g. Chinese	0.017857
parsing	0.000811
lies	0.000058
1990s	0.000087
syntactic parsers	0.076923
approximate	0.000058
with 12	0.005464
, distance	0.000561
centroid ''	0.500000
offering	0.000029
answer to	0.166667
, Discontinuous	0.000561
matching the	0.200000
Z	0.000029
also needs	0.014493
-LRB- ISRI	0.002710
disabilities can	0.250000
builds	0.000058
II in	0.500000
attached	0.000058
6 over	0.250000
stages	0.000058
then with	0.028571
to one	0.002656
and funding	0.001445
covers	0.000116
the only	0.000692
stability in	1.000000
results .	0.095238
results ,	0.095238
translation may	0.013514
appears several	0.200000
generally	0.000318
expansion Automated	0.333333
plateaued and	1.000000
of sequential	0.000891
of patterns	0.000891
<s> Also	0.002306
Unsupervised Morpheme	0.166667
, Robyn	0.000561
other forms	0.014286
are broken	0.004149
consider a	0.250000
With isolated	0.142857
mild	0.000029
technique	0.000203
millions of	1.000000
, coughing	0.000561
preparation of	1.000000
Other taggers	0.142857
meaningful way	0.125000
Customized OCR	1.000000
variance on	1.000000
or sometimes	0.004505
applications discussed	0.040000
gold-standard	0.000029
the QA	0.000692
Force for	0.500000
about human	0.025000
did	0.000145
die	0.000029
and semantics	0.004335
information overload	0.021739
-LRB- Lehnert	0.005420
the typical	0.000692
Efficient	0.000029
-LRB- sometimes	0.002710
, favor	0.000561
is reported	0.002033
the finite	0.000692
decelerations during	1.000000
than text	0.022222
assessed mainly	1.000000
achieve accuracy	0.500000
data to	0.012987
data records	0.012987
Rabinow .	1.000000
More complex	0.111111
avoiding linguistic	0.500000
hits than	1.000000
Kurzweil Computer	0.285714
: Hidden	0.009804
history .	0.250000
useful	0.000405
Analysis of	0.200000
When	0.000203
evaluation data	0.018519
flexibility	0.000029
calls instead	1.000000
ultimately want	1.000000
learn explicit	0.076923
rules defining	0.023256
the BLEU	0.000692
condition that	1.000000
hierarchy of	1.000000
Annual Test	1.000000
sharing	0.000029
Dependence	0.000029
form an	0.050000
Another term	0.076923
a calculator	0.002454
fly	0.000029
Pyramid	0.000029
data source	0.012987
<s> Our	0.002306
avoiding	0.000058
Large-scale	0.000029
e.g. marking	0.017857
discourse -LRB-	0.055556
were repeatedly	0.024390
arrive	0.000029
bites	0.000087
claim	0.000029
`` create	0.005291
predict	0.000174
`` Computer	0.005291
years ,	0.238095
years .	0.190476
at short	0.014706
went in	0.200000
, automates	0.000561
that humans	0.007092
measured with	0.166667
in psycholinguistics	0.001873
critics	0.000029
Performing	0.000029
system selects	0.010753
sociolinguistics ,	0.500000
is expected	0.002033
a single	0.011043
this method	0.010989
for tense	0.003610
useful to	0.142857
field that	0.074074
can aid	0.005525
other features	0.014286
gradual	0.000029
typically involve	0.055556
video ,	0.200000
argued	0.000029
digitize the	1.000000
hidden parts	0.125000
mail	0.000058
main	0.000232
English like	0.027027
views	0.000029
<s> Encouraging	0.000769
current QA	0.142857
is very	0.012195
semiotics	0.000029
relations ,	0.166667
developments	0.000087
possess	0.000029
, education	0.000561
each document	0.022222
Business-card	0.000029
either a	0.200000
was delayed	0.012987
, selecting	0.000561
those it	0.045455
clear why	0.250000
Results	0.000029
field with	0.037037
-RRB- Video	0.002817
overlaps to	0.500000
FoG ,	0.500000
involve various	0.166667
correct	0.000434
use software	0.013889
and rule-based	0.001445
state of	0.357143
which associate	0.007246
undertook recognition	1.000000
second important	0.100000
taught to	0.333333
Microsoft Corporation	0.500000
and current	0.001445
Phrases ,	1.000000
paradigms .	1.000000
<s> because	0.000769
that is	0.056738
Please help	0.666667
of computer	0.003565
These results	0.058824
declared	0.000058
Pronunciation	0.000029
question-answering abilities	0.500000
un-supervised	0.000029
are grouped	0.004149
with adjacent	0.005464
the Ge'ez	0.000692
n Computer	0.500000
solve a	0.250000
mining	0.000145
nascent online	1.000000
into an	0.025641
character for	0.045455
analysis -RRB-	0.030769
user-provided	0.000029
word -RRB-	0.016667
input features	0.024390
questions have	0.038462
easily when	0.111111
, could	0.000561
Court	0.000058
word accuracies	0.016667
DA	0.000087
acquire basic	1.000000
Issues In	0.500000
demonstrates the	1.000000
backgrounds ,	1.000000
extraction algorithm	0.032258
right-hand-sides of	1.000000
or even	0.022523
system -LRB-	0.021505
green	0.000029
Du	0.000029
Weizenbaum between	0.333333
normal	0.000058
data has	0.012987
strengths of	0.500000
we think	0.022222
-LRB- this	0.002710
paper explored	0.090909
We apply	0.142857
tract	0.000029
D.	0.000145
and other	0.013006
especially	0.000434
surprising	0.000029
interest ,	0.090909
that read	0.003546
interest .	0.090909
gracefully	0.000029
precise	0.000087
lexicon	0.000261
analytics to	1.000000
Carbonell	0.000029
<s> Narrow	0.000769
Test	0.000029
more effective	0.010526
Importance of	1.000000
the Vulcan	0.000692
published but	0.142857
n-dimensional real-valued	1.000000
with isolated	0.005464
on work	0.004717
on word	0.004717
ranking	0.000203
abstractive summarization	0.333333
machine processes	0.012658
dictionary entry	0.142857
Turn	0.000029
and legal	0.001445
ears ,	1.000000
conjunction	0.000087
constructs -RRB-	0.333333
potential of	0.285714
Corpus tag	0.125000
are currently	0.008299
medial	0.000029
sounds representing	0.066667
both left-most	0.032258
for several	0.007220
or answers	0.004505
Parsing can	0.200000
it uses	0.017094
languages was	0.020000
common nouns	0.080000
reveal that	1.000000
on how	0.009434
9 parts	1.000000
a template	0.002454
represents an	0.250000
dBase system	1.000000
forecast	0.000029
enumerated	0.000029
systems such	0.017857
evidence of	0.500000
is entirely	0.002033
<s> Full	0.000769
modifying words	1.000000
that apply	0.003546
extremely expensive	0.250000
by deep	0.005714
considered as	0.111111
extraction -LRB-	0.064516
tagging include	0.040000
a flight	0.001227
of word-frequency	0.000891
considered an	0.111111
the structure	0.002076
are concerned	0.004149
so simply	0.033333
areas of	0.333333
ELIZA was	0.111111
well human-ratings	0.035714
maintained	0.000058
much additional	0.045455
use either	0.013889
important distinction	0.125000
material .	0.500000
Michel Foucault	1.000000
speech With	0.006579
unusual	0.000029
for example	0.064982
U.S. Department	0.142857
, what	0.001123
mark	0.000087
coupons	0.000029
-LRB- Black	0.002710
script used	0.250000
head hurts	1.000000
for modeling	0.003610
one video	0.015385
list of	0.727273
distinctive groups	0.500000
the water	0.000692
and assessing	0.001445
of Energy	0.000891
which consists	0.007246
characteristics	0.000058
decide :	0.250000
cluster	0.000058
Thompson ,	1.000000
everyday	0.000029
-LRB- linguistics	0.005420
segment text	0.222222
different	0.001419
<s> Front-End	0.000769
, call	0.000561
Two vertices	0.142857
of automatically	0.001783
multiscript	0.000029
get high	0.142857
the detection	0.000692
Commanders	0.000029
running	0.000087
helped overall	0.333333
the earliest-used	0.001384
using NLG	0.050847
was historically	0.012987
markup	0.000029
to meet	0.005312
start symbol	0.285714
by PageRank	0.005714
aspect	0.000058
Scope	0.000029
of digital	0.000891
models -LRB-	0.115385
also terminate	0.014493
Margaret	0.000029
extensive	0.000087
main drawback	0.125000
several summarization	0.045455
they think	0.025000
accurately if	0.500000
are too	0.004149
after stemming	0.083333
be weighted	0.004219
his or	0.083333
implicate	0.000029
interpretable	0.000029
technologies for	0.250000
is angry	0.002033
London	0.000029
to classify	0.001328
and eigenvector	0.001445
the design	0.001384
<s> Google	0.000769
-LRB- FAS	0.002710
usefully be	1.000000
systems however	0.008929
error-prone	0.000029
are generated	0.004149
critical	0.000116
fully articulated	0.166667
, style	0.000561
moderate	0.000145
words such	0.018349
measuring	0.000029
IEEE Transactions	0.666667
moderate should	0.200000
notable	0.000029
notably	0.000087
splitting is	0.500000
the extent	0.001384
dictionary or	0.142857
in automatic	0.003745
ten-year-long	0.000029
practical	0.000058
corpora such	0.090909
world of	0.066667
recognizing difficult	0.200000
, typewritten	0.001123
for cartoon	0.003610
systems .	0.089286
systems ,	0.053571
related information	0.066667
and phrases	0.002890
combining it	0.250000
systems :	0.008929
<s> Context	0.000769
Harold	0.000029
decode	0.000029
Obama	0.000029
-RRB- MorphoChallenge	0.002817
Extractor	0.000029
be similar	0.004219
language will	0.006757
knowledge representation	0.037037
Wilensky ,	1.000000
takes as	0.333333
shallow .	0.166667
networks Main	0.071429
operation .	0.500000
than conversation	0.022222
Reiter and	1.000000
the volume	0.000692
area includes	0.090909
of pairs	0.001783
sample corpus	0.333333
retrained	0.000029
all quantitative	0.023256
in reconfiguring	0.001873
Commercial research	0.500000
require exponential	0.045455
account several	0.333333
word boundaries	0.016667
active area	0.500000
301 computer	1.000000
rise of	0.500000
resolution	0.000116
feedback on	0.500000
any domain	0.032258
to wreck	0.001328
E-set :	1.000000
1930s .	1.000000
1952 and	0.500000
children	0.000058
and Markov	0.001445
Given basic	0.071429
cheque -LRB-	1.000000
echoes ,	1.000000
main knowledge	0.125000
each input	0.022222
much of	0.090909
several choices	0.045455
cut and	1.000000
straightforward	0.000029
translations	0.000058
, so	0.006738
to reformulate	0.001328
to solve	0.005312
concatenating	0.000029
results when	0.095238
person was	0.052632
of problems	0.001783
on Text	0.004717
most practical	0.017241
and became	0.001445
complex cognitive	0.041667
Whether a	0.500000
further	0.000232
most text	0.017241
comparison uses	0.333333
contractions like	0.500000
the current	0.001384
instances ,	0.333333
movement	0.000029
<s> Language	0.000769
type of	0.571429
create tokens	0.058824
promising	0.000029
Puma helicopter	1.000000
speeches	0.000029
of dividing	0.002674
produced tones	0.111111
sentence-end	0.000029
rules from	0.023256
general speech	0.045455
published	0.000203
especially inflectional	0.066667
candidates for	0.200000
the broadcast	0.000692
or indiscriminate	0.004505
task-based evaluations	0.750000
e.g. transformational	0.017857
phonemes of	0.166667
slowly and	0.500000
start with	0.142857
, plus	0.000561
distinct	0.000203
analog signal	0.500000
call routing	0.333333
usually not	0.031250
confusion with	1.000000
Aerospace -LRB-	0.500000
new sentences	0.041667
A. Lauriault\/Loriot	0.400000
Ask.com	0.000029
particular	0.000376
More powerful	0.111111
every 10	0.333333
their effectiveness	0.029412
OCR service	0.040816
translation Main	0.013514
on Mandarin	0.004717
result ,	0.272727
step towards	0.066667
multiple approaches	0.076923
predicate logic	1.000000
a second	0.003681
500,000 .	1.000000
the issues	0.000692
payments .	1.000000
graph would	0.076923
Lamb ,	1.000000
`` understanding	0.005291
often addressed	0.022727
compare automatic	0.142857
Products ,	0.500000
phone ,	0.500000
Application-Oriented OCR	1.000000
Lisp	0.000029
CLAWS pioneered	0.250000
is broad	0.002033
: The	0.039216
larger context	0.062500
along with	1.000000
response	0.000058
Generally speaking	0.400000
would enable	0.018868
'' could	0.005376
recognizes the	1.000000
retrieval	0.000203
recognition -RRB-	0.008264
are divided	0.004149
standard metric	0.071429
its nascent	0.028571
independent systems	0.500000
a security	0.001227
, aspect	0.000561
help blind	0.111111
very recent	0.024390
often and	0.022727
detected	0.000058
previously-written human	1.000000
for words	0.003610
good	0.000376
into French	0.025641
helicopter pilot	0.250000
to new	0.005312
should we	0.052632
easily	0.000261
Potter	0.000029
generally evaluated	0.090909
abstraction involves	0.250000
ports	0.000029
subsystem	0.000029
mental	0.000087
sciences ,	0.500000
parsing input	0.035714
two summaries	0.034483
factory -RRB-	1.000000
user could	0.071429
an entire	0.007576
E.	0.000116
ambiguous word	0.083333
: the	0.019608
meaning in	0.086957
the realm	0.000692
sentences .	0.105263
takes into	0.333333
largely dependent	0.200000
difficulty	0.000203
machine ''	0.012658
contextual polarity	0.500000
produced systems	0.222222
Thus ,	0.916667
benefits	0.000058
language interface	0.006757
more formally	0.010526
some rules	0.012048
text and	0.018868
pilots	0.000058
answered ,	0.200000
intelligence and	0.125000
could thus	0.062500
in order	0.013109
deep parsing	0.142857
instances	0.000087
performed an	0.100000
not included	0.008929
be generated	0.004219
RSI became	1.000000
phase is	1.000000
machine-learning-based implementation	1.000000
algorithms requires	0.028571
with word	0.016393
statement	0.000029
, How	0.000561
different levels	0.020408
criteria is	0.250000
positives by	1.000000
Language	0.000347
are important	0.004149
, followed	0.000561
other automatic	0.014286
the printed	0.000692
Problem	0.000029
and sub-categories	0.001445
morphology ,	0.714286
Text simplification	0.166667
real human	0.111111
have not	0.019231
person-years	0.000029
, more	0.002246
speed is	0.142857
service on	0.200000
were easy	0.024390
pre-existing	0.000058
Snyder -LRB-	0.500000
edges build	0.142857
Glass-box evaluation	1.000000
Text segmentation	0.166667
2006 and	0.333333
foreign word	0.500000
built	0.000087
build	0.000087
no means	0.076923
steered toward	1.000000
This criterion	0.015873
translation is	0.013514
actual NLP	0.200000
all rules	0.023256
including web	0.071429
-LRB- also	0.010840
recognition for	0.008264
Sample	0.000029
Baum-Welch algorithm	1.000000
sub-committee is	1.000000
particularly	0.000145
nine ''	1.000000
especially of	0.066667
were simply	0.024390
with realistic	0.005464
keywords ,	0.500000
fonts used	0.333333
, how	0.000561
fine	0.000058
find	0.000376
depended	0.000029
dividing	0.000087
that used	0.003546
98 %	1.000000
<s> Yet	0.000769
highly and	0.111111
would need	0.018868
Jurafsky	0.000029
Studies -RRB-	1.000000
LUNAR ,	0.666667
improvement by	0.250000
resolve	0.000116
Lao ,	1.000000
, TaleSpin	0.000561
A. D.	0.200000
in January	0.003745
Technolangue\/Easy project	0.500000
act as	0.750000
additional evidence	0.166667
some assertive	0.012048
is subject	0.002033
translating Quechua	0.250000
, Brill	0.000561
superseded	0.000029
hand-produced rules	1.000000
the Lancaster-Oslo-Bergen	0.000692
processing step	0.018519
Terry	0.000029
word stems	0.016667
model ''	0.033333
consonants	0.000087
as first	0.003484
Modern general-purpose	0.333333
aircraft	0.000203
although usually	0.166667
annual	0.000058
'' This	0.005376
worse if	1.000000
a generated	0.001227
' structures	0.105263
tag ``	0.062500
transformations	0.000058
NLP techniques	0.042553
ranking over	0.142857
he or	0.142857
Shallow	0.000058
in a	0.093633
in `	0.003745
meeting	0.000029
` naturally	0.062500
emergence of	1.000000
simple as	0.076923
himself with	0.500000
indicate speech	0.333333
involve learning	0.166667
500,000	0.000029
an idea	0.007576
the adviser	0.000692
be any	0.004219
otherwise ,	0.500000
post-secondary	0.000029
solid	0.000029
effects of	1.000000
in .	0.001873
and was	0.001445
first few	0.030303
even for	0.037037
quoting people	1.000000
apple the	0.333333
a meaning	0.002454
itself	0.000145
text linguistics	0.006289
<s> Features	0.000769
late 1960s	0.111111
Shipibo Paragraph	0.500000
BLEU .	0.333333
all ,	0.069767
same time	0.120000
all .	0.023256
when there	0.028571
yesterday	0.000087
EBMT -RRB-	1.000000
pre-defined or	0.500000
state -RRB-	0.071429
and paragraphs	0.001445
are remarkably	0.004149
more consistent	0.010526
Schegloff	0.000029
also cut	0.014493
Institute -LRB-	1.000000
entry	0.000116
parametric	0.000029
Kittredge ,	0.500000
one observation	0.015385
longer sentences	1.000000
right answer	0.100000
, paper	0.000561
and questions	0.001445
question posed	0.047619
tagging Koine	0.040000
million words	0.333333
from natural	0.009615
past-tense	0.000029
capitalization at	0.333333
the space	0.002076
evaluation comes	0.018519
to better	0.003984
Did	0.000029
big	0.000058
To translate	0.111111
agglutinative	0.000029
search Query	0.090909
systems since	0.008929
techniques could	0.043478
cognitive	0.000058
, many	0.003930
follows	0.000058
A very	0.020000
, recall	0.000561
of active	0.000891
`` out	0.005291
fine tune	0.500000
some major	0.012048
one on	0.015385
Strzalkowski	0.000029
often	0.001274
one of	0.215385
were workshops	0.024390
them in	0.052632
other things	0.042857
sub-problems	0.000029
one or	0.030769
he developed	0.142857
scale	0.000174
in very	0.005618
1982 -RRB-	0.333333
affects	0.000029
that detected	0.003546
eliminate	0.000058
PC platform	0.250000
and QA	0.001445
been shown	0.014706
tag probabilities	0.062500
than the	0.088889
consisting of	1.000000
dictionaries ,	1.000000
David	0.000116
taggers and	0.285714
Typically	0.000029
1-July-2005 ,	1.000000
searching for	0.333333
automated target	0.142857
analyses of	0.200000
wave .	0.222222
are in-principle	0.004149
post-process the	1.000000
get ranked	0.142857
module looks	0.333333
proportional	0.000029
Reader 's	1.000000
contexts make	0.142857
GRASSHOPPER	0.000087
successful in	0.111111
using sentence	0.016949
pronunciation	0.000029
visual detection	0.500000
, Reukos	0.000561
this system	0.010989
state-of-the-art in	0.500000
hopes	0.000029
is transformed	0.002033
directed	0.000029
dynamic programming	0.200000
hit you	1.000000
significant increases	0.111111
, Sandra	0.000561
psychology Response	0.250000
they are	0.175000
the hidden	0.000692
in Statistical	0.001873
messages .	0.500000
a sophisticated	0.001227
Answering	0.000029
parliament	0.000029
because many	0.033333
as working	0.003484
fluency	0.000029
%	0.001129
specify precisely	1.000000
humanities	0.000029
word breaks	0.016667
spectral-domain	0.000029
combine the	0.333333
might select	0.038462
applied different	0.066667
lend	0.000029
of supervised	0.000891
large ,	0.043478
waves would	0.142857
, Battle	0.000561
2002	0.000058
2000	0.000087
2001	0.000058
2006	0.000087
2007	0.000145
2004	0.000087
2005	0.000029
2008	0.000029
2009	0.000087
into two	0.012821
Goodwin ,	1.000000
every 10msec	0.333333
automatically The	0.047619
as controlled	0.003484
Ethnography of	1.000000
upload paper	1.000000
: Instead	0.009804
might provide	0.038462
<s> One	0.009224
, Flickinger	0.000561
intensive	0.000029
eventually spun	1.000000
decomposition	0.000029
undirected	0.000029
co-articulation	0.000029
base ,	0.500000
Santoni B.	1.000000
interface commercially	0.250000
needed -RRB-	0.619048
manually assigned	0.250000
to internal	0.001328
terminate a	1.000000
to decide	0.002656
was able	0.051948
one used	0.015385
grammar for	0.027027
e.g. Constraints	0.017857
independent system	0.500000
`` proper	0.005291
walks and	0.500000
was FoG	0.012987
leaders of	1.000000
, supervised	0.000561
replicated	0.000029
Extrinsic evaluation	0.500000
complex system	0.083333
confusable words	1.000000
more often	0.010526
deterministic rules	0.250000
questioner ,	0.500000
produce interpretable	0.045455
transcribe such	1.000000
opinion has	0.200000
and Pang	0.001445
with weights	0.005464
human language	0.065217
others	0.000347
Swales ,	1.000000
merging of	0.500000
Paul Chilton	0.200000
wide use	0.250000
should represent	0.105263
rules based	0.023256
these simple	0.023810
Cloud Computing	1.000000
themselves as	0.250000
formally expressed	0.500000
early 20th-century	0.100000
made feasible	0.062500
of unstructured	0.000891
omni-font	0.000029
next stage	0.285714
involve counting	0.166667
politics ,	1.000000
Dale	0.000029
explore and	0.250000
-LRB- NER	0.002710
language Prolog	0.006757
would fail	0.018868
and NLP	0.002890
system generates	0.010753
Basically	0.000029
begin with	0.666667
as keeping	0.003484
customisation by	1.000000
meaning then	0.043478
of extracted	0.000891
non-trivial ,	0.500000
subscription	0.000029
SWER	0.000029
Extracted sentences	1.000000
some improvement	0.012048
presents the	1.000000
of discourses	0.000891
the shops	0.000692
with hand-written	0.005464
Kurzweil and	0.142857
are expected	0.004149
far ,	0.125000
word vector	0.016667
deciding on	0.166667
and to	0.015896
More up	0.111111
e.g.	0.001621
not well	0.008929
for statistical	0.007220
employs	0.000058
neural network	0.333333
working for	0.142857
parsed by	0.750000
AI-complete problem	0.333333
stock	0.000087
-LRB- p.	0.002710
In recent	0.019048
NLG systems	0.238095
collection	0.000145
the ARNS	0.000692
the inferior	0.000692
company for	0.333333
column of	1.000000
lexicons with	0.500000
automatically the	0.047619
lines	0.000087
correspond	0.000058
Russian sentences	1.000000
UMLS -RRB-	1.000000
<s> Vocalizations	0.000769
D.S. 1998	1.000000
to reflect	0.001328
of process	0.000891
summaries automatically	0.023256
output quality	0.038462
labor	0.000058
classification task	0.058824
Methods Computers	0.250000
Canada to	0.166667
descriptive	0.000087
good approximation	0.076923
own expert	0.166667
semantic analysis	0.095238
<s> Open	0.000769
mention	0.000087
make use	0.050000
day	0.000029
verifying	0.000029
that part	0.003546
identified	0.000145
that words	0.007092
to message	0.001328
constraints	0.000116
and potential	0.001445
From	0.000029
made between	0.062500
formalisms such	0.500000
the centers	0.000692
<s> Contrary	0.001537
defining programming	1.000000
English-French record	1.000000
and coverage	0.001445
<s> Edges	0.001537
general learning	0.045455
for computers	0.003610
Instead of	1.000000
hours .	0.500000
Compare speech	1.000000
summary covers	0.023810
of great	0.000891
might include	0.038462
different aspects	0.020408
so on	0.166667
context dependency	0.030303
since 2000	0.100000
CSR	0.000087
respectively .	1.000000
Later ,	1.000000
The English	0.005208
of government	0.001783
grammar Rhetoric	0.027027
improvements	0.000058
or less	0.018018
A procedure	0.020000
Advanced ,	0.200000
time -LRB-	0.060606
a car	0.001227
more descriptive	0.010526
Gail Jefferson	1.000000
of omni-font	0.000891
then combining	0.028571
most basic	0.017241
Association	0.000029
paragraphs ,	0.250000
grammatical and	0.090909
paragraphs .	0.250000
Scansoft ,	1.000000
the annual	0.000692
-LRB- titled	0.002710
in agglutinative	0.001873
original training	0.076923
prune	0.000029
certain restrictions	0.142857
varying degrees	1.000000
new opportunities	0.041667
Note ,	0.111111
performance has	0.055556
as 7	0.003484
as 1	0.003484
accuracy over	0.032258
curves	0.000029
performance had	0.055556
demonstration	0.000145
similarity classes	0.100000
, would	0.001684
to highly	0.001328
answer may	0.033333
<s> Working	0.000769
<s> ``	0.003843
journal ``	0.333333
automatically learning	0.047619
unless	0.000029
keyphrases formed	0.028571
word senses	0.016667
as `	0.003484
as a	0.118467
preliminary	0.000087
rendered view	1.000000
sophisticated	0.000203
Maximum entropy-based	0.333333
Automatic learning	0.111111
Beigi covers	1.000000
gather	0.000029
Modern NLP	0.333333
under stress	0.200000
selection	0.000029
provider dictates	1.000000
absorbing	0.000087
text	0.004603
is -LRB-	0.004065
speech recogniton	0.006579
assumptions on	0.200000
is part	0.002033
a commercial	0.002454
EUROPARL	0.000029
been learned	0.029412
disciplines ,	1.000000
Airline Ticket	1.000000
Hybrid machine	0.500000
asked for	0.333333
key clauses	0.166667
in testing	0.001873
answer is	0.066667
unusual in	1.000000
`` Natural	0.005291
often be	0.022727
input that	0.048780
calling	0.000029
system comprising	0.010753
used on	0.008850
Bar-Hillel .	1.000000
of Arabic	0.000891
using elements	0.016949
Wikipedia	0.000058
now we	0.076923
professor at	1.000000
post-processed	0.000029
Grows	0.000029
to disseminate	0.001328
phases	0.000029
Mellon	0.000058
Bois ,	1.000000
a discussion	0.001227
Brazil ,	1.000000
routing	0.000087
progress	0.000203
for avoiding	0.003610
continuous recognition	0.166667
Questions are	1.000000
how big	0.034483
Schank at	0.200000
structure grammar	0.083333
design feature	0.250000
: Transfer-based	0.009804
as weather	0.003484
correctly .	1.000000
generated summaries	0.066667
otherwise	0.000058
think about	0.333333
portions .	1.000000
Solving	0.000058
Advanced Fighter	0.200000
results can	0.047619
dismiss the	1.000000
quantitative approaches	0.250000
received a	0.500000
biomedical	0.000029
where metrics	0.028571
normalized by	1.000000
Moore 's	1.000000
designed grammars	0.142857
`` the	0.026455
plain	0.000029
are capable	0.008299
of domains	0.000891
taking only	0.200000
handwriting	0.000058
: noun	0.009804
expressions that	0.333333
word segmentation	0.050000
In computer	0.009524
recommendation ''	1.000000
file	0.000029
logic -RRB-	0.250000
helped	0.000087
Lauriault\/Loriot ,	1.000000
Task	0.000087
a component	0.002454
claimed	0.000058
concern .	1.000000
sounds are	0.133333
possibilities .	0.200000
possibilities ,	0.200000
simple implementations	0.038462
that of	0.028369
Produce	0.000029
<s> Sentiment	0.003843
Real progress	0.500000
moderate to	0.600000
finite	0.000145
define these	0.500000
Canadian parliament	0.500000
Marcus	0.000029
keeping the	0.500000
's that	0.019608
scholars	0.000058
broken into	0.600000
following are	0.066667
that an	0.003546
lookup algorithms	1.000000
a hierarchy	0.001227
thought	0.000087
sets	0.000318
position	0.000116
geography ,	1.000000
differences themselves	0.333333
machine-translation	0.000058
contexts and	0.142857
the sequence	0.000692
three to	0.333333
whether an	0.076923
capabilities of	0.200000
statistical methods	0.121212
workday	0.000029
perhaps ,	0.166667
extraction depends	0.032258
counting cases	1.000000
linguistics that	0.100000
of implementing	0.000891
would output	0.018868
the collection	0.000692
realized on	1.000000
open world	0.250000
analysis could	0.015385
selection is	1.000000
watertight barmaid	1.000000
purpose graph-based	0.400000
several methods	0.045455
Dijk	0.000029
being asked	0.055556
sentences can	0.039474
: it	0.009804
engine ,	0.166667
large collections	0.043478
soft	0.000116
Documents	0.000029
segmentation in	0.030303
an original	0.007576
convey	0.000087
representation of	0.105263
segmentation is	0.272727
of statistical	0.001783
highlighting	0.000029
techniques for	0.086957
scores for	0.200000
journals include	0.500000
example generic	0.012346
-LRB- Realtime	0.002710
stemming or	0.500000
groups :	0.200000
noise	0.000232
tasks is	0.031250
as first-order	0.003484
step ,	0.133333
step .	0.133333
legal word	0.333333
groups ,	0.200000
occur in	0.400000
bigram ,	1.000000
approximating	0.000029
tasks in	0.093750
human .	0.065217
December	0.000029
some languages	0.024096
DCD library	1.000000
In 1914	0.009524
polynomial-size representations	1.000000
real-valued vectors	0.333333
by Homayoon	0.005714
Marc Angenot	1.000000
Interspeech	0.000029
shallow ''	0.166667
support the	0.250000
expected .	0.142857
expected ,	0.142857
medical records	0.333333
weak ,	1.000000
calculator program	0.500000
The simplest	0.005208
machine is	0.012658
<s> Knowledge	0.000769
the identities	0.000692
and isolated	0.001445
in some	0.007491
at by	0.014706
changed from	0.500000
Compare	0.000029
operating system	0.500000
ones are	0.100000
whole sentences	0.222222
the clusters	0.000692
Semi-supervised	0.000029
to most	0.001328
of that	0.001783
important -RRB-	0.062500
annotating texts	1.000000
-LRB- CSR	0.005420
a written-out	0.001227
model Modern	0.033333
substitution of	1.000000
not using	0.008929
system exhibited	0.010753
Vice	0.000029
claiming	0.000029
<s> Semantic	0.000769
importance is	0.166667
solving larger	1.000000
robustness in	0.250000
of intelligence	0.000891
emoticons ,	1.000000
words must	0.009174
five years	0.400000
strategy for	0.200000
which found	0.014493
multi-word	0.000029
have all	0.009615
Thus	0.000347
mapping the	0.500000
unrealistically high	1.000000
, queries	0.000561
places and	0.500000
marks may	0.250000
module uses	0.333333
-LRB- including	0.002710
G.	0.000058
the production	0.000692
these problems	0.023810
risk	0.000058
good ''	0.076923
unexpected features	1.000000
rise	0.000058
while abstraction	0.050000
set appends	0.025641
first primitive	0.030303
sound pattern	0.050000
function -LRB-	0.125000
system-generated summary	0.500000
known type	0.038462
resolution ,	0.250000
October 2007	1.000000
EBMT	0.000029
integrated	0.000087
resolution :	0.250000
Alenia Aermacchi	1.000000
valuable detailed	0.500000
and processing	0.001445
as OnlineOCR	0.003484
surrounding	0.000145
sizes generally	0.333333
handwritten cursive	0.500000
as objective	0.003484
they had	0.025000
we wanted	0.022222
science disciplines	0.100000
on large	0.004717
Work in	0.500000
feature which	0.076923
can serve	0.011050
four decades	0.142857
name is	0.200000
Searches ,	1.000000
so most	0.033333
digits	0.000029
if documents	0.035714
In normal	0.009524
to rescore	0.001328
changed	0.000058
of ``	0.007130
readily reveal	0.333333
develop in	0.200000
analysts	0.000058
heteroscedastic	0.000058
changes	0.000029
achieving fully	0.500000
might skip	0.038462
discussion groups	0.500000
multi-way scale	1.000000
for his	0.007220
be answered	0.004219
processing task	0.018519
market to	0.333333
human translation	0.043478
by rules	0.005714
referred to	1.000000
question or	0.023810
forums	0.000029
are directly	0.004149
showing comparative	0.500000
from small	0.019231
naive	0.000058
complex spoken	0.041667
How should	0.142857
phone	0.000116
The various	0.005208
must	0.000405
scanned can	0.333333
rarity and	1.000000
appraisal	0.000029
the strength	0.001384
watertight	0.000029
: Interlingual	0.009804
argued that	1.000000
, responding	0.000561
Sparkle campaign	1.000000
country .	0.500000
A parser	0.020000
country ,	0.250000
keyphrases ``	0.028571
subjective .	0.333333
distinguish names	0.200000
adjacent	0.000174
resulting classifier	0.250000
widespread	0.000029
for businesses	0.003610
a general	0.003681
Emanuel	0.000058
generated from	0.133333
recognize For	0.111111
error rates	0.250000
correlation	0.000058
specific voice	0.047619
Levenshtein distance	1.000000
to documents	0.001328
interpretation	0.000058
over	0.000347
algorithms currently	0.028571
probabilistic context-free	0.142857
criterion of	0.500000
a wave	0.004908
with computer-aided	0.005464
SAM	0.000029
exploit domain-specific	1.000000
writing	0.000261
engine page	0.166667
common strategy	0.040000
are pre-determined	0.004149
However	0.001071
the issue	0.002768
to suggest	0.001328
most notably	0.017241
, correlation	0.000561
though automating	0.100000
to represent	0.001328
Baum-Welch	0.000029
contains no	0.100000
One of	0.153846
fonts	0.000087
<s> Several	0.002306
an integrated	0.007576
in evaluating	0.001873
opinion mining	0.200000
by experts	0.005714
grammars for	0.071429
Theo van	1.000000
sentences correct	0.013158
with the	0.153005
is related	0.002033
One can	0.076923
Real time	0.500000
does ,	0.100000
driving	0.000029
Gina	0.000029
William	0.000058
look-up tables	1.000000
have much	0.009615
perception	0.000058
free	0.000116
wanted	0.000029
The machine-learning	0.005208
true keyphrases	0.500000
does a	0.200000
vowels depends	0.333333
developed by	0.038462
large multilingual	0.043478
second system	0.100000
a strong	0.002454
the moderate	0.002076
portable	0.000087
consumed	0.000029
efficient parsers	0.333333
learning As	0.023256
whose easy-to-use	0.333333
percentage	0.000029
, article	0.001684
blind people	0.750000
Search	0.000058
discussing what	0.500000
quite high	0.125000
before classifying	0.166667
Machine learning	0.111111
from any	0.009615
; ``	0.021277
senses ,	0.500000
1978	0.000087
classes	0.000145
compute the	0.500000
's and	0.019608
restricted vocabulary	0.250000
-RRB- from	0.002817
Rubin ,	1.000000
Cary Grant	1.000000
at IBM	0.014706
relatively	0.000029
clearly visible	0.333333
isolated	0.000145
understanding in	0.030303
understanding is	0.060606
by further	0.005714
in deaf	0.001873
<s> Relationship	0.000769
properties as	0.250000
has given	0.011905
commanding	0.000029
Defense Advanced	1.000000
or any	0.013514
times they	0.200000
and cognition	0.001445
highly complex	0.111111
that specific	0.003546
probabilities of	0.272727
<s> Keyphrase	0.002306
Markov chain	0.055556
Its	0.000058
to perform	0.005312
for Italian	0.003610
labels	0.000058
disambiguation Word-sense	0.100000
APEXC machine	1.000000
availability	0.000029
Big	0.000029
what categories	0.031250
morphosyntactic	0.000029
later part-of-speech	0.100000
answer type	0.066667
or poetry	0.004505
-LRB- 1966	0.002710
a person	0.013497
simply too	0.083333
NP-complete	0.000029
abstraction .	0.250000
is publicly	0.002033
<s> Use	0.000769
databases -RRB-	0.125000
-LRB- icon	0.002710
by supplying	0.005714
recognition technology	0.008264
the forward-backward	0.000692
in vastly	0.001873
Cleave and	1.000000
the optical	0.000692
, David	0.001684
question answering	0.214286
practice of	0.500000
Performance	0.000029
end a	0.125000
discourse and	0.111111
answers to	0.083333
sound signal	0.050000
of elaborate	0.000891
evaluation requires	0.018519
Today there	1.000000
Digest and	0.333333
Unsupervised approaches	0.166667
end .	0.125000
end ,	0.125000
and have	0.001445
level of	0.350000
research attempts	0.047619
been debated	0.014706
On the	0.333333
Since the	0.200000
faces	0.000029
are three	0.004149
Automatically translate	1.000000
comprehension	0.000203
high pollen	0.055556
VRX	0.000029
negative up	0.125000
the intermediary	0.000692
some perception	0.012048
Input -RRB-	0.500000
the details	0.000692
pre-marked	0.000029
the main	0.001384
be considered	0.008439
very dependent	0.024390
<s> Read	0.000769
a sublanguage	0.001227
<s> Real	0.001537
exchange of	1.000000
Animate	0.000029
uninterrupted and	1.000000
or noun	0.004505
definite on	1.000000
-LRB- most	0.010840
new token	0.041667
with larger	0.005464
networks has	0.071429
1989 -RRB-	0.500000
committed into	1.000000
translation at	0.013514
then direct	0.028571
commercializing paper-to-computer	1.000000
Parseval\/GEIG project	1.000000
offer the	1.000000
sentences -RRB-	0.026316
rely are	0.142857
Recently ,	1.000000
strategies ,	0.500000
the text-to-speech	0.000692
11 point	1.000000
characters	0.000463
Canada and	0.166667
two general	0.034483
: navigation	0.009804
parsers .	0.076923
more dynamic	0.010526
that tell	0.003546
Strzalkowski T.	1.000000
to text	0.002656
a limit	0.001227
begin and	0.333333
translation and	0.040541
corpus linguistics	0.096774
Some scholars	0.047619
unwanted	0.000029
system output	0.010753
the feature	0.000692
be roughly	0.004219
demonstrate .	1.000000
, Wallace	0.000561
processing tools	0.018519
source documents	0.125000
businesses looking	0.500000
OCR and	0.020408
a journal	0.001227
lexical statistics	0.076923
boundary markers	0.166667
very effective	0.024390
advanced	0.000145
many consecutive	0.019231
many programmers	0.019231
Robotics	0.000029
Answer formulation	0.333333
Dragon Systems	1.000000
some common	0.012048
informative	0.000058
by air	0.011429
burden on	1.000000
breaking -LRB-	0.500000
enough information	0.200000
NP for	1.000000
work for	0.041667
as hidden	0.003484
rapidly changing	0.500000
-LRB- For	0.005420
beforehand -LRB-	1.000000
translation Statistical	0.013514
He	0.000232
for help	0.003610
what knowledge	0.031250
produces all	0.250000
unigrams to	0.083333
established within	1.000000
and check	0.001445
of numbers	0.001783
H.	0.000058
steadily	0.000029
efforts	0.000203
of running	0.000891
series -RRB-	0.125000
paraphrases	0.000029
interrogative -LRB-	1.000000
presence	0.000029
against any	0.200000
text structure	0.006289
Petrov ,	1.000000
shape of	1.000000
truck A	1.000000
nice side	0.250000
, texts	0.000561
using CSIS	0.016949
lead-in	0.000029
Petrov	0.000029
and generally	0.001445
syntax and	0.090909
-RRB- ``	0.002817
synthesis	0.000029
by heteroscedastic	0.005714
differences	0.000087
removes	0.000029
a strength	0.001227
including recognition	0.071429
the content	0.002076
removed	0.000029
like this	0.035714
versions	0.000087
was conducted	0.025974
into phonetic-based	0.012821
NLG -RRB-	0.047619
and limited	0.001445
Introduction	0.000029
orthography to	0.500000
be automated	0.004219
years long	0.047619
-LRB- for	0.018970
of stochastic	0.000891
or after	0.004505
constructed	0.000058
perform data	0.090909
The cache	0.005208
research may	0.023810
As a	0.111111
of low	0.000891
distinctive initial	0.500000
models upon	0.038462
this genre	0.010989
refers to	1.000000
ideal deep	1.000000
Guzman ,	1.000000
longer	0.000029
have questioned	0.009615
for substantial	0.003610
Putting words	1.000000
neighbors	0.000087
, unlike	0.000561
or topics	0.004505
expensive since	0.142857
remarkably	0.000029
Ncmsan ,	1.000000
Today	0.000029
Components and	1.000000
1949	0.000058
of organized	0.000891
1946	0.000029
Standard	0.000058
The extractor	0.005208
new entrants	0.041667
: Vocabulary	0.009804
sentences ``	0.026316
Bell Telephone	1.000000
central ``	0.333333
for data	0.007220
<s> Languages	0.002306
culminating	0.000029
McCarthy	0.000029
NLP comes	0.021277
no information	0.076923
Language understanding	0.083333
, deciding	0.002246
sentence ,	0.125000
sentence .	0.145833
slower	0.000058
Sociologist	0.000029
-RRB- Court	0.002817
units such	0.142857
measures can	0.333333
another ,	0.076923
another .	0.230769
knowledge but	0.037037
stands	0.000029
Automotive	0.000029
Page ,	1.000000
written by	0.230769
where word	0.028571
‚Üê	0.000029
a hard	0.002454
human translators	0.021739
approaches presume	0.035714
water	0.000029
baseball	0.000029
Note that	0.777778
supplying	0.000029
= Machine	0.111111
numbers ,	0.285714
and which	0.001445
? ''	0.750000
navigation	0.000058
cache	0.000029
, cited	0.000561
, Alan	0.000561
modifying	0.000029
has fairly	0.011905
the nature	0.003460
operational	0.000029
also similar	0.014493
piecewise stationary	1.000000
memory	0.000058
intermediary ,	0.333333
with certain	0.005464
but other	0.014706
to write	0.001328
October	0.000029
and analyze	0.001445
outputs	0.000029
same summary	0.040000
`` can	0.005291
why applying	0.142857
device converted	0.500000
insights	0.000029
are confusable	0.004149
Oil Company	1.000000
the biomedical	0.000692
human judgments	0.021739
syntax is	0.090909
minimum	0.000058
input ;	0.024390
up ''	0.045455
theorists of	1.000000
stream	0.000058
including PARRY	0.071429
the presence	0.000692
NP-complete .	1.000000
use hidden	0.013889
input ,	0.073171
possible unigrams	0.041667
British National	0.333333
Coulthard ,	1.000000
a good	0.004908
The notion	0.010417
names of	0.142857
working examples	0.142857
probably ``	0.250000
bunch of	1.000000
to Xerox	0.001328
larger volume	0.062500
unigrams in	0.250000
needs	0.000290
of itself	0.000891
typewritten	0.000145
input a	0.024390
close the	1.000000
classroom	0.000029
language analysis	0.006757
to each	0.006640
ones	0.000290
research and	0.119048
one font	0.015385
words	0.003156
vice versa	1.000000
done by	0.181818
constituents	0.000058
agreement among	0.333333
mainly	0.000174
the -LRB-	0.000692
that carried	0.003546
analyzing written	0.200000
kind to	0.090909
determination :	1.000000
occurring '	1.000000
include voice	0.037037
others assign	0.083333
Top-down parsing	1.000000
of complex	0.000891
1991 A	0.333333
same example-generation	0.040000
responsible for	1.000000
advent	0.000029
realistic	0.000029
on its	0.009434
serial numbers	1.000000
ALPAC report	1.000000
English-French	0.000029
that now	0.003546
Gee ,	1.000000
maintained within	0.500000
exclamation	0.000029
it difficult	0.017094
discourse relationships	0.027778
factors	0.000087
<s> Acoustical	0.000769
even appears	0.037037
follow-the-bouncing-ball	0.000029
factory	0.000029
extrapolate	0.000029
computer programs	0.045455
with learning	0.005464
2005 -RRB-	1.000000
Deborah Schiffrin	0.500000
deep are	0.142857
technology devised	0.045455
Dog	0.000029
for extracting	0.003610
capital of	0.666667
<s> E.	0.000769
Command -RRB-	0.500000
also capitalized	0.014493
financial section	0.250000
which are	0.086957
minimum classification	0.500000
errors in	0.200000
motion	0.000029
primitive computer-type	1.000000
context in	0.030303
progress and	0.142857
digital dictation	0.142857
involves preliminary	0.100000
features of	0.153846
that merely	0.003546
space is	0.200000
symbolic	0.000029
less time	0.083333
researchers must	0.100000
concatenated text	1.000000
Computers can	1.000000
features or	0.038462
cope with	1.000000
verbs ,	0.600000
coupons returned	1.000000
If it	0.100000
Short history	1.000000
several modules	0.045455
Data	0.000029
QA research	0.047619
exploring	0.000029
season	0.000029
some written	0.024096
PDF	0.000029
HTML and	1.000000
distinctions -LRB-	0.500000
wide	0.000116
of 1,500	0.000891
any other	0.064516
lowest	0.000029
alignment software	0.500000
topics automatically	0.142857
the examples	0.002076
short summary	0.125000
about feature	0.025000
areas --	0.166667
statistics readily	0.125000
The fact	0.005208
conversion	0.000087
using votes	0.016949
strengths	0.000058
actual forecast	0.200000
University introduced	0.111111
computer applications	0.022727
performance on	0.055556
to 1966	0.001328
formed the	0.200000
performance of	0.111111
multiply	0.000029
on several	0.004717
impossible .	0.500000
fact ambiguous	0.090909
quantity	0.000087
reproducing formatted	1.000000
Guidelines see	0.500000
collecting a	1.000000
as discussions	0.003484
entity ,	0.400000
increased so	0.200000
answer a	0.033333
conflicting objectives	1.000000
see computational	0.050000
Other segmentation	0.142857
Emergent grammar	1.000000
hand-written by	0.142857
and controversial	0.001445
that they	0.024823
nasality ,	1.000000
year .	0.500000
n being	0.500000
Foucault himself	0.333333
answer .	0.233333
answer ,	0.033333
inaccurate or	1.000000
severe in	1.000000
a process	0.004908
intelligence -LRB-	0.125000
indeed ,	0.333333
is ambiguous	0.002033
One example	0.076923
Man dog	0.500000
encouraged	0.000029
suffer	0.000029
ways	0.000232
review	0.000087
, that	0.002246
so we	0.033333
were realized	0.024390
marked for	0.666667
' -RRB-	0.052632
machine-encoded text	1.000000
U.S.	0.000203
inseparable	0.000029
is apple	0.002033
a probability	0.001227
your head	0.500000
Speech recognition	0.290323
information is	0.043478
missions	0.000029
example by	0.024691
MUC and	1.000000
Sublanguage analysis	1.000000
information in	0.043478
utterance	0.000087
Re-encoding this	1.000000
des parties	1.000000
Open source	1.000000
Duranti ,	1.000000
and duplicate	0.001445
rules similar	0.046512
happy .	1.000000
assertions	0.000058
<s> DeRose	0.001537
on functional	0.004717
two simple	0.034483
confusable	0.000029
Systran ,	1.000000
Tom Clancy	1.000000
all handwritten	0.023256
The LexRank	0.005208
's SPHINX	0.019608
and Martin	0.001445
many instances	0.019231
broader and	1.000000
gestures ,	0.500000
more or	0.031579
'' highly	0.005376
summary that	0.047619
harder to	0.285714
would not	0.018868
recall may	0.333333
shops	0.000029
combined with	0.500000
with values	0.016393
Additional	0.000029
telephone	0.000058
, translation	0.001123
Sparkle	0.000029
`` happy	0.005291
appear ``	0.062500
performed using	0.100000
give the	0.500000
, using	0.005615
of social	0.001783
top T	0.400000
Du Bois	1.000000
what type	0.031250
IT	0.000029
driven	0.000029
the topic	0.001384
various genres	0.055556
a quantity	0.001227
IE	0.000087
ID	0.000029
edges ?	0.285714
minimize	0.000029
on context	0.004717
It	0.001100
First summarizes	1.000000
say whether	0.142857
components	0.000145
In	0.003040
including the	0.071429
If	0.000290
in addition	0.005618
<s> Named	0.000769
if word	0.035714
improvement of	0.500000
of hidden	0.000891
captured	0.000029
Broadly	0.000029
lip-synch timing	1.000000
Applications	0.000058
samples	0.000058
for accuracy	0.003610
correlate best	0.333333
<s> Xerox	0.000769
original text	0.461538
made WebOCR	0.062500
<s> Topic	0.000769
Fully	0.000029
often has	0.045455
Stemming Text	1.000000
transcended the	1.000000
can do	0.011050
Avionics	0.000029
such cases	0.016260
Another key	0.076923
of language	0.004456
Spoken	0.000029
noise ,	0.125000
atmosphere -LRB-	1.000000
Since	0.000145
character-by-character OCR	1.000000
by hand	0.034286
L'action	0.000029
extraction can	0.032258
: for	0.009804
respect	0.000203
International	0.000029
assign a	0.400000
Knowing	0.000029
acts in	0.333333
data used	0.025974
subproblem	0.000029
speech signal	0.006579
by domain	0.005714
perspectives and	1.000000
of constraints	0.000891
Continuous speech	1.000000
have started	0.009615
earlier	0.000116
you have	0.153846
research direction	0.023810
but deep	0.014706
linguistic nuances	0.062500
formalism which	1.000000
Garfinkel who	1.000000
found .	0.071429
affective state	1.000000
next four	0.142857
of connected	0.000891
determine	0.000666
cases ,	0.388889
particular note	0.076923
the Parliament	0.000692
machine recognition	0.012658
distinctions	0.000058
19th -	1.000000
reason ,	0.500000
discourse turns	0.027778
code ,	0.142857
LL parsers	1.000000
code .	0.428571
later licensed	0.100000
tuned weights	1.000000
and ontology	0.001445
Once these	0.200000
orthogonal to	1.000000
an hour	0.007576
personalised business	1.000000
RDF	0.000029
and patented	0.001445
a tagging	0.001227
but steadily	0.014706
or grammatical	0.004505
numbers after	0.142857
new domains	0.041667
considerable success	0.200000
Louise	0.000029
modules	0.000058
of extractive	0.000891
incorrect	0.000087
single language	0.071429
the Bayes	0.000692
with different	0.010929
structured resources	0.166667
-LRB- actual	0.002710
5	0.000058
summaries must	0.023256
ASR is	0.166667
two ?	0.034483
separate	0.000290
symbol	0.000116
term parsing	0.055556
and Language	0.005780
calls	0.000029
A first	0.020000
man-hours worked	1.000000
lack of	1.000000
whole discourses	0.111111
making a	0.142857
matrix ,	1.000000
meant that	0.500000
improve the	0.076923
lack	0.000029
a standard	0.002454
Turing published	0.500000
The method	0.005208
construct over	0.333333
stutering	0.000029
set and	0.025641
creating pre-defined	0.142857
opportunities	0.000029
doctors make	0.333333
setting of	0.200000
progress -	0.142857
not appear	0.008929
far	0.000232
task entirely	0.023810
: an	0.009804
hand-compiled list	1.000000
psychologist	0.000029
ultraviolet	0.000029
had similar	0.071429
not used	0.017857
intended emotional	0.200000
or Latin	0.004505
Reukos S.	1.000000
researchers have	0.300000
align	0.000029
accuracy reported	0.032258
, taught	0.000561
Discourse	0.000087
would choose	0.018868
an F-score	0.007576
functioning	0.000087
will generate	0.085714
BioCreative Message	1.000000
meanings depending	0.250000
precise ones	0.333333
to choose	0.001328
state .	0.071429
and a	0.023121
time and	0.090909
card OCR	0.250000
Short	0.000029
: Putting	0.009804
have produced	0.009615
can add	0.005525
summaries for	0.023256
, substantial	0.000561
to discover	0.001328
state a	0.071429
book-new	0.000029
allows	0.000232
Intuitively	0.000029
whether it	0.076923
opening ''	1.000000
n't see	0.250000
sentence transformations	0.020833
approaches Automatic	0.035714
recognition using	0.008264
heuristic to	0.333333
Evaluation	0.000261
unlabeled data	1.000000
following the	0.066667
accurate results	0.142857
plural common	0.200000
to resolve	0.003984
the fixed	0.000692
an individual	0.007576
machine at	0.012658
Such perceptions	0.125000
certainty of	1.000000
operators	0.000029
developing Q&A	0.250000
a non-whitespace	0.001227
by Schank	0.005714
be located	0.004219
other NLP	0.014286
earlier Brown	0.250000
depends greatly	0.125000
commercial products	0.090909
memory Political	0.500000
Tagger	0.000029
like summarization	0.035714
In 1994	0.009524
In 1996	0.009524
implementation of	1.000000
simulates the	1.000000
In 1993	0.009524
Different	0.000058
, trigram	0.001123
challenging	0.000029
metrics often	0.111111
or produce	0.004505
this issue	0.010989
Speaker	0.000174
characterized DARPA	0.250000
fall between	0.250000
the creation	0.000692
talk-in-interaction	0.000029
values to	0.125000
recursive	0.000029
Intelligent	0.000087
decisions about	0.200000
sound impressive	0.050000
stemming	0.000058
relevant to	0.142857
reflect	0.000029
and large-scale	0.001445
various features	0.055556
solve algebra	0.250000
Heritage ,	1.000000
, he	0.001123
demonstration of	0.400000
predefined template	1.000000
be expected	0.012658
1,915,993	0.000029
unambiguously identified	1.000000
Mandarin	0.000058
and manage	0.001445
This reader	0.015873
he had	0.142857
Many systems	0.083333
the text	0.017993
commercial perspective	0.090909
standard telegraph	0.071429
return	0.000058
, Number	0.000561
M. 1999	0.250000
correct ''	0.066667
Lightning	0.000029
framework	0.000116
American camp	0.200000
recognition since	0.008264
variability ,	1.000000
, Guy	0.000561
approximated as	1.000000
Telephone	0.000029
Telephony	0.000029
Languages which	0.333333
other languages	0.071429
done	0.000318
summaries with	0.046512
of this	0.009804
Ray	0.000029
sense that	0.125000
A well-known	0.020000
generation	0.000261
necessary anymore	0.100000
capabilities and	0.200000
Joseph	0.000058
goal is	0.428571
undertake	0.000029
water .	1.000000
of Hidden	0.000891
`` not	0.005291
parsing community	0.035714
Interactive QA	0.500000
commonly associated	0.125000
The experiment	0.005208
Reiter	0.000029
The construction	0.005208
develop as	0.200000
in NIST	0.001873
all get	0.023256
unique	0.000029
Alternatively ,	1.000000
Sync	0.000029
prestige ''	1.000000
he went	0.285714
proceeds in	1.000000
These findings	0.058824
aspects such	0.142857
relate	0.000058
fancy	0.000029
Gary Hendrix	1.000000
provided within	0.200000
humans transcribe	0.083333
now common	0.076923
enable the	1.000000
script	0.000116
, William	0.001123
which discourse	0.007246
aspect is	0.500000
splicing and	1.000000
the elements	0.000692
call to	0.333333
option	0.000029
determines the	0.666667
domain -LRB-	0.050000
Evaluation techniques	0.111111
convinced	0.000029
and would	0.001445
question domain	0.023810
ideas -RRB-	0.250000
a categorical	0.001227
many stochastic	0.019231
Dictionary-based	0.000058
much larger	0.090909
Speech Communication	0.032258
test the	0.100000
simply model	0.083333
real-world knowledge	0.166667
transcriptions	0.000058
Recall-Oriented	0.000058
so for	0.033333
classifying its	0.200000
certain cases	0.142857
, associating	0.000561
a generic	0.001227
of context-free	0.000891
these two	0.023810
ranked highly	0.400000
Closed-domain	0.000029
cues help	1.000000
suitable ontology	0.250000
best application	0.055556
was entertaining	0.012987
Carston ,	1.000000
the closest	0.000692
linear regression	0.142857
translation process	0.027027
or positive	0.004505
British	0.000087
and trigrams	0.002890
for recognizing	0.003610
% error	0.025641
individual sentences	0.083333
font	0.000087
real-time written	0.500000
theoretical aspects	0.333333
of deciding	0.000891
his	0.000347
hit	0.000029
usually evaluated	0.031250
longest	0.000029
these other	0.023810
him	0.000058
for continued	0.003610
also manual	0.014493
Canada Post	0.166667
Pang	0.000087
art	0.000058
engines ,	0.333333
attached to	0.500000
are	0.006977
tool to	0.500000
arm	0.000029
learns	0.000029
tasks such	0.062500
When processing	0.142857
distinctive	0.000058
formatted	0.000029
libraries	0.000058
the basics	0.000692
wrote ELIZA	0.166667
various	0.000521
encouraging ,	1.000000
consecutive	0.000058
and voice	0.001445
initially	0.000029
general-purpose	0.000029
reduced .	0.500000
Parsing algorithms	0.200000
Japanese	0.000232
c	0.000029
possible transcriptions	0.083333
rejecting ``	0.666667
became	0.000145
sentiment strength	0.040000
they differ	0.025000
final post-processing	0.111111
arbitrarily	0.000029
content and	0.166667
other research	0.014286
estimated probability	1.000000
and manipulate	0.001445
but switched	0.014706
by IMR	0.005714
about each	0.025000
systems will	0.008929
whom	0.000058
reduction	0.000058
colloquially termed	1.000000
units are	0.285714
ATC simulators	0.200000
1950s	0.000116
evaluating NLG	0.200000
's specific	0.019608
input-stream by	1.000000
any human	0.032258
Integration -LRB-	1.000000
models of	0.038462
yes-no question	1.000000
techniques on	0.043478
behavior	0.000058
students at	0.666667
engineers	0.000029
merged with	1.000000
count .	0.200000
is much	0.004065
only specific	0.026316
lengths	0.000029
some machine	0.012048
graph is	0.230769
sometimes ,	0.076923
widely	0.000232
rules and	0.023256
of computational	0.002674
fastens	0.000029
a writer	0.001227
of users	0.001783
Tipster	0.000029
the above	0.001384
gets around	0.500000
analysis	0.001882
, written	0.000561
edge	0.000087
have increased	0.028846
count T	0.200000
suitability as	0.500000
steady increase	0.500000
motion during	1.000000
possibility to	0.250000
grammar having	0.027027
intervals	0.000029
Northern areas	0.333333
could co-occur	0.062500
perform by	0.090909
most prior	0.017241
Naturally Speaking	1.000000
field comes	0.037037
find only	0.076923
displayed as	0.500000
the full	0.002076
2 -RRB-	0.200000
unlimited	0.000029
preferred computer-generated	1.000000
not easily	0.026786
The rule-based	0.005208
with regards	0.005464
identify and	0.083333
speech to	0.019737
ignore	0.000029
be sufficient	0.004219
that simple	0.003546
keyphrases for	0.057143
of papers	0.000891
their hands	0.029412
a new	0.007362
are easier	0.004149
lessened .	1.000000
trends of	1.000000
underpinnings	0.000029
Many different	0.166667
unambiguous sentence-ending	0.500000
Applied linguistics	0.500000
selected based	0.500000
importance would	0.166667
most	0.001679
-LRB- ``	0.021680
Patent 2,663,758	0.333333
e.g. with	0.017857
modal	0.000029
for some	0.018051
cutoff	0.000029
, 1952	0.000561
accepted ,	1.000000
word at	0.016667
<s> Extrinsic	0.001537
in service	0.001873
the identification	0.001384
restaurant reviews	0.500000
intra-texual .	1.000000
issue is	0.125000
OCR or	0.020408
of systems	0.001783
IBM .	0.333333
issue in	0.125000
accurate by	0.142857
NLG input	0.047619
searching	0.000087
repeatedly	0.000029
Technolangue\/Easy	0.000058
a rainbow	0.001227
perform adaptive	0.090909
parsing comes	0.035714
called	0.000521
Another popular	0.076923
is far	0.004065
from multiple	0.009615
approximately divided	0.500000
Court reporting	1.000000
mining refers	0.200000
will cover	0.028571
to such	0.002656
mainly came	0.166667
relative certainty	0.333333
the supervised	0.000692
invention of	1.000000
's work	0.019608
question into	0.023810
grouped	0.000058
into consideration	0.012821
Informally	0.000029
the formal	0.001384
could imagine	0.062500
step that	0.133333
to convey	0.003984
of speech	0.040998
personalised	0.000029
global semitied	0.333333
complex formalisms	0.041667
it easily	0.008547
reading comprehension	0.250000
linguist to	0.500000
Speech and	0.161290
to 90	0.001328
direct hand	0.166667
language like	0.006757
to 98	0.001328
some degree	0.024096
, this	0.003369
my hand-compiled	1.000000
-LRB- plural	0.002710
After 30	0.333333
features\/aspects	0.000029
different meanings	0.020408
, only	0.001123
email address	0.500000
, graphic	0.000561
wishes	0.000029
IT technology	1.000000
for parse	0.003610
; Each	0.021277
deals	0.000116
: Merging	0.009804
norm .	1.000000
classifies features	1.000000
What distinguishes	0.090909
summarise electronic	0.333333
surrounding vowels	0.200000
universities	0.000029
Part-of-speech Tagging	0.500000
Union as	1.000000
neutral or	0.500000
computing :	0.500000
For more	0.032787
of some	0.004456
computing .	0.500000
as Eugene	0.003484
stored more	1.000000
USA in	1.000000
summaries There	0.023256
several systems	0.045455
and synthesis	0.001445
with rules	0.005464
Hardy	0.000029
Re-encoding	0.000029
which often	0.007246
performed ,	0.200000
-LRB- various	0.002710
languages of	0.020000
see below	0.050000
apple	0.000087
text documents	0.006289
Robert	0.000116
giving the	0.500000
emerged as	1.000000
Decoding the	0.500000
languages or	0.020000
him perform	0.500000
apply	0.000145
for comparison	0.003610
markup like	1.000000
if they	0.035714
Vietnamese	0.000029
common way	0.080000
and combine	0.001445
and how	0.004335
time factor	0.030303
Sync -RRB-	1.000000
be poorly	0.004219
like that	0.035714
noise levels	0.125000
employed within	1.000000
and EUROPARL	0.001445
and slang	0.001445
consider sequences	0.250000
uses only	0.071429
object ,	0.500000
scanner to	0.333333
the techniques	0.000692
instructions .	1.000000
main underlying	0.125000
reduction of	0.500000
written language	0.115385
Northern	0.000087
tell us	0.333333
for ASR	0.003610
tag	0.000463
particular case	0.076923
as language	0.003484
serial	0.000029
meaning to	0.086957
debated much	1.000000
polarity helped	0.125000
and paragraph	0.001445
SPOTLIGHT system	1.000000
Conversational analysis	1.000000
similarity metrics	0.100000
for inclusion	0.003610
minimizes the	1.000000
Hence	0.000058
, Grishman	0.000561
Aermacchi	0.000029
date is	0.333333
, previously	0.000561
noise pertain	0.125000
one element	0.015385
cepstral coefficients	0.500000
figure on	0.500000
<s> What	0.003075
Germany .	0.500000
tokens from	0.142857
Germany ,	0.500000
into each	0.012821
trivial word	0.250000
interrogative	0.000029
occurrence ,	0.500000
anywhere on	1.000000
data that	0.025974
the relationship	0.000692
drawn right-to-left	1.000000
RCA 301	0.200000
practice	0.000058
articles in	0.250000
co-founded Google	1.000000
Adam	0.000029
aircraft -LRB-	0.285714
false	0.000058
classification ''	0.294118
a fully	0.001227
interlingual	0.000116
Voice commands	0.200000
door ''	0.500000
new POS	0.041667
The learning	0.005208
different left	0.020408
translations ,	0.500000
information extraction	0.021739
Who is	0.500000
and possessives	0.001445
category	0.000058
T final	0.166667
is responsible	0.002033
preselects	0.000029
reformulate	0.000029
dictionary	0.000203
and -RRB-	0.001445
of word-forms	0.000891
the language	0.005536
and depth	0.001445
abstracts ,	0.500000
, 13	0.000561
, 10	0.001123
Corpus and	0.125000
Medical Language	0.500000
Topics	0.000058
preposition ,	1.000000
feasible	0.000058
Gisting	0.000058
conversation	0.000116
a greater	0.001227
<s> Rule-based	0.000769
run-time .	1.000000
explanation ,	1.000000
several -RRB-	0.045455
commonly teach	0.125000
and also	0.001445
accent	0.000029
specific task	0.047619
then common	0.028571
the core	0.000692
of parsing	0.001783
create both	0.058824
remember	0.000029
short textual	0.125000
which showed	0.007246
vocabularies	0.000058
barmaid -RRB-	0.500000
proposes some	1.000000
was -LRB-	0.012987
several words	0.045455
the scope	0.001384
also considered	0.014493
Paul Gee	0.200000
The importance	0.005208
perform complex	0.090909
and extract	0.001445
Independent	0.000029
1990 -RRB-	0.666667
grammars are	0.071429
using their	0.016949
vs. manual	0.083333
`` a	0.005291
or neutral	0.004505
adapt to	1.000000
<s> Compare	0.000769
examples and	0.166667
20 %	1.000000
be satisfactory	0.004219
and most	0.001445
HLT ,	1.000000
`` A	0.005291
`` B	0.005291
archiving	0.000029
`` I	0.005291
, internet	0.000561
vision .	1.000000
, stored	0.000561
known .	0.038462
speaker can	0.055556
-RRB- formal	0.002817
analyst is	1.000000
purely	0.000029
as that	0.003484
Recognition ''	0.375000
area -RRB-	0.090909
of Roger	0.000891
high degree	0.055556
In natural	0.009524
candidates	0.000145
thousands	0.000087
methods for	0.045455
including linguistics	0.142857
the needs	0.000692
for detecting	0.003610
that combines	0.003546
Paragraph	0.000029
interoperability	0.000029
e.g. pictures	0.017857
are confirmed	0.004149
speech which	0.006579
the Grace	0.000692
at binary	0.014706
networks emerged	0.071429
concerned in	0.200000
Mariani J.	1.000000
of substantial	0.000891
hand-written rules	0.857143
view	0.000087
than sixty	0.022222
uncertainties at	1.000000
a period	0.002454
and Thai	0.001445
Transfer-based	0.000058
dependencies .	1.000000
discouraged the	1.000000
bill payment	0.500000
closer	0.000058
functions such	0.500000
by mapping	0.005714
text itself	0.006289
fidelity of	1.000000
pre-defined by	0.500000
closed	0.000029
undertake harder	1.000000
require minimal	0.045455
know is	0.500000
Systems based	0.250000
inter-annotator agreement	1.000000
is rarely	0.002033
of 15-20	0.000891
, strategies	0.000561
a science	0.002454
captioning	0.000029
the Turing	0.000692
by comparing	0.005714
Church independently	0.333333
and even	0.008671
operated successfully	0.500000
to assign	0.003984
complex sets	0.041667
spacecraft ,	1.000000
only succeeding	0.026316
forecasts in	0.200000
one ,	0.061538
one .	0.030769
clarification .	0.333333
the statistical	0.001384
a concept	0.001227
particular feature	0.076923
late 1930s	0.111111
the word	0.005536
the work	0.001384
to ones	0.001328
unambiguous .	0.500000
-LRB- MMR	0.002710
developed for	0.038462
V ,	1.000000
early precursor	0.100000
thesis at	1.000000
NLG may	0.047619
Eight years	1.000000
Language Generation	0.083333
a reading	0.001227
<s> Intuitively	0.000769
the length	0.001384
-LRB- MMI	0.002710
Navigation	0.000029
or fuse	0.004505
formally ,	0.500000
restaurant	0.000058
artifacts ,	1.000000
good summary	0.153846
will	0.001013
the process	0.007612
or lexical	0.009009
achieved by	0.200000
A good	0.020000
characters themselves	0.062500
ELIZA ,	0.333333
, even	0.003930
or phonemes	0.009009
by many	0.005714
Manual analysis	0.333333
content question	0.083333
concluded that	1.000000
of typical	0.000891
Alan Turing	1.000000
the theory	0.002076
the label	0.000692
chart parsing	1.000000
are MARGIE	0.004149
1999 -RRB-	0.500000
and pasted	0.001445
one word	0.030769
from MUC	0.009615
web pages	0.125000
the specific	0.002076
question can	0.023810
some variant	0.012048
le fran√ßais	1.000000
<s> High-order	0.000769
Speaker Recognition	0.166667
of arbitrary	0.000891
the Vocabulary	0.000692
and perspective	0.001445
<s> Because	0.001537
fashion ,	1.000000
an important	0.015152
WordNet ,	0.500000
WordNet .	0.500000
from Moore	0.009615
distortion ,	1.000000
a vertex	0.002454
systems read	0.008929
, Dr.	0.000561
for plural	0.003610
like what	0.035714
widely used	0.875000
identical	0.000058
weighted to	0.333333
such representation	0.008130
Drum	0.000029
-LRB- role	0.002710
them for	0.052632
of about	0.000891
features into	0.038462
know	0.000058
measures of	0.166667
syntax to	0.181818
rare --	0.250000
Nagao	0.000029
and do	0.001445
'' http:\/\/arxiv.org\/abs\/1104.2086	0.005376
construct lightweight	0.333333
-LRB- the	0.021680
, Animate	0.000561
because	0.000869
sequence	0.000232
may not	0.096154
software varied	0.037037
preposition	0.000087
psycholinguistics ,	0.500000
Jonathan	0.000029
Speech can	0.032258
considered for	0.111111
lead	0.000058
subjective Yes\/No	0.166667
has to	0.059524
the improvement	0.000692
those East	0.045455
sociolinguistics Ethnography	0.500000
locate	0.000029
address -	0.250000
previously unseen	0.500000
probably important	0.250000
simply apply	0.083333
reference model	0.125000
getting	0.000116
nice beach	0.250000
dependence	0.000029
dependency	0.000145
Types of	1.000000
breaking ,	0.500000
as supervised	0.003484
portable to	0.333333
tag the	0.062500
ranking task	0.142857
Vulcan later	0.500000
using will	0.016949
one human	0.015385
entire content	0.333333
evaluations have	0.166667
debates ,	1.000000
meaning part	0.043478
testing accuracy	0.200000
silence are	1.000000
heuristic	0.000087
more categories	0.010526
a binary	0.002454
DARPA funding	0.250000
of automated	0.000891
has the	0.023810
For nouns	0.016393
similarities in	0.500000
`` Gismo	0.010582
language that	0.006757
Tipster project	1.000000
texts .	0.176471
ELIZA sometimes	0.111111
texts ,	0.117647
non-existent	0.000029
helicopter .	0.250000
meaningless	0.000029
of questions	0.004456
that cause	0.003546
typically produces	0.055556
selects important	0.500000
similar in	0.037037
Several MT	0.333333
book	0.000232
long-time	0.000029
terms do	0.076923
accurate transcription	0.142857
table of	0.428571
Weaver	0.000029
shared-task events	1.000000
space	0.000145
the theoretical	0.000692
method of	0.125000
